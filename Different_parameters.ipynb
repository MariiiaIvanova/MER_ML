{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4f3664-29a1-44db-bf67-549e9a17d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import fnmatch \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9b830a-1180-45ea-ab9d-9fed9035ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/MER_audio_taffc_dataset/panda_dataset_taffc_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8b8c81-6800-4848-a81d-2b9ee8b52256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>PQuad</th>\n",
       "      <th>MoodsTotal</th>\n",
       "      <th>Moods</th>\n",
       "      <th>MoodsFoundStr</th>\n",
       "      <th>MoodsStr</th>\n",
       "      <th>MoodsStrSplit</th>\n",
       "      <th>Genres</th>\n",
       "      <th>GenresStr</th>\n",
       "      <th>Sample</th>\n",
       "      <th>SampleURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>Charlie Poole</td>\n",
       "      <td>Bulldog Down in Sunny Tennessee</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>circular; greasy; messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>2</td>\n",
       "      <td>Country; International</td>\n",
       "      <td>1</td>\n",
       "      <td>http://rovimusic.rovicorp.com/playback.mp3?c=l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT0000011357</td>\n",
       "      <td>Dismember</td>\n",
       "      <td>Reborn in Blasphemy</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>jittery; negative; nervous</td>\n",
       "      <td>Negative; Nervous/Jittery</td>\n",
       "      <td>Negative; Nervous; Jittery</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronic; International; Pop/Rock</td>\n",
       "      <td>1</td>\n",
       "      <td>http://rovimusic.rovicorp.com/playback.mp3?c=0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT0000011975</td>\n",
       "      <td>Curse of the Golden Vampire</td>\n",
       "      <td>Ultrasonic Meltdown</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>fierce; harsh; hostile; menacing; outrageous</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>1</td>\n",
       "      <td>http://rovimusic.rovicorp.com/playback.mp3?c=_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT0000040632</td>\n",
       "      <td>Gipsy Kings</td>\n",
       "      <td>Flamencos en el Aire</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>fiery; sexy; spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>2</td>\n",
       "      <td>International; Jazz</td>\n",
       "      <td>1</td>\n",
       "      <td>http://rovimusic.rovicorp.com/playback.mp3?c=G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT0000044741</td>\n",
       "      <td>Little Walter</td>\n",
       "      <td>Last Night</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>greasy; gritty; gutsy; lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>1</td>\n",
       "      <td>Blues</td>\n",
       "      <td>1</td>\n",
       "      <td>http://rovimusic.rovicorp.com/playback.mp3?c=k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song                       Artist                            Title  \\\n",
       "0  MT0000004637                Charlie Poole  Bulldog Down in Sunny Tennessee   \n",
       "1  MT0000011357                    Dismember              Reborn in Blasphemy   \n",
       "2  MT0000011975  Curse of the Golden Vampire              Ultrasonic Meltdown   \n",
       "3  MT0000040632                  Gipsy Kings             Flamencos en el Aire   \n",
       "4  MT0000044741                Little Walter                       Last Night   \n",
       "\n",
       "  Quadrant     PQuad  MoodsTotal  Moods  \\\n",
       "0       Q3  0.666667           3      3   \n",
       "1       Q2  0.666667           3      3   \n",
       "2       Q2  0.666667           6      5   \n",
       "3       Q1  0.750000           4      3   \n",
       "4       Q3  0.750000           4      4   \n",
       "\n",
       "                                  MoodsFoundStr  \\\n",
       "0                       circular; greasy; messy   \n",
       "1                    jittery; negative; nervous   \n",
       "2  fierce; harsh; hostile; menacing; outrageous   \n",
       "3                            fiery; sexy; spicy   \n",
       "4                   greasy; gritty; gutsy; lazy   \n",
       "\n",
       "                                            MoodsStr  \\\n",
       "0                            Circular; Greasy; Messy   \n",
       "1                          Negative; Nervous/Jittery   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy   \n",
       "\n",
       "                                       MoodsStrSplit  Genres  \\\n",
       "0                            Circular; Greasy; Messy       2   \n",
       "1                         Negative; Nervous; Jittery       3   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...       1   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy       2   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy       1   \n",
       "\n",
       "                             GenresStr  Sample  \\\n",
       "0               Country; International       1   \n",
       "1  Electronic; International; Pop/Rock       1   \n",
       "2                           Electronic       1   \n",
       "3                  International; Jazz       1   \n",
       "4                                Blues       1   \n",
       "\n",
       "                                           SampleURL  \n",
       "0  http://rovimusic.rovicorp.com/playback.mp3?c=l...  \n",
       "1  http://rovimusic.rovicorp.com/playback.mp3?c=0...  \n",
       "2  http://rovimusic.rovicorp.com/playback.mp3?c=_...  \n",
       "3  http://rovimusic.rovicorp.com/playback.mp3?c=G...  \n",
       "4  http://rovimusic.rovicorp.com/playback.mp3?c=k...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b60345c-fb1f-49a1-9b87-36a731e9f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df['Artist'] = music_df['Artist'].isna().fillna('no_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae158a-bd68-4f09-9769-20ee3283a9be",
   "metadata": {},
   "source": [
    "# Извлечение хромограммы и составление датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9448961d-c762-49e9-a703-771e5a295b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 900 файлов.\n",
      "Форма массива хромаграмм: (900, 60)\n"
     ]
    }
   ],
   "source": [
    "# Папка с аудиофайлами\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "\n",
    "# Список для хранения хромаграмм\n",
    "chroma_list = []\n",
    "file_names = []\n",
    "\n",
    "for file in files:\n",
    "    # Загружаем аудиофайл\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "    \n",
    "    # Вычисляем хромаграмму CQT с широкой шкалой частот (охватывает около 60 нот)\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr, bins_per_octave=60, n_chroma=60)\n",
    "    \n",
    "    # Сохраняем средние значения хромаграммы по времени\n",
    "    chroma_list.append(chroma.mean(axis=1))\n",
    "    file_names.append(file)\n",
    "\n",
    "# Конвертация результатов в массив numpy\n",
    "chroma_array = np.array(chroma_list)\n",
    "\n",
    "# Вывод информации о полученных данных\n",
    "print(f'Обработано {len(chroma_list)} файлов.')\n",
    "print(f'Форма массива хромаграмм: {chroma_array.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40cf82e0-40dd-446c-9cb0-d538530759ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_df = pd.DataFrame(chroma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a361310a-1d94-49e4-aeea-646246e61c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443772</td>\n",
       "      <td>0.323246</td>\n",
       "      <td>0.273419</td>\n",
       "      <td>0.265752</td>\n",
       "      <td>0.279812</td>\n",
       "      <td>0.307410</td>\n",
       "      <td>0.343295</td>\n",
       "      <td>0.381698</td>\n",
       "      <td>0.404105</td>\n",
       "      <td>0.539922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421216</td>\n",
       "      <td>0.341251</td>\n",
       "      <td>0.295385</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>0.248288</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.258989</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>0.415222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533384</td>\n",
       "      <td>0.551730</td>\n",
       "      <td>0.486165</td>\n",
       "      <td>0.418510</td>\n",
       "      <td>0.421176</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.399229</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387055</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.393433</td>\n",
       "      <td>0.411496</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.450908</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>0.442369</td>\n",
       "      <td>0.451103</td>\n",
       "      <td>0.466110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370861</td>\n",
       "      <td>0.397420</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>0.763953</td>\n",
       "      <td>0.719482</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.424701</td>\n",
       "      <td>0.370711</td>\n",
       "      <td>0.414319</td>\n",
       "      <td>0.466448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411753</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>0.353964</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.327530</td>\n",
       "      <td>0.313331</td>\n",
       "      <td>0.297589</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.339963</td>\n",
       "      <td>0.299659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175796</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.199381</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.432433</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>0.387899</td>\n",
       "      <td>0.216214</td>\n",
       "      <td>0.171414</td>\n",
       "      <td>0.162288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343376</td>\n",
       "      <td>0.421373</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.486496</td>\n",
       "      <td>0.377427</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>0.205623</td>\n",
       "      <td>0.181390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377437</td>\n",
       "      <td>0.388933</td>\n",
       "      <td>0.373309</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.387285</td>\n",
       "      <td>0.347906</td>\n",
       "      <td>0.295515</td>\n",
       "      <td>0.254130</td>\n",
       "      <td>0.288449</td>\n",
       "      <td>0.452692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.261255</td>\n",
       "      <td>0.306224</td>\n",
       "      <td>0.348963</td>\n",
       "      <td>0.391604</td>\n",
       "      <td>0.376148</td>\n",
       "      <td>0.348385</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.358920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.443772  0.323246  0.273419  0.265752  0.279812  0.307410  0.343295   \n",
       "1  0.533384  0.551730  0.486165  0.418510  0.421176  0.409938  0.397159   \n",
       "2  0.370861  0.397420  0.526688  0.763953  0.719482  0.561702  0.424701   \n",
       "3  0.175796  0.178800  0.199381  0.257791  0.432433  0.538870  0.387899   \n",
       "4  0.377437  0.388933  0.373309  0.384422  0.387285  0.347906  0.295515   \n",
       "\n",
       "         7         8         9   ...        50        51        52        53  \\\n",
       "0  0.381698  0.404105  0.539922  ...  0.421216  0.341251  0.295385  0.290910   \n",
       "1  0.399229  0.386361  0.376404  ...  0.387055  0.405054  0.393433  0.411496   \n",
       "2  0.370711  0.414319  0.466448  ...  0.411753  0.415309  0.353964  0.319828   \n",
       "3  0.216214  0.171414  0.162288  ...  0.343376  0.421373  0.454371  0.432721   \n",
       "4  0.254130  0.288449  0.452692  ...  0.231400  0.261255  0.306224  0.348963   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.248288  0.263075  0.273234  0.258989  0.300271  0.415222  \n",
       "1  0.413557  0.450908  0.445248  0.442369  0.451103  0.466110  \n",
       "2  0.327530  0.313331  0.297589  0.313480  0.339963  0.299659  \n",
       "3  0.456311  0.486496  0.377427  0.250039  0.205623  0.181390  \n",
       "4  0.391604  0.376148  0.348385  0.331108  0.353600  0.358920  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f77bf451-ca71-4d48-8c3e-ee208c954870",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([chroma_df, pd.Series(file_names, name='Song')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ac8db30-2cdf-4ce3-b0d1-d78bfc880876",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Song'] = combined_df['Song'].str[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a1717ce-944e-4126-aafc-4eb519e823b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.443772</td>\n",
       "      <td>0.323246</td>\n",
       "      <td>0.273419</td>\n",
       "      <td>0.265752</td>\n",
       "      <td>0.279812</td>\n",
       "      <td>0.307410</td>\n",
       "      <td>0.343295</td>\n",
       "      <td>0.381698</td>\n",
       "      <td>0.404105</td>\n",
       "      <td>0.539922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341251</td>\n",
       "      <td>0.295385</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>0.248288</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.258989</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>0.415222</td>\n",
       "      <td>MT0000004637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533384</td>\n",
       "      <td>0.551730</td>\n",
       "      <td>0.486165</td>\n",
       "      <td>0.418510</td>\n",
       "      <td>0.421176</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.399229</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.393433</td>\n",
       "      <td>0.411496</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.450908</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>0.442369</td>\n",
       "      <td>0.451103</td>\n",
       "      <td>0.466110</td>\n",
       "      <td>MT0000011357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370861</td>\n",
       "      <td>0.397420</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>0.763953</td>\n",
       "      <td>0.719482</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.424701</td>\n",
       "      <td>0.370711</td>\n",
       "      <td>0.414319</td>\n",
       "      <td>0.466448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>0.353964</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.327530</td>\n",
       "      <td>0.313331</td>\n",
       "      <td>0.297589</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.339963</td>\n",
       "      <td>0.299659</td>\n",
       "      <td>MT0000011975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175796</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.199381</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.432433</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>0.387899</td>\n",
       "      <td>0.216214</td>\n",
       "      <td>0.171414</td>\n",
       "      <td>0.162288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421373</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.486496</td>\n",
       "      <td>0.377427</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>0.205623</td>\n",
       "      <td>0.181390</td>\n",
       "      <td>MT0000040632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377437</td>\n",
       "      <td>0.388933</td>\n",
       "      <td>0.373309</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.387285</td>\n",
       "      <td>0.347906</td>\n",
       "      <td>0.295515</td>\n",
       "      <td>0.254130</td>\n",
       "      <td>0.288449</td>\n",
       "      <td>0.452692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261255</td>\n",
       "      <td>0.306224</td>\n",
       "      <td>0.348963</td>\n",
       "      <td>0.391604</td>\n",
       "      <td>0.376148</td>\n",
       "      <td>0.348385</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.358920</td>\n",
       "      <td>MT0000044741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.443772  0.323246  0.273419  0.265752  0.279812  0.307410  0.343295   \n",
       "1  0.533384  0.551730  0.486165  0.418510  0.421176  0.409938  0.397159   \n",
       "2  0.370861  0.397420  0.526688  0.763953  0.719482  0.561702  0.424701   \n",
       "3  0.175796  0.178800  0.199381  0.257791  0.432433  0.538870  0.387899   \n",
       "4  0.377437  0.388933  0.373309  0.384422  0.387285  0.347906  0.295515   \n",
       "\n",
       "          7         8         9  ...        51        52        53        54  \\\n",
       "0  0.381698  0.404105  0.539922  ...  0.341251  0.295385  0.290910  0.248288   \n",
       "1  0.399229  0.386361  0.376404  ...  0.405054  0.393433  0.411496  0.413557   \n",
       "2  0.370711  0.414319  0.466448  ...  0.415309  0.353964  0.319828  0.327530   \n",
       "3  0.216214  0.171414  0.162288  ...  0.421373  0.454371  0.432721  0.456311   \n",
       "4  0.254130  0.288449  0.452692  ...  0.261255  0.306224  0.348963  0.391604   \n",
       "\n",
       "         55        56        57        58        59          Song  \n",
       "0  0.263075  0.273234  0.258989  0.300271  0.415222  MT0000004637  \n",
       "1  0.450908  0.445248  0.442369  0.451103  0.466110  MT0000011357  \n",
       "2  0.313331  0.297589  0.313480  0.339963  0.299659  MT0000011975  \n",
       "3  0.486496  0.377427  0.250039  0.205623  0.181390  MT0000040632  \n",
       "4  0.376148  0.348385  0.331108  0.353600  0.358920  MT0000044741  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a6270aa-980b-4022-81b5-3afae9392d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(music_df, combined_df, on='Song', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "383b0573-6241-41fb-aa60-4aad1c0f5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>PQuad</th>\n",
       "      <th>MoodsTotal</th>\n",
       "      <th>Moods</th>\n",
       "      <th>MoodsFoundStr</th>\n",
       "      <th>MoodsStr</th>\n",
       "      <th>MoodsStrSplit</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>Charlie Poole</td>\n",
       "      <td>Bulldog Down in Sunny Tennessee</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>circular; greasy; messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421216</td>\n",
       "      <td>0.341251</td>\n",
       "      <td>0.295385</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>0.248288</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.258989</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>0.415222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT0000011357</td>\n",
       "      <td>Dismember</td>\n",
       "      <td>Reborn in Blasphemy</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>jittery; negative; nervous</td>\n",
       "      <td>Negative; Nervous/Jittery</td>\n",
       "      <td>Negative; Nervous; Jittery</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387055</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.393433</td>\n",
       "      <td>0.411496</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.450908</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>0.442369</td>\n",
       "      <td>0.451103</td>\n",
       "      <td>0.466110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT0000011975</td>\n",
       "      <td>Curse of the Golden Vampire</td>\n",
       "      <td>Ultrasonic Meltdown</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>fierce; harsh; hostile; menacing; outrageous</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411753</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>0.353964</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.327530</td>\n",
       "      <td>0.313331</td>\n",
       "      <td>0.297589</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.339963</td>\n",
       "      <td>0.299659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT0000040632</td>\n",
       "      <td>Gipsy Kings</td>\n",
       "      <td>Flamencos en el Aire</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>fiery; sexy; spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343376</td>\n",
       "      <td>0.421373</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.486496</td>\n",
       "      <td>0.377427</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>0.205623</td>\n",
       "      <td>0.181390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT0000044741</td>\n",
       "      <td>Little Walter</td>\n",
       "      <td>Last Night</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>greasy; gritty; gutsy; lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.261255</td>\n",
       "      <td>0.306224</td>\n",
       "      <td>0.348963</td>\n",
       "      <td>0.391604</td>\n",
       "      <td>0.376148</td>\n",
       "      <td>0.348385</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.358920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song                       Artist                            Title  \\\n",
       "0  MT0000004637                Charlie Poole  Bulldog Down in Sunny Tennessee   \n",
       "1  MT0000011357                    Dismember              Reborn in Blasphemy   \n",
       "2  MT0000011975  Curse of the Golden Vampire              Ultrasonic Meltdown   \n",
       "3  MT0000040632                  Gipsy Kings             Flamencos en el Aire   \n",
       "4  MT0000044741                Little Walter                       Last Night   \n",
       "\n",
       "  Quadrant     PQuad  MoodsTotal  Moods  \\\n",
       "0       Q3  0.666667           3      3   \n",
       "1       Q2  0.666667           3      3   \n",
       "2       Q2  0.666667           6      5   \n",
       "3       Q1  0.750000           4      3   \n",
       "4       Q3  0.750000           4      4   \n",
       "\n",
       "                                  MoodsFoundStr  \\\n",
       "0                       circular; greasy; messy   \n",
       "1                    jittery; negative; nervous   \n",
       "2  fierce; harsh; hostile; menacing; outrageous   \n",
       "3                            fiery; sexy; spicy   \n",
       "4                   greasy; gritty; gutsy; lazy   \n",
       "\n",
       "                                            MoodsStr  \\\n",
       "0                            Circular; Greasy; Messy   \n",
       "1                          Negative; Nervous/Jittery   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy   \n",
       "\n",
       "                                       MoodsStrSplit  ...        50        51  \\\n",
       "0                            Circular; Greasy; Messy  ...  0.421216  0.341251   \n",
       "1                         Negative; Nervous; Jittery  ...  0.387055  0.405054   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...  ...  0.411753  0.415309   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy  ...  0.343376  0.421373   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy  ...  0.231400  0.261255   \n",
       "\n",
       "         52        53        54        55        56        57        58  \\\n",
       "0  0.295385  0.290910  0.248288  0.263075  0.273234  0.258989  0.300271   \n",
       "1  0.393433  0.411496  0.413557  0.450908  0.445248  0.442369  0.451103   \n",
       "2  0.353964  0.319828  0.327530  0.313331  0.297589  0.313480  0.339963   \n",
       "3  0.454371  0.432721  0.456311  0.486496  0.377427  0.250039  0.205623   \n",
       "4  0.306224  0.348963  0.391604  0.376148  0.348385  0.331108  0.353600   \n",
       "\n",
       "         59  \n",
       "0  0.415222  \n",
       "1  0.466110  \n",
       "2  0.299659  \n",
       "3  0.181390  \n",
       "4  0.358920  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62805a46-5c43-449f-baa2-e8e2d11db55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.443772</td>\n",
       "      <td>0.323246</td>\n",
       "      <td>0.273419</td>\n",
       "      <td>0.265752</td>\n",
       "      <td>0.279812</td>\n",
       "      <td>0.307410</td>\n",
       "      <td>0.343295</td>\n",
       "      <td>0.381698</td>\n",
       "      <td>0.404105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421216</td>\n",
       "      <td>0.341251</td>\n",
       "      <td>0.295385</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>0.248288</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.273234</td>\n",
       "      <td>0.258989</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>0.415222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.533384</td>\n",
       "      <td>0.551730</td>\n",
       "      <td>0.486165</td>\n",
       "      <td>0.418510</td>\n",
       "      <td>0.421176</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.397159</td>\n",
       "      <td>0.399229</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387055</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.393433</td>\n",
       "      <td>0.411496</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.450908</td>\n",
       "      <td>0.445248</td>\n",
       "      <td>0.442369</td>\n",
       "      <td>0.451103</td>\n",
       "      <td>0.466110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.370861</td>\n",
       "      <td>0.397420</td>\n",
       "      <td>0.526688</td>\n",
       "      <td>0.763953</td>\n",
       "      <td>0.719482</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.424701</td>\n",
       "      <td>0.370711</td>\n",
       "      <td>0.414319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411753</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>0.353964</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.327530</td>\n",
       "      <td>0.313331</td>\n",
       "      <td>0.297589</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.339963</td>\n",
       "      <td>0.299659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>0.175796</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.199381</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.432433</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>0.387899</td>\n",
       "      <td>0.216214</td>\n",
       "      <td>0.171414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343376</td>\n",
       "      <td>0.421373</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>0.432721</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.486496</td>\n",
       "      <td>0.377427</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>0.205623</td>\n",
       "      <td>0.181390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.377437</td>\n",
       "      <td>0.388933</td>\n",
       "      <td>0.373309</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.387285</td>\n",
       "      <td>0.347906</td>\n",
       "      <td>0.295515</td>\n",
       "      <td>0.254130</td>\n",
       "      <td>0.288449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.261255</td>\n",
       "      <td>0.306224</td>\n",
       "      <td>0.348963</td>\n",
       "      <td>0.391604</td>\n",
       "      <td>0.376148</td>\n",
       "      <td>0.348385</td>\n",
       "      <td>0.331108</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.358920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quadrant         0         1         2         3         4         5  \\\n",
       "0       Q3  0.443772  0.323246  0.273419  0.265752  0.279812  0.307410   \n",
       "1       Q2  0.533384  0.551730  0.486165  0.418510  0.421176  0.409938   \n",
       "2       Q2  0.370861  0.397420  0.526688  0.763953  0.719482  0.561702   \n",
       "3       Q1  0.175796  0.178800  0.199381  0.257791  0.432433  0.538870   \n",
       "4       Q3  0.377437  0.388933  0.373309  0.384422  0.387285  0.347906   \n",
       "\n",
       "          6         7         8  ...        50        51        52        53  \\\n",
       "0  0.343295  0.381698  0.404105  ...  0.421216  0.341251  0.295385  0.290910   \n",
       "1  0.397159  0.399229  0.386361  ...  0.387055  0.405054  0.393433  0.411496   \n",
       "2  0.424701  0.370711  0.414319  ...  0.411753  0.415309  0.353964  0.319828   \n",
       "3  0.387899  0.216214  0.171414  ...  0.343376  0.421373  0.454371  0.432721   \n",
       "4  0.295515  0.254130  0.288449  ...  0.231400  0.261255  0.306224  0.348963   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.248288  0.263075  0.273234  0.258989  0.300271  0.415222  \n",
       "1  0.413557  0.450908  0.445248  0.442369  0.451103  0.466110  \n",
       "2  0.327530  0.313331  0.297589  0.313480  0.339963  0.299659  \n",
       "3  0.456311  0.486496  0.377427  0.250039  0.205623  0.181390  \n",
       "4  0.391604  0.376148  0.348385  0.331108  0.353600  0.358920  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = merged_df[['Quadrant'] + list(merged_df.columns[-60:])]\n",
    "#merged_df = pd.concat(merged_df['Quadrant'], combined_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d5732-4039-4ffc-977a-7f6a392bd29d",
   "metadata": {},
   "source": [
    "# Разделене выборки на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0b4ab9b-1aa8-4d4d-9719-6154e99d4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('Quadrant',axis=1)\n",
    "y = final_df['Quadrant']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4a91ceb-9e83-48fd-8fa6-8ef38e4aa124",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scal_X_train = scaler.fit_transform(X_train)\n",
    "scal_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499cf4d-8378-400e-bb4e-98d77fdc2447",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfdc729d-6569-4ce3-9528-518f127d67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=[128, 140, 150, 200]\n",
    "max_features= [3,4,5]\n",
    "bootstrap = [True]\n",
    "oob_score = [True]\n",
    "criterion =['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4ebbe82-118c-45cc-ab97-522d8935adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':n_estimators,\n",
    "             'max_features':max_features,\n",
    "             'bootstrap':bootstrap,\n",
    "             'oob_score':oob_score,\n",
    "             'criterion': criterion,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d09a4d85-4f8f-4ea4-9846-e8267634dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc_grid = GridSearchCV(rfc,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d572437-09ab-40e1-800a-91e5dcfbf82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True], &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [128, 140, 150, 200],\n",
       "                         &#x27;oob_score&#x27;: [True]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True], &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [128, 140, 150, 200],\n",
       "                         &#x27;oob_score&#x27;: [True]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True], 'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': [3, 4, 5],\n",
       "                         'n_estimators': [128, 140, 150, 200],\n",
       "                         'oob_score': [True]})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "271ee3ee-0e66-4fe6-be41-3f6750e313c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'gini',\n",
       " 'max_features': 4,\n",
       " 'n_estimators': 150,\n",
       " 'oob_score': True}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3823969e-fe48-46e3-9ce7-0321b159512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e41e5df1-8efa-4ddb-b801-2ca3692001a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.54      0.45      0.49        42\n",
      "          Q2       0.61      0.62      0.62        32\n",
      "          Q3       0.70      0.52      0.60        44\n",
      "          Q4       0.35      0.71      0.47        17\n",
      "\n",
      "    accuracy                           0.55       135\n",
      "   macro avg       0.55      0.58      0.54       135\n",
      "weighted avg       0.58      0.55      0.55       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rfc_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c865c097-1432-4608-ba6f-7cd09e49aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e294836810>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test,rfc_pred)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1a92e-7b8e-4cdf-8864-35bc925ac8ac",
   "metadata": {},
   "source": [
    "# RandomForestClassifier подбор параметров halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3362421e-7c58-4ef8-b8e5-766bfa2b8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 136, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 60, 'max_depth': 45}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "# Определяем пространство гиперпараметров\n",
    "param_dist = {\n",
    "    'n_estimators': np.linspace(10, 200, 10, dtype=int),\n",
    "    'max_features': np.linspace(1, X_train.shape[1], 5, dtype=int),\n",
    "    'max_depth': [None] + list(np.linspace(5, 50, 10, dtype=int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Создаём классификатор\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Запускаем HalvingRandomSearchCV\n",
    "halving_rs = HalvingRandomSearchCV(\n",
    "    clf, param_dist, factor=3,  # Оставляем треть лучших на каждой итерации\n",
    "    resource='n_samples', min_resources=30,\n",
    "    cv=3, random_state=42\n",
    ")\n",
    "halving_rs.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"Лучшие параметры:\", halving_rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c41510d-2e13-4a73-b9f7-ef46641b4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=136, min_samples_split=5, min_samples_leaf=1, max_features=60, max_depth=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "587a89fd-b5df-49fa-a4d6-b66d8c14c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pred = halving_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e717ded5-eedb-40f9-a28d-8483cac0f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.46      0.44      0.45        36\n",
      "          Q2       0.55      0.51      0.53        35\n",
      "          Q3       0.64      0.46      0.53        46\n",
      "          Q4       0.32      0.61      0.42        18\n",
      "\n",
      "    accuracy                           0.49       135\n",
      "   macro avg       0.49      0.51      0.48       135\n",
      "weighted avg       0.52      0.49      0.50       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(clf_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4b9664-5ce6-45ef-ae19-bc9d0114be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae8251-b866-481d-90f7-aa0d563a2e27",
   "metadata": {},
   "source": [
    "# CatBoostClassifier halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "081bcc01-95da-4590-97dc-936843aa8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "47b7be61-01df-4e5f-819f-5bcca85fe5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'learning_rate': 0.005623413251903491, 'l2_leaf_reg': 0.1, 'iterations': 550, 'depth': 4, 'border_count': 143}\n",
      "Accuracy: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Создаём модель CatBoost (без предобучения)\n",
    "clf = CatBoostClassifier(\n",
    "    verbose=0,  # Отключаем вывод во время обучения\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Определяем пространство гиперпараметров\n",
    "param_dist = {\n",
    "    'iterations': np.linspace(100, 1000, 5, dtype=int),\n",
    "    'learning_rate': np.logspace(-3, 0, 5),\n",
    "    'depth': np.arange(4, 11),\n",
    "    'l2_leaf_reg': np.logspace(-2, 2, 5),\n",
    "    'border_count': np.linspace(32, 255, 5, dtype=int)\n",
    "}\n",
    "\n",
    "# Запускаем HalvingRandomSearchCV\n",
    "halving_rs = HalvingRandomSearchCV(\n",
    "    clf, param_dist, factor=3,  \n",
    "    resource='n_samples', min_resources=30,\n",
    "    cv=3, random_state=42\n",
    ")\n",
    "\n",
    "# Обучаем модель\n",
    "halving_rs.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"Лучшие параметры:\", halving_rs.best_params_)\n",
    "\n",
    "# Оцениваем модель\n",
    "best_model = halving_rs.best_estimator_\n",
    "print(\"Accuracy:\", best_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c3bc539-30ab-4e9a-8571-cb7443c04da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_halving = CatBoostClassifier(learning_rate=0.005623413251903491, l2_leaf_reg=0.1, iterations=550, depth=4, border_count=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13091c17-3d76-472d-a54e-02c33176f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_halving_pred = halving_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c535535b-f070-4715-8387-8cd0eb1fdc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.46      0.44      0.45        36\n",
      "          Q2       0.55      0.51      0.53        35\n",
      "          Q3       0.64      0.46      0.53        46\n",
      "          Q4       0.32      0.61      0.42        18\n",
      "\n",
      "    accuracy                           0.49       135\n",
      "   macro avg       0.49      0.51      0.48       135\n",
      "weighted avg       0.52      0.49      0.50       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cbc_halving_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b8e31-cc0e-4148-945d-cbdf62e9039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a241839-e13d-4848-9f03-6f4591d8ab19",
   "metadata": {},
   "source": [
    "# ПРОБУЮ ДРУГОЙ ПОДХОД"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57b3c1-e9d6-49a8-96df-ae7d8bdf8b1a",
   "metadata": {},
   "source": [
    "# Только хромограмма 3-х видов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2975f4cd-8b06-4801-888f-548702d8a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 900 файлов.\n",
      "Форма массива хромаграмм: (900, 336)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Папка с аудиофайлами\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "\n",
    "# Списки для хранения признаков и имен файлов\n",
    "chroma_features_list = []\n",
    "file_names = []\n",
    "\n",
    "for file in files:\n",
    "    # Загружаем аудиофайл\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "\n",
    "    # 🔹 1. Хромаграмма CQT (широкий частотный диапазон)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr, bins_per_octave=60, n_chroma=60)\n",
    "    \n",
    "    # 🔹 2. Хромаграмма STFT (учитывает динамику атаки)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "    # 🔹 3. Хромаграмма CENS (устойчива к шуму)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "\n",
    "    # 🔹 4. Логарифмирование хромаграмм (чтобы выделить слабые ноты)\n",
    "    chroma_cqt = np.log1p(chroma_cqt)\n",
    "    chroma_stft = np.log1p(chroma_stft)\n",
    "    chroma_cens = np.log1p(chroma_cens)\n",
    "\n",
    "    # 🔹 5. Вычисляем статистики по каждой хромаграмме\n",
    "    def extract_statistics(feature):\n",
    "        return np.hstack([\n",
    "            np.mean(feature, axis=1),    # Среднее\n",
    "            np.std(feature, axis=1),     # Стандартное отклонение\n",
    "            np.median(feature, axis=1),  # Медиана\n",
    "            np.max(feature, axis=1) - np.min(feature, axis=1)  # Размах\n",
    "        ])\n",
    "\n",
    "    chroma_cqt_stats = extract_statistics(chroma_cqt)\n",
    "    chroma_stft_stats = extract_statistics(chroma_stft)\n",
    "    chroma_cens_stats = extract_statistics(chroma_cens)\n",
    "\n",
    "    # 🔹 6. Объединяем все статистики в единый вектор\n",
    "    chroma_features = np.hstack([chroma_cqt_stats, chroma_stft_stats, chroma_cens_stats])\n",
    "\n",
    "    # Добавляем в список\n",
    "    chroma_features_list.append(chroma_features)\n",
    "    file_names.append(file)\n",
    "\n",
    "# Преобразуем в numpy массив\n",
    "chroma_array = np.array(chroma_features_list)\n",
    "\n",
    "# 🔹 7. Нормализация признаков (ускоряет обучение моделей)\n",
    "scaler = StandardScaler()\n",
    "chroma_array_scaled = scaler.fit_transform(chroma_array)\n",
    "\n",
    "# Вывод информации о данных\n",
    "print(f'Обработано {len(chroma_features_list)} файлов.')\n",
    "print(f'Форма массива хромаграмм: {chroma_array_scaled.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1426ba55-f5cc-4c28-a28e-bdb7bc02197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_df = pd.DataFrame(chroma_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07498d8f-3d83-468e-adc7-6afac4fe5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\cqt_stft_cens_chromas_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da3191-5ff7-4c64-a8a9-3ceeb0355f79",
   "metadata": {},
   "source": [
    "# Только mfcc и mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ce253c-d362-4115-8548-6776693eaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_list = []\n",
    "mfcc_list = []\n",
    "file_names = []\n",
    "\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')   \n",
    "\n",
    "for file in files:\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "\n",
    "    # Вычисляем Mel-спектрограмму\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    mel_list.append(mel.mean(axis=1))\n",
    "\n",
    "    # Вычисляем MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    mfcc_list.append(mfcc.mean(axis=1))\n",
    "\n",
    "    file_names.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0923806-90d0-4857-a9d0-2e74ef9b01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df = pd.DataFrame(mfcc_list)\n",
    "mel_df = pd.DataFrame(mel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91d44d3-de39-4da7-91cf-38a447a1ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\mfcc_df.csv')\n",
    "mel_df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\mel_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8df48-d8d9-417f-adb2-ac5eca22cb20",
   "metadata": {},
   "source": [
    "# Темп "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dffe883c-df55-4067-95d2-17270dcdf63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 900 файлов.\n",
      "Форма Tempo: (900, 1)\n"
     ]
    }
   ],
   "source": [
    "tempo_list = []\n",
    "file_names = []\n",
    "\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "\n",
    "for file in files:\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "\n",
    "    # Вычисляем темп (BPM)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    tempo_list.append(tempo)  # Добавляем темп в список\n",
    "\n",
    "    file_names.append(file)\n",
    "    \n",
    "tempo_df = pd.DataFrame(tempo_list)\n",
    "\n",
    "# Выводим информацию\n",
    "print(f'Обработано {len(file_names)} файлов.')\n",
    "print(f'Форма Tempo: {tempo_df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f1b02-c5b9-461a-970f-6846e3ade9f4",
   "metadata": {},
   "source": [
    "# Итоговый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8f6468c9-6285-4861-97a6-753305b56a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt_stft_cens_chromas_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/cqt_stft_cens_chromas_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "91e43915-7c91-4983-bc71-5edb85456bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/mel_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac0a2cd1-6050-4d9c-83b9-e36d3522121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/mfcc_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a335e837-dd4d-44bb-8743-8ee8cb6f2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([cqt_stft_cens_chromas_df, mel_df, mfcc_df, tempo_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "13a2c507-3544-4eb1-bd91-c279964334ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9aeffe0d-ff6f-4e41-9637-3c24ef963fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344369</td>\n",
       "      <td>0.267671</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.236617</td>\n",
       "      <td>0.256444</td>\n",
       "      <td>0.282879</td>\n",
       "      <td>0.309561</td>\n",
       "      <td>0.325702</td>\n",
       "      <td>0.414427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>2.324166</td>\n",
       "      <td>3.567792</td>\n",
       "      <td>3.883560</td>\n",
       "      <td>-1.823020</td>\n",
       "      <td>-2.058319</td>\n",
       "      <td>-5.530811</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-2.063657</td>\n",
       "      <td>163.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413149</td>\n",
       "      <td>0.422476</td>\n",
       "      <td>0.382707</td>\n",
       "      <td>0.338075</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.332445</td>\n",
       "      <td>0.323744</td>\n",
       "      <td>0.324923</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>0.309919</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.688632</td>\n",
       "      <td>-3.825361</td>\n",
       "      <td>-0.613288</td>\n",
       "      <td>-3.535904</td>\n",
       "      <td>-4.854705</td>\n",
       "      <td>-1.428813</td>\n",
       "      <td>-8.155371</td>\n",
       "      <td>0.105861</td>\n",
       "      <td>-4.854570</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.310428</td>\n",
       "      <td>0.328462</td>\n",
       "      <td>0.413456</td>\n",
       "      <td>0.555491</td>\n",
       "      <td>0.530212</td>\n",
       "      <td>0.436717</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.308844</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.085293</td>\n",
       "      <td>-2.503842</td>\n",
       "      <td>-4.341682</td>\n",
       "      <td>-2.598336</td>\n",
       "      <td>-3.895138</td>\n",
       "      <td>-0.943562</td>\n",
       "      <td>-4.858965</td>\n",
       "      <td>0.452470</td>\n",
       "      <td>-4.311635</td>\n",
       "      <td>101.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.161369</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.220572</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.407468</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.147535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663398</td>\n",
       "      <td>-3.054370</td>\n",
       "      <td>-3.469282</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>-2.130995</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>-1.407931</td>\n",
       "      <td>4.732381</td>\n",
       "      <td>-2.828623</td>\n",
       "      <td>98.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.319286</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.314276</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.250883</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719656</td>\n",
       "      <td>-4.388300</td>\n",
       "      <td>0.210486</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>-0.584419</td>\n",
       "      <td>3.384225</td>\n",
       "      <td>-4.916590</td>\n",
       "      <td>1.795105</td>\n",
       "      <td>-4.837695</td>\n",
       "      <td>66.964286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.344369  0.267671  0.231999  0.226553  0.236617  0.256444  0.282879   \n",
       "1  0.413149  0.422476  0.382707  0.338075  0.339839  0.332445  0.323744   \n",
       "2  0.310428  0.328462  0.413456  0.555491  0.530212  0.436717  0.347030   \n",
       "3  0.159420  0.161369  0.177484  0.220572  0.341637  0.407468  0.316527   \n",
       "4  0.311646  0.319286  0.308918  0.314276  0.316000  0.288682  0.250883   \n",
       "\n",
       "          7         8         9  ...        31        32        33        34  \\\n",
       "0  0.309561  0.325702  0.414427  ... -0.020307  2.324166  3.567792  3.883560   \n",
       "1  0.324923  0.316282  0.309919  ... -1.688632 -3.825361 -0.613288 -3.535904   \n",
       "2  0.308844  0.339200  0.370777  ... -2.085293 -2.503842 -4.341682 -2.598336   \n",
       "3  0.190813  0.155512  0.147535  ...  1.663398 -3.054370 -3.469282  0.551196   \n",
       "4  0.219238  0.244121  0.351694  ... -2.719656 -4.388300  0.210486  0.959180   \n",
       "\n",
       "         35        36        37        38        39           0  \n",
       "0 -1.823020 -2.058319 -5.530811 -2.079775 -2.063657  163.043478  \n",
       "1 -4.854705 -1.428813 -8.155371  0.105861 -4.854570  135.999178  \n",
       "2 -3.895138 -0.943562 -4.858965  0.452470 -4.311635  101.351351  \n",
       "3 -2.130995  1.955830 -1.407931  4.732381 -2.828623   98.684211  \n",
       "4 -0.584419  3.384225 -4.916590  1.795105 -4.837695   66.964286  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "006f2bb8-0f54-46ee-ad40-0807c2753ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.columns = range(df_combined.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82376cb0-f279-4e25-bf44-fefb591f2c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.344369\n",
       "1      0.413149\n",
       "2      0.310428\n",
       "3      0.159420\n",
       "4      0.311646\n",
       "         ...   \n",
       "895    0.447475\n",
       "896    0.401390\n",
       "897    0.361099\n",
       "898    0.225305\n",
       "899    0.499234\n",
       "Name: 0, Length: 900, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "54d1b512-26b1-4c3c-bebe-36d9aa08e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_df = df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "071ad7b3-1203-41e3-9907-f605ff3189f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/MER_audio_taffc_dataset/panda_dataset_taffc_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4373abd5-207e-4260-a7dd-c212eb60aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df['Artist'] = music_df['Artist'].isna().fillna('no_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4643d66a-eac4-4815-ad3b-19ae3c4a68c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344369</td>\n",
       "      <td>0.267671</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.236617</td>\n",
       "      <td>0.256444</td>\n",
       "      <td>0.282879</td>\n",
       "      <td>0.309561</td>\n",
       "      <td>0.325702</td>\n",
       "      <td>0.414427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>2.324166</td>\n",
       "      <td>3.567792</td>\n",
       "      <td>3.883560</td>\n",
       "      <td>-1.823020</td>\n",
       "      <td>-2.058319</td>\n",
       "      <td>-5.530811</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-2.063657</td>\n",
       "      <td>163.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413149</td>\n",
       "      <td>0.422476</td>\n",
       "      <td>0.382707</td>\n",
       "      <td>0.338075</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.332445</td>\n",
       "      <td>0.323744</td>\n",
       "      <td>0.324923</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>0.309919</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.688632</td>\n",
       "      <td>-3.825361</td>\n",
       "      <td>-0.613288</td>\n",
       "      <td>-3.535904</td>\n",
       "      <td>-4.854705</td>\n",
       "      <td>-1.428813</td>\n",
       "      <td>-8.155371</td>\n",
       "      <td>0.105861</td>\n",
       "      <td>-4.854570</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.310428</td>\n",
       "      <td>0.328462</td>\n",
       "      <td>0.413456</td>\n",
       "      <td>0.555491</td>\n",
       "      <td>0.530212</td>\n",
       "      <td>0.436717</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.308844</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.085293</td>\n",
       "      <td>-2.503842</td>\n",
       "      <td>-4.341682</td>\n",
       "      <td>-2.598336</td>\n",
       "      <td>-3.895138</td>\n",
       "      <td>-0.943562</td>\n",
       "      <td>-4.858965</td>\n",
       "      <td>0.452470</td>\n",
       "      <td>-4.311635</td>\n",
       "      <td>101.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.161369</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.220572</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.407468</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.147535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663398</td>\n",
       "      <td>-3.054370</td>\n",
       "      <td>-3.469282</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>-2.130995</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>-1.407931</td>\n",
       "      <td>4.732381</td>\n",
       "      <td>-2.828623</td>\n",
       "      <td>98.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.319286</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.314276</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.250883</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719656</td>\n",
       "      <td>-4.388300</td>\n",
       "      <td>0.210486</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>-0.584419</td>\n",
       "      <td>3.384225</td>\n",
       "      <td>-4.916590</td>\n",
       "      <td>1.795105</td>\n",
       "      <td>-4.837695</td>\n",
       "      <td>66.964286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.344369  0.267671  0.231999  0.226553  0.236617  0.256444  0.282879   \n",
       "1  0.413149  0.422476  0.382707  0.338075  0.339839  0.332445  0.323744   \n",
       "2  0.310428  0.328462  0.413456  0.555491  0.530212  0.436717  0.347030   \n",
       "3  0.159420  0.161369  0.177484  0.220572  0.341637  0.407468  0.316527   \n",
       "4  0.311646  0.319286  0.308918  0.314276  0.316000  0.288682  0.250883   \n",
       "\n",
       "        7         8         9    ...       497       498       499       500  \\\n",
       "0  0.309561  0.325702  0.414427  ... -0.020307  2.324166  3.567792  3.883560   \n",
       "1  0.324923  0.316282  0.309919  ... -1.688632 -3.825361 -0.613288 -3.535904   \n",
       "2  0.308844  0.339200  0.370777  ... -2.085293 -2.503842 -4.341682 -2.598336   \n",
       "3  0.190813  0.155512  0.147535  ...  1.663398 -3.054370 -3.469282  0.551196   \n",
       "4  0.219238  0.244121  0.351694  ... -2.719656 -4.388300  0.210486  0.959180   \n",
       "\n",
       "        501       502       503       504       505         506  \n",
       "0 -1.823020 -2.058319 -5.530811 -2.079775 -2.063657  163.043478  \n",
       "1 -4.854705 -1.428813 -8.155371  0.105861 -4.854570  135.999178  \n",
       "2 -3.895138 -0.943562 -4.858965  0.452470 -4.311635  101.351351  \n",
       "3 -2.130995  1.955830 -1.407931  4.732381 -2.828623   98.684211  \n",
       "4 -0.584419  3.384225 -4.916590  1.795105 -4.837695   66.964286  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95a2ca4a-559d-4b40-99d4-97a55cd682ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([chroma_df, pd.Series(file_names, name='Song')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c29718ea-8107-4e77-8fcf-776d81b0796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Song'] = combined_df['Song'].str[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3fb2f92b-24d4-425c-abda-3c04551fa8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344369</td>\n",
       "      <td>0.267671</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.236617</td>\n",
       "      <td>0.256444</td>\n",
       "      <td>0.282879</td>\n",
       "      <td>0.309561</td>\n",
       "      <td>0.325702</td>\n",
       "      <td>0.414427</td>\n",
       "      <td>...</td>\n",
       "      <td>2.324166</td>\n",
       "      <td>3.567792</td>\n",
       "      <td>3.883560</td>\n",
       "      <td>-1.823020</td>\n",
       "      <td>-2.058319</td>\n",
       "      <td>-5.530811</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-2.063657</td>\n",
       "      <td>163.043478</td>\n",
       "      <td>MT0000004637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413149</td>\n",
       "      <td>0.422476</td>\n",
       "      <td>0.382707</td>\n",
       "      <td>0.338075</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.332445</td>\n",
       "      <td>0.323744</td>\n",
       "      <td>0.324923</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>0.309919</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.825361</td>\n",
       "      <td>-0.613288</td>\n",
       "      <td>-3.535904</td>\n",
       "      <td>-4.854705</td>\n",
       "      <td>-1.428813</td>\n",
       "      <td>-8.155371</td>\n",
       "      <td>0.105861</td>\n",
       "      <td>-4.854570</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>MT0000011357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.310428</td>\n",
       "      <td>0.328462</td>\n",
       "      <td>0.413456</td>\n",
       "      <td>0.555491</td>\n",
       "      <td>0.530212</td>\n",
       "      <td>0.436717</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.308844</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503842</td>\n",
       "      <td>-4.341682</td>\n",
       "      <td>-2.598336</td>\n",
       "      <td>-3.895138</td>\n",
       "      <td>-0.943562</td>\n",
       "      <td>-4.858965</td>\n",
       "      <td>0.452470</td>\n",
       "      <td>-4.311635</td>\n",
       "      <td>101.351351</td>\n",
       "      <td>MT0000011975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.161369</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.220572</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.407468</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.147535</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.054370</td>\n",
       "      <td>-3.469282</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>-2.130995</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>-1.407931</td>\n",
       "      <td>4.732381</td>\n",
       "      <td>-2.828623</td>\n",
       "      <td>98.684211</td>\n",
       "      <td>MT0000040632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.319286</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.314276</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.250883</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.388300</td>\n",
       "      <td>0.210486</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>-0.584419</td>\n",
       "      <td>3.384225</td>\n",
       "      <td>-4.916590</td>\n",
       "      <td>1.795105</td>\n",
       "      <td>-4.837695</td>\n",
       "      <td>66.964286</td>\n",
       "      <td>MT0000044741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.344369  0.267671  0.231999  0.226553  0.236617  0.256444  0.282879   \n",
       "1  0.413149  0.422476  0.382707  0.338075  0.339839  0.332445  0.323744   \n",
       "2  0.310428  0.328462  0.413456  0.555491  0.530212  0.436717  0.347030   \n",
       "3  0.159420  0.161369  0.177484  0.220572  0.341637  0.407468  0.316527   \n",
       "4  0.311646  0.319286  0.308918  0.314276  0.316000  0.288682  0.250883   \n",
       "\n",
       "          7         8         9  ...       498       499       500       501  \\\n",
       "0  0.309561  0.325702  0.414427  ...  2.324166  3.567792  3.883560 -1.823020   \n",
       "1  0.324923  0.316282  0.309919  ... -3.825361 -0.613288 -3.535904 -4.854705   \n",
       "2  0.308844  0.339200  0.370777  ... -2.503842 -4.341682 -2.598336 -3.895138   \n",
       "3  0.190813  0.155512  0.147535  ... -3.054370 -3.469282  0.551196 -2.130995   \n",
       "4  0.219238  0.244121  0.351694  ... -4.388300  0.210486  0.959180 -0.584419   \n",
       "\n",
       "        502       503       504       505         506          Song  \n",
       "0 -2.058319 -5.530811 -2.079775 -2.063657  163.043478  MT0000004637  \n",
       "1 -1.428813 -8.155371  0.105861 -4.854570  135.999178  MT0000011357  \n",
       "2 -0.943562 -4.858965  0.452470 -4.311635  101.351351  MT0000011975  \n",
       "3  1.955830 -1.407931  4.732381 -2.828623   98.684211  MT0000040632  \n",
       "4  3.384225 -4.916590  1.795105 -4.837695   66.964286  MT0000044741  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8d354763-4bb8-4d2e-8e1f-b60e9e4f0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(music_df, combined_df, on='Song', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f83a4968-f91e-432d-9ac6-02c9252726ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>PQuad</th>\n",
       "      <th>MoodsTotal</th>\n",
       "      <th>Moods</th>\n",
       "      <th>MoodsFoundStr</th>\n",
       "      <th>MoodsStr</th>\n",
       "      <th>MoodsStrSplit</th>\n",
       "      <th>...</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>False</td>\n",
       "      <td>Bulldog Down in Sunny Tennessee</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>circular; greasy; messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>Circular; Greasy; Messy</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>2.324166</td>\n",
       "      <td>3.567792</td>\n",
       "      <td>3.883560</td>\n",
       "      <td>-1.823020</td>\n",
       "      <td>-2.058319</td>\n",
       "      <td>-5.530811</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-2.063657</td>\n",
       "      <td>163.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT0000011357</td>\n",
       "      <td>False</td>\n",
       "      <td>Reborn in Blasphemy</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>jittery; negative; nervous</td>\n",
       "      <td>Negative; Nervous/Jittery</td>\n",
       "      <td>Negative; Nervous; Jittery</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.688632</td>\n",
       "      <td>-3.825361</td>\n",
       "      <td>-0.613288</td>\n",
       "      <td>-3.535904</td>\n",
       "      <td>-4.854705</td>\n",
       "      <td>-1.428813</td>\n",
       "      <td>-8.155371</td>\n",
       "      <td>0.105861</td>\n",
       "      <td>-4.854570</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT0000011975</td>\n",
       "      <td>False</td>\n",
       "      <td>Ultrasonic Meltdown</td>\n",
       "      <td>Q2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>fierce; harsh; hostile; menacing; outrageous</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>Fierce; Harsh; Hostile; Menacing; Outrageous; ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.085293</td>\n",
       "      <td>-2.503842</td>\n",
       "      <td>-4.341682</td>\n",
       "      <td>-2.598336</td>\n",
       "      <td>-3.895138</td>\n",
       "      <td>-0.943562</td>\n",
       "      <td>-4.858965</td>\n",
       "      <td>0.452470</td>\n",
       "      <td>-4.311635</td>\n",
       "      <td>101.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT0000040632</td>\n",
       "      <td>False</td>\n",
       "      <td>Flamencos en el Aire</td>\n",
       "      <td>Q1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>fiery; sexy; spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>Cathartic; Fiery; Sexy; Spicy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663398</td>\n",
       "      <td>-3.054370</td>\n",
       "      <td>-3.469282</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>-2.130995</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>-1.407931</td>\n",
       "      <td>4.732381</td>\n",
       "      <td>-2.828623</td>\n",
       "      <td>98.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT0000044741</td>\n",
       "      <td>False</td>\n",
       "      <td>Last Night</td>\n",
       "      <td>Q3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>greasy; gritty; gutsy; lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>Greasy; Gritty; Gutsy; Lazy</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719656</td>\n",
       "      <td>-4.388300</td>\n",
       "      <td>0.210486</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>-0.584419</td>\n",
       "      <td>3.384225</td>\n",
       "      <td>-4.916590</td>\n",
       "      <td>1.795105</td>\n",
       "      <td>-4.837695</td>\n",
       "      <td>66.964286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song  Artist                            Title Quadrant     PQuad  \\\n",
       "0  MT0000004637   False  Bulldog Down in Sunny Tennessee       Q3  0.666667   \n",
       "1  MT0000011357   False              Reborn in Blasphemy       Q2  0.666667   \n",
       "2  MT0000011975   False              Ultrasonic Meltdown       Q2  0.666667   \n",
       "3  MT0000040632   False             Flamencos en el Aire       Q1  0.750000   \n",
       "4  MT0000044741   False                       Last Night       Q3  0.750000   \n",
       "\n",
       "   MoodsTotal  Moods                                 MoodsFoundStr  \\\n",
       "0           3      3                       circular; greasy; messy   \n",
       "1           3      3                    jittery; negative; nervous   \n",
       "2           6      5  fierce; harsh; hostile; menacing; outrageous   \n",
       "3           4      3                            fiery; sexy; spicy   \n",
       "4           4      4                   greasy; gritty; gutsy; lazy   \n",
       "\n",
       "                                            MoodsStr  \\\n",
       "0                            Circular; Greasy; Messy   \n",
       "1                          Negative; Nervous/Jittery   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy   \n",
       "\n",
       "                                       MoodsStrSplit  ...       497       498  \\\n",
       "0                            Circular; Greasy; Messy  ... -0.020307  2.324166   \n",
       "1                         Negative; Nervous; Jittery  ... -1.688632 -3.825361   \n",
       "2  Fierce; Harsh; Hostile; Menacing; Outrageous; ...  ... -2.085293 -2.503842   \n",
       "3                      Cathartic; Fiery; Sexy; Spicy  ...  1.663398 -3.054370   \n",
       "4                        Greasy; Gritty; Gutsy; Lazy  ... -2.719656 -4.388300   \n",
       "\n",
       "        499       500       501       502       503       504       505  \\\n",
       "0  3.567792  3.883560 -1.823020 -2.058319 -5.530811 -2.079775 -2.063657   \n",
       "1 -0.613288 -3.535904 -4.854705 -1.428813 -8.155371  0.105861 -4.854570   \n",
       "2 -4.341682 -2.598336 -3.895138 -0.943562 -4.858965  0.452470 -4.311635   \n",
       "3 -3.469282  0.551196 -2.130995  1.955830 -1.407931  4.732381 -2.828623   \n",
       "4  0.210486  0.959180 -0.584419  3.384225 -4.916590  1.795105 -4.837695   \n",
       "\n",
       "          506  \n",
       "0  163.043478  \n",
       "1  135.999178  \n",
       "2  101.351351  \n",
       "3   98.684211  \n",
       "4   66.964286  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0a7a9b18-6156-46fc-82a1-622ad804875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.344369</td>\n",
       "      <td>0.267671</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.236617</td>\n",
       "      <td>0.256444</td>\n",
       "      <td>0.282879</td>\n",
       "      <td>0.309561</td>\n",
       "      <td>0.325702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>2.324166</td>\n",
       "      <td>3.567792</td>\n",
       "      <td>3.883560</td>\n",
       "      <td>-1.823020</td>\n",
       "      <td>-2.058319</td>\n",
       "      <td>-5.530811</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-2.063657</td>\n",
       "      <td>163.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.413149</td>\n",
       "      <td>0.422476</td>\n",
       "      <td>0.382707</td>\n",
       "      <td>0.338075</td>\n",
       "      <td>0.339839</td>\n",
       "      <td>0.332445</td>\n",
       "      <td>0.323744</td>\n",
       "      <td>0.324923</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.688632</td>\n",
       "      <td>-3.825361</td>\n",
       "      <td>-0.613288</td>\n",
       "      <td>-3.535904</td>\n",
       "      <td>-4.854705</td>\n",
       "      <td>-1.428813</td>\n",
       "      <td>-8.155371</td>\n",
       "      <td>0.105861</td>\n",
       "      <td>-4.854570</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2</td>\n",
       "      <td>0.310428</td>\n",
       "      <td>0.328462</td>\n",
       "      <td>0.413456</td>\n",
       "      <td>0.555491</td>\n",
       "      <td>0.530212</td>\n",
       "      <td>0.436717</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.308844</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.085293</td>\n",
       "      <td>-2.503842</td>\n",
       "      <td>-4.341682</td>\n",
       "      <td>-2.598336</td>\n",
       "      <td>-3.895138</td>\n",
       "      <td>-0.943562</td>\n",
       "      <td>-4.858965</td>\n",
       "      <td>0.452470</td>\n",
       "      <td>-4.311635</td>\n",
       "      <td>101.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.161369</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.220572</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.407468</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663398</td>\n",
       "      <td>-3.054370</td>\n",
       "      <td>-3.469282</td>\n",
       "      <td>0.551196</td>\n",
       "      <td>-2.130995</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>-1.407931</td>\n",
       "      <td>4.732381</td>\n",
       "      <td>-2.828623</td>\n",
       "      <td>98.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.319286</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.314276</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.288682</td>\n",
       "      <td>0.250883</td>\n",
       "      <td>0.219238</td>\n",
       "      <td>0.244121</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719656</td>\n",
       "      <td>-4.388300</td>\n",
       "      <td>0.210486</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>-0.584419</td>\n",
       "      <td>3.384225</td>\n",
       "      <td>-4.916590</td>\n",
       "      <td>1.795105</td>\n",
       "      <td>-4.837695</td>\n",
       "      <td>66.964286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quadrant         0         1         2         3         4         5  \\\n",
       "0       Q3  0.344369  0.267671  0.231999  0.226553  0.236617  0.256444   \n",
       "1       Q2  0.413149  0.422476  0.382707  0.338075  0.339839  0.332445   \n",
       "2       Q2  0.310428  0.328462  0.413456  0.555491  0.530212  0.436717   \n",
       "3       Q1  0.159420  0.161369  0.177484  0.220572  0.341637  0.407468   \n",
       "4       Q3  0.311646  0.319286  0.308918  0.314276  0.316000  0.288682   \n",
       "\n",
       "          6         7         8  ...       497       498       499       500  \\\n",
       "0  0.282879  0.309561  0.325702  ... -0.020307  2.324166  3.567792  3.883560   \n",
       "1  0.323744  0.324923  0.316282  ... -1.688632 -3.825361 -0.613288 -3.535904   \n",
       "2  0.347030  0.308844  0.339200  ... -2.085293 -2.503842 -4.341682 -2.598336   \n",
       "3  0.316527  0.190813  0.155512  ...  1.663398 -3.054370 -3.469282  0.551196   \n",
       "4  0.250883  0.219238  0.244121  ... -2.719656 -4.388300  0.210486  0.959180   \n",
       "\n",
       "        501       502       503       504       505         506  \n",
       "0 -1.823020 -2.058319 -5.530811 -2.079775 -2.063657  163.043478  \n",
       "1 -4.854705 -1.428813 -8.155371  0.105861 -4.854570  135.999178  \n",
       "2 -3.895138 -0.943562 -4.858965  0.452470 -4.311635  101.351351  \n",
       "3 -2.130995  1.955830 -1.407931  4.732381 -2.828623   98.684211  \n",
       "4 -0.584419  3.384225 -4.916590  1.795105 -4.837695   66.964286  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = merged_df[['Quadrant'] + list(merged_df.columns[-507:])]\n",
    "#merged_df = pd.concat(merged_df['Quadrant'], combined_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80183362-b8e8-4a58-bc80-bd61046a6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed203a6-86cc-40d7-bd0d-7ff80817d1f0",
   "metadata": {},
   "source": [
    "# Разделение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae060b7d-ec62-4846-88f1-d6db322cfd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "474e56b0-f8d3-4276-a59a-70c5d69a1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('C:/Users/Mary/Desktop/Диплом/cqt_stft_cens_chromas_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f628470c-474b-488c-9450-8e79ea17b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 509)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0624a309-7aae-435a-a8a1-0337b85cbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('Quadrant',axis=1)\n",
    "y = final_df['Quadrant']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71dbf4e2-1edf-49e5-b817-2b24c261187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scal_X_train = scaler.fit_transform(X_train)\n",
    "scal_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a144f83-359d-4875-8a7d-5a4f4f24681c",
   "metadata": {},
   "source": [
    "# Optuna в rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3d53320e-0ab2-4bb8-b565-6c5dc3a20320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a04c5470-d973-49dd-b093-0298effd57f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-08 22:05:57,639] A new study created in memory with name: no-name-f02f6f26-eb3a-49f1-a99e-5ec3e4c596c7\n",
      "[I 2025-03-08 22:06:52,353] Trial 3 finished with value: 0.5738562091503268 and parameters: {'n_estimators': 173, 'max_depth': 47, 'min_samples_split': 0.3082299057445912, 'min_samples_leaf': 3, 'max_features': 0.22067866430454208, 'bootstrap': False}. Best is trial 3 with value: 0.5738562091503268.\n",
      "[I 2025-03-08 22:07:04,510] Trial 7 finished with value: 0.584313725490196 and parameters: {'n_estimators': 290, 'max_depth': 47, 'min_samples_split': 0.04271740354422055, 'min_samples_leaf': 6, 'max_features': 0.39863261940329353, 'bootstrap': False}. Best is trial 7 with value: 0.584313725490196.\n",
      "[I 2025-03-08 22:07:10,447] Trial 5 finished with value: 0.5699346405228758 and parameters: {'n_estimators': 177, 'max_depth': 48, 'min_samples_split': 0.38064194185007943, 'min_samples_leaf': 12, 'max_features': 0.2367829658633477, 'bootstrap': False}. Best is trial 7 with value: 0.584313725490196.\n",
      "[I 2025-03-08 22:07:16,626] Trial 4 finished with value: 0.538562091503268 and parameters: {'n_estimators': 210, 'max_depth': 37, 'min_samples_split': 0.1930996106651227, 'min_samples_leaf': 16, 'max_features': 0.9964145003291357, 'bootstrap': False}. Best is trial 7 with value: 0.584313725490196.\n",
      "[I 2025-03-08 22:07:17,279] Trial 0 finished with value: 0.6143790849673203 and parameters: {'n_estimators': 449, 'max_depth': 27, 'min_samples_split': 0.0399790155101209, 'min_samples_leaf': 10, 'max_features': 0.10499760418335172, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:07:25,691] Trial 6 finished with value: 0.48888888888888893 and parameters: {'n_estimators': 418, 'max_depth': 5, 'min_samples_split': 0.3894872173891064, 'min_samples_leaf': 9, 'max_features': 0.5751492891586304, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:07:32,002] Trial 1 finished with value: 0.5647058823529412 and parameters: {'n_estimators': 377, 'max_depth': 31, 'min_samples_split': 0.30524891282945155, 'min_samples_leaf': 8, 'max_features': 0.47307425117538293, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:07:39,797] Trial 2 finished with value: 0.5947712418300654 and parameters: {'n_estimators': 303, 'max_depth': 21, 'min_samples_split': 0.08684223293198363, 'min_samples_leaf': 12, 'max_features': 0.305127480259192, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:08:20,445] Trial 8 finished with value: 0.5738562091503268 and parameters: {'n_estimators': 193, 'max_depth': 23, 'min_samples_split': 0.01245272903996357, 'min_samples_leaf': 9, 'max_features': 0.8815110099617008, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:08:42,407] Trial 9 finished with value: 0.5581699346405229 and parameters: {'n_estimators': 362, 'max_depth': 19, 'min_samples_split': 0.2899609343938606, 'min_samples_leaf': 11, 'max_features': 0.5463005648350194, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:08:44,781] Trial 10 finished with value: 0.5529411764705883 and parameters: {'n_estimators': 339, 'max_depth': 31, 'min_samples_split': 0.3747484071460971, 'min_samples_leaf': 19, 'max_features': 0.5673641038877963, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:08:46,028] Trial 11 finished with value: 0.5738562091503268 and parameters: {'n_estimators': 80, 'max_depth': 29, 'min_samples_split': 0.23228901492774653, 'min_samples_leaf': 10, 'max_features': 0.2899625337343736, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:08:54,025] Trial 12 finished with value: 0.5816993464052288 and parameters: {'n_estimators': 221, 'max_depth': 8, 'min_samples_split': 0.16753325089204907, 'min_samples_leaf': 20, 'max_features': 0.22363282024626352, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:19,515] Trial 14 finished with value: 0.5307189542483659 and parameters: {'n_estimators': 106, 'max_depth': 49, 'min_samples_split': 0.32901611371877776, 'min_samples_leaf': 8, 'max_features': 0.6629634272153128, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:27,479] Trial 13 finished with value: 0.5568627450980392 and parameters: {'n_estimators': 243, 'max_depth': 24, 'min_samples_split': 0.17036161123206686, 'min_samples_leaf': 14, 'max_features': 0.9587429396775043, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:29,411] Trial 15 finished with value: 0.5660130718954248 and parameters: {'n_estimators': 203, 'max_depth': 12, 'min_samples_split': 0.325112528868242, 'min_samples_leaf': 16, 'max_features': 0.12612339686485555, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:33,585] Trial 16 finished with value: 0.47973856209150323 and parameters: {'n_estimators': 175, 'max_depth': 29, 'min_samples_split': 0.4145913373784934, 'min_samples_leaf': 20, 'max_features': 0.6847045391925067, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:40,804] Trial 17 finished with value: 0.5908496732026145 and parameters: {'n_estimators': 488, 'max_depth': 8, 'min_samples_split': 0.16369320536023968, 'min_samples_leaf': 20, 'max_features': 0.1363368488779258, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:46,389] Trial 18 finished with value: 0.5856209150326798 and parameters: {'n_estimators': 461, 'max_depth': 13, 'min_samples_split': 0.13246977615195854, 'min_samples_leaf': 15, 'max_features': 0.10716594094919657, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:09:55,182] Trial 19 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 493, 'max_depth': 14, 'min_samples_split': 0.11226784322890482, 'min_samples_leaf': 14, 'max_features': 0.15811602904907196, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:10:05,370] Trial 20 finished with value: 0.6 and parameters: {'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 0.09839863393444015, 'min_samples_leaf': 14, 'max_features': 0.14185121769573086, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:10:14,322] Trial 21 finished with value: 0.5895424836601307 and parameters: {'n_estimators': 482, 'max_depth': 16, 'min_samples_split': 0.10188991474215016, 'min_samples_leaf': 14, 'max_features': 0.14727603354985963, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:10:18,457] Trial 22 finished with value: 0.5947712418300655 and parameters: {'n_estimators': 467, 'max_depth': 13, 'min_samples_split': 0.07382639974058403, 'min_samples_leaf': 15, 'max_features': 0.10303806312895819, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:10:29,812] Trial 23 finished with value: 0.5895424836601307 and parameters: {'n_estimators': 494, 'max_depth': 16, 'min_samples_split': 0.09078656503977328, 'min_samples_leaf': 4, 'max_features': 0.12310037296341453, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:10:39,690] Trial 24 finished with value: 0.592156862745098 and parameters: {'n_estimators': 494, 'max_depth': 15, 'min_samples_split': 0.08074097668647642, 'min_samples_leaf': 1, 'max_features': 0.12282376127936576, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:11,620] Trial 25 finished with value: 0.5895424836601307 and parameters: {'n_estimators': 492, 'max_depth': 16, 'min_samples_split': 0.07987860300866986, 'min_samples_leaf': 5, 'max_features': 0.35449053029180644, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:21,640] Trial 27 finished with value: 0.4549019607843137 and parameters: {'n_estimators': 299, 'max_depth': 38, 'min_samples_split': 0.4926833071118719, 'min_samples_leaf': 5, 'max_features': 0.3657488128944758, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:28,166] Trial 26 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 302, 'max_depth': 39, 'min_samples_split': 0.07095836930935101, 'min_samples_leaf': 5, 'max_features': 0.3486580794924256, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:31,117] Trial 28 finished with value: 0.4496732026143791 and parameters: {'n_estimators': 445, 'max_depth': 19, 'min_samples_split': 0.49791963954196683, 'min_samples_leaf': 12, 'max_features': 0.334939859012334, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:39,740] Trial 29 finished with value: 0.45359477124183006 and parameters: {'n_estimators': 423, 'max_depth': 20, 'min_samples_split': 0.4827304195063632, 'min_samples_leaf': 12, 'max_features': 0.35466993617743514, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:11:52,892] Trial 30 finished with value: 0.5764705882352942 and parameters: {'n_estimators': 437, 'max_depth': 2, 'min_samples_split': 0.05790883814467698, 'min_samples_leaf': 17, 'max_features': 0.3798908052326073, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:12:05,260] Trial 31 finished with value: 0.4562091503267974 and parameters: {'n_estimators': 423, 'max_depth': 37, 'min_samples_split': 0.4809138961732867, 'min_samples_leaf': 17, 'max_features': 0.36418249441757644, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:12:19,465] Trial 32 finished with value: 0.6013071895424836 and parameters: {'n_estimators': 426, 'max_depth': 37, 'min_samples_split': 0.03947642133066084, 'min_samples_leaf': 18, 'max_features': 0.31744494875878027, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:12:27,254] Trial 33 finished with value: 0.4522875816993464 and parameters: {'n_estimators': 430, 'max_depth': 37, 'min_samples_split': 0.4664625504446418, 'min_samples_leaf': 17, 'max_features': 0.21435125934487423, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:12:32,824] Trial 34 finished with value: 0.5673202614379085 and parameters: {'n_estimators': 429, 'max_depth': 2, 'min_samples_split': 0.017508651785199444, 'min_samples_leaf': 17, 'max_features': 0.2186343815329203, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:13:01,046] Trial 35 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 435, 'max_depth': 9, 'min_samples_split': 0.015089614015023612, 'min_samples_leaf': 18, 'max_features': 0.2142886441721546, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:13:42,006] Trial 36 finished with value: 0.6078431372549019 and parameters: {'n_estimators': 406, 'max_depth': 10, 'min_samples_split': 0.01763318054072982, 'min_samples_leaf': 18, 'max_features': 0.44619091553134255, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:14:16,044] Trial 37 finished with value: 0.6104575163398693 and parameters: {'n_estimators': 397, 'max_depth': 33, 'min_samples_split': 0.017843776501089655, 'min_samples_leaf': 17, 'max_features': 0.4441526820879407, 'bootstrap': False}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:14:18,460] Trial 38 finished with value: 0.5908496732026144 and parameters: {'n_estimators': 396, 'max_depth': 10, 'min_samples_split': 0.011691113137255751, 'min_samples_leaf': 13, 'max_features': 0.19921971713491243, 'bootstrap': True}. Best is trial 0 with value: 0.6143790849673203.\n",
      "[I 2025-03-08 22:14:40,841] Trial 39 finished with value: 0.6169934640522876 and parameters: {'n_estimators': 387, 'max_depth': 10, 'min_samples_split': 0.010245918919697478, 'min_samples_leaf': 13, 'max_features': 0.20246386097397454, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:14:46,775] Trial 40 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 385, 'max_depth': 34, 'min_samples_split': 0.017747762253002147, 'min_samples_leaf': 18, 'max_features': 0.20144563182139702, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:15:13,182] Trial 41 finished with value: 0.592156862745098 and parameters: {'n_estimators': 381, 'max_depth': 41, 'min_samples_split': 0.019307927303923667, 'min_samples_leaf': 18, 'max_features': 0.2659020227419613, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:15:43,265] Trial 42 finished with value: 0.6013071895424836 and parameters: {'n_estimators': 392, 'max_depth': 44, 'min_samples_split': 0.03543084330435692, 'min_samples_leaf': 13, 'max_features': 0.2699433333643938, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:15:57,174] Trial 43 finished with value: 0.5947712418300654 and parameters: {'n_estimators': 388, 'max_depth': 43, 'min_samples_split': 0.03601171257165538, 'min_samples_leaf': 18, 'max_features': 0.2817612059543981, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:16:48,070] Trial 44 finished with value: 0.6104575163398693 and parameters: {'n_estimators': 399, 'max_depth': 44, 'min_samples_split': 0.036418859102625295, 'min_samples_leaf': 13, 'max_features': 0.4849865034048552, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:17:31,843] Trial 45 finished with value: 0.6026143790849674 and parameters: {'n_estimators': 369, 'max_depth': 34, 'min_samples_split': 0.036117262492331756, 'min_samples_leaf': 19, 'max_features': 0.4499151510094985, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:17:34,644] Trial 46 finished with value: 0.6026143790849674 and parameters: {'n_estimators': 335, 'max_depth': 42, 'min_samples_split': 0.04142392428437691, 'min_samples_leaf': 19, 'max_features': 0.4597800921520865, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:18:24,410] Trial 47 finished with value: 0.603921568627451 and parameters: {'n_estimators': 336, 'max_depth': 43, 'min_samples_split': 0.04571649988464287, 'min_samples_leaf': 10, 'max_features': 0.45353871261865936, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:18:50,726] Trial 48 finished with value: 0.6052287581699347 and parameters: {'n_estimators': 345, 'max_depth': 34, 'min_samples_split': 0.04116552411654691, 'min_samples_leaf': 19, 'max_features': 0.4493005208674144, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:19:21,343] Trial 49 finished with value: 0.6039215686274509 and parameters: {'n_estimators': 349, 'max_depth': 34, 'min_samples_split': 0.04678017038889575, 'min_samples_leaf': 11, 'max_features': 0.46158716308398945, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:20:16,662] Trial 50 finished with value: 0.6078431372549019 and parameters: {'n_estimators': 349, 'max_depth': 32, 'min_samples_split': 0.05007517227179578, 'min_samples_leaf': 10, 'max_features': 0.49918025378175296, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:20:19,814] Trial 51 finished with value: 0.611764705882353 and parameters: {'n_estimators': 336, 'max_depth': 32, 'min_samples_split': 0.05202335706025779, 'min_samples_leaf': 10, 'max_features': 0.44346480930544274, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:20:59,432] Trial 52 finished with value: 0.5843137254901961 and parameters: {'n_estimators': 343, 'max_depth': 27, 'min_samples_split': 0.12726512343202162, 'min_samples_leaf': 10, 'max_features': 0.4344604726270024, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:21:39,550] Trial 53 finished with value: 0.6 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 0.12957881507154506, 'min_samples_leaf': 10, 'max_features': 0.5018359324802999, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:21:40,405] Trial 54 finished with value: 0.5620915032679739 and parameters: {'n_estimators': 347, 'max_depth': 27, 'min_samples_split': 0.22536526971808313, 'min_samples_leaf': 11, 'max_features': 0.5120592080910322, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:22:36,719] Trial 55 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 352, 'max_depth': 23, 'min_samples_split': 0.12113005009054129, 'min_samples_leaf': 7, 'max_features': 0.612873496635036, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:22:54,992] Trial 56 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 256, 'max_depth': 27, 'min_samples_split': 0.11881805419535767, 'min_samples_leaf': 7, 'max_features': 0.5312443608991413, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:23:13,484] Trial 57 finished with value: 0.5843137254901961 and parameters: {'n_estimators': 267, 'max_depth': 26, 'min_samples_split': 0.12128219068112563, 'min_samples_leaf': 8, 'max_features': 0.5236831809639235, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:23:30,507] Trial 58 finished with value: 0.5620915032679739 and parameters: {'n_estimators': 256, 'max_depth': 26, 'min_samples_split': 0.2342616350504203, 'min_samples_leaf': 8, 'max_features': 0.5251195180733141, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:24:11,676] Trial 59 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 320, 'max_depth': 26, 'min_samples_split': 0.12629067822391726, 'min_samples_leaf': 7, 'max_features': 0.6292328766230796, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:24:53,860] Trial 60 finished with value: 0.5594771241830065 and parameters: {'n_estimators': 407, 'max_depth': 24, 'min_samples_split': 0.21241170264690126, 'min_samples_leaf': 8, 'max_features': 0.6296194986200465, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:25:00,981] Trial 61 finished with value: 0.5660130718954248 and parameters: {'n_estimators': 267, 'max_depth': 23, 'min_samples_split': 0.21036194114283502, 'min_samples_leaf': 8, 'max_features': 0.6228733663385819, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:25:53,108] Trial 62 finished with value: 0.5947712418300654 and parameters: {'n_estimators': 272, 'max_depth': 25, 'min_samples_split': 0.0617372236654151, 'min_samples_leaf': 8, 'max_features': 0.6451362646498142, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:27:05,047] Trial 63 finished with value: 0.5986928104575163 and parameters: {'n_estimators': 405, 'max_depth': 25, 'min_samples_split': 0.06295764338947411, 'min_samples_leaf': 8, 'max_features': 0.5486403579328649, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:27:24,105] Trial 64 finished with value: 0.5764705882352942 and parameters: {'n_estimators': 404, 'max_depth': 30, 'min_samples_split': 0.15362984708219485, 'min_samples_leaf': 8, 'max_features': 0.778674101370412, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:28:08,694] Trial 65 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 409, 'max_depth': 6, 'min_samples_split': 0.0628802116866072, 'min_samples_leaf': 9, 'max_features': 0.4094251329733614, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:29:07,071] Trial 66 finished with value: 0.5751633986928104 and parameters: {'n_estimators': 402, 'max_depth': 30, 'min_samples_split': 0.06386533786952117, 'min_samples_leaf': 15, 'max_features': 0.7612280320641207, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:30:25,304] Trial 67 finished with value: 0.5699346405228758 and parameters: {'n_estimators': 462, 'max_depth': 46, 'min_samples_split': 0.063298044168479, 'min_samples_leaf': 15, 'max_features': 0.7521771104484949, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:30:39,150] Trial 68 finished with value: 0.603921568627451 and parameters: {'n_estimators': 366, 'max_depth': 31, 'min_samples_split': 0.06277765933721988, 'min_samples_leaf': 9, 'max_features': 0.40446955370240195, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:31:16,122] Trial 69 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 404, 'max_depth': 31, 'min_samples_split': 0.06644074098791054, 'min_samples_leaf': 9, 'max_features': 0.40137079079920723, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:31:52,153] Trial 70 finished with value: 0.6065359477124184 and parameters: {'n_estimators': 463, 'max_depth': 30, 'min_samples_split': 0.061890948552794534, 'min_samples_leaf': 9, 'max_features': 0.4114097002472369, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:33:11,036] Trial 71 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 459, 'max_depth': 32, 'min_samples_split': 0.09044400303496666, 'min_samples_leaf': 9, 'max_features': 0.7141929601668249, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:33:20,008] Trial 72 finished with value: 0.5908496732026144 and parameters: {'n_estimators': 367, 'max_depth': 50, 'min_samples_split': 0.08066449406966934, 'min_samples_leaf': 9, 'max_features': 0.4142176856702332, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:34:18,533] Trial 73 finished with value: 0.596078431372549 and parameters: {'n_estimators': 463, 'max_depth': 46, 'min_samples_split': 0.09128045147977842, 'min_samples_leaf': 13, 'max_features': 0.5873926332057515, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:35:13,821] Trial 74 finished with value: 0.5986928104575163 and parameters: {'n_estimators': 463, 'max_depth': 32, 'min_samples_split': 0.09607854583091824, 'min_samples_leaf': 13, 'max_features': 0.579061781915136, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:35:32,549] Trial 75 finished with value: 0.5934640522875817 and parameters: {'n_estimators': 367, 'max_depth': 32, 'min_samples_split': 0.09204266332311617, 'min_samples_leaf': 13, 'max_features': 0.5771608231012261, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:36:19,438] Trial 76 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 449, 'max_depth': 33, 'min_samples_split': 0.09117359436928885, 'min_samples_leaf': 12, 'max_features': 0.4925591694262655, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:37:32,447] Trial 77 finished with value: 0.592156862745098 and parameters: {'n_estimators': 449, 'max_depth': 32, 'min_samples_split': 0.09351316084596802, 'min_samples_leaf': 13, 'max_features': 0.5833290518060664, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:38:04,787] Trial 78 finished with value: 0.5882352941176471 and parameters: {'n_estimators': 474, 'max_depth': 32, 'min_samples_split': 0.08788746999932781, 'min_samples_leaf': 13, 'max_features': 0.5820465653458047, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:39:00,239] Trial 79 finished with value: 0.6091503267973857 and parameters: {'n_estimators': 446, 'max_depth': 21, 'min_samples_split': 0.026889356069482107, 'min_samples_leaf': 12, 'max_features': 0.5667458482922407, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:39:28,523] Trial 80 finished with value: 0.6052287581699347 and parameters: {'n_estimators': 448, 'max_depth': 21, 'min_samples_split': 0.026819409200776162, 'min_samples_leaf': 13, 'max_features': 0.4850934978331354, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:39:44,059] Trial 81 finished with value: 0.5594771241830065 and parameters: {'n_estimators': 450, 'max_depth': 32, 'min_samples_split': 0.28640084903859137, 'min_samples_leaf': 11, 'max_features': 0.4939428827419536, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:40:54,843] Trial 82 finished with value: 0.6013071895424836 and parameters: {'n_estimators': 445, 'max_depth': 29, 'min_samples_split': 0.02593118289850649, 'min_samples_leaf': 11, 'max_features': 0.48995682927506606, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:41:52,100] Trial 83 finished with value: 0.6013071895424837 and parameters: {'n_estimators': 446, 'max_depth': 29, 'min_samples_split': 0.031144973078492268, 'min_samples_leaf': 10, 'max_features': 0.49186588604962284, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:42:15,334] Trial 84 finished with value: 0.615686274509804 and parameters: {'n_estimators': 475, 'max_depth': 29, 'min_samples_split': 0.02393289572693613, 'min_samples_leaf': 11, 'max_features': 0.4771451446314212, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:43:14,281] Trial 85 finished with value: 0.6104575163398693 and parameters: {'n_estimators': 477, 'max_depth': 11, 'min_samples_split': 0.027968271732277616, 'min_samples_leaf': 16, 'max_features': 0.43515727277331795, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:43:56,305] Trial 86 finished with value: 0.6104575163398693 and parameters: {'n_estimators': 416, 'max_depth': 18, 'min_samples_split': 0.02770249104829409, 'min_samples_leaf': 11, 'max_features': 0.4834780833717126, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:43:59,909] Trial 88 finished with value: 0.6026143790849674 and parameters: {'n_estimators': 135, 'max_depth': 11, 'min_samples_split': 0.026183025290294693, 'min_samples_leaf': 11, 'max_features': 0.18284147376529958, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:44:09,188] Trial 87 finished with value: 0.6143790849673203 and parameters: {'n_estimators': 317, 'max_depth': 18, 'min_samples_split': 0.028188727244019607, 'min_samples_leaf': 11, 'max_features': 0.473059652308229, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:44:44,576] Trial 89 finished with value: 0.6052287581699346 and parameters: {'n_estimators': 415, 'max_depth': 29, 'min_samples_split': 0.026351273892752103, 'min_samples_leaf': 11, 'max_features': 0.3169547347627173, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:45:11,288] Trial 91 finished with value: 0.6078431372549019 and parameters: {'n_estimators': 379, 'max_depth': 18, 'min_samples_split': 0.05153566445224521, 'min_samples_leaf': 12, 'max_features': 0.17067543541237828, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:45:13,761] Trial 90 finished with value: 0.6 and parameters: {'n_estimators': 477, 'max_depth': 35, 'min_samples_split': 0.05097843747974735, 'min_samples_leaf': 16, 'max_features': 0.23993949712172294, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:45:37,635] Trial 92 finished with value: 0.6065359477124184 and parameters: {'n_estimators': 418, 'max_depth': 36, 'min_samples_split': 0.025644710201541736, 'min_samples_leaf': 12, 'max_features': 0.17321217106021936, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:46:04,131] Trial 93 finished with value: 0.5947712418300654 and parameters: {'n_estimators': 482, 'max_depth': 18, 'min_samples_split': 0.02380872880361522, 'min_samples_leaf': 16, 'max_features': 0.24219599313675122, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:46:16,925] Trial 94 finished with value: 0.611764705882353 and parameters: {'n_estimators': 479, 'max_depth': 17, 'min_samples_split': 0.013259930882436165, 'min_samples_leaf': 16, 'max_features': 0.16750730321370774, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:46:40,007] Trial 95 finished with value: 0.6000000000000001 and parameters: {'n_estimators': 475, 'max_depth': 18, 'min_samples_split': 0.011552310851982321, 'min_samples_leaf': 16, 'max_features': 0.24419244384660885, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:46:53,896] Trial 96 finished with value: 0.5908496732026144 and parameters: {'n_estimators': 319, 'max_depth': 17, 'min_samples_split': 0.012742092936719514, 'min_samples_leaf': 16, 'max_features': 0.24417254225215781, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:47:47,938] Trial 97 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 479, 'max_depth': 16, 'min_samples_split': 0.051297730130998885, 'min_samples_leaf': 16, 'max_features': 0.47228689341626934, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:48:17,504] Trial 98 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 321, 'max_depth': 17, 'min_samples_split': 0.014730661525427449, 'min_samples_leaf': 16, 'max_features': 0.42895917158861147, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n",
      "[I 2025-03-08 22:48:18,749] Trial 99 finished with value: 0.6 and parameters: {'n_estimators': 312, 'max_depth': 18, 'min_samples_split': 0.011787474737767124, 'min_samples_leaf': 12, 'max_features': 0.3814171988656252, 'bootstrap': False}. Best is trial 39 with value: 0.6169934640522876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 387, 'max_depth': 10, 'min_samples_split': 0.010245918919697478, 'min_samples_leaf': 13, 'max_features': 0.20246386097397454, 'bootstrap': False}\n",
      "Лучший результат: 0.6169934640522876\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Оптимизируем гиперпараметры\n",
    "def objective(trial):\n",
    "    # Подбираемые параметры\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)  # Количество деревьев\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 50)  # Глубина деревьев\n",
    "    min_samples_split = trial.suggest_float(\"min_samples_split\", 0.01, 0.5)  # Мин. число объектов для разбиения\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)  # Мин. число объектов в листе\n",
    "    max_features = trial.suggest_float(\"max_features\", 0.1, 1.0)  # Доля признаков для построения каждого дерева\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])  # Использовать бутстрап?\n",
    "\n",
    "    # Определяем модель\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Параллельный запуск\n",
    "    )\n",
    "\n",
    "    # Кросс-валидация (StratifiedKFold для лучшего баланса классов)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "    \n",
    "    return score  # Оптимизируем точность\n",
    "\n",
    "# Запускаем Optuna с Pruner (отбрасывание слабых комбинаций)\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1)  # Больше итераций\n",
    "\n",
    "# Вывод лучших параметров\n",
    "print(\"Лучшие параметры:\", study.best_params)\n",
    "print(\"Лучший результат:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cb26df99-bcd0-4764-bb1e-26d27aa7c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_rfc = RandomForestClassifier(n_estimators=387, max_depth=10, min_samples_split=0.010245918919697478, min_samples_leaf=13, max_features=0.20246386097397454, bootstrap=False)\n",
    "optuna_rfc.fit(X_train,y_train)\n",
    "optuna_rfc_preds = optuna_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1baa1fd0-3c76-4d53-b256-631ebb09504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.66      0.61      0.63        41\n",
      "          Q2       0.71      0.80      0.75        40\n",
      "          Q3       0.69      0.64      0.67        28\n",
      "          Q4       0.65      0.65      0.65        26\n",
      "\n",
      "    accuracy                           0.68       135\n",
      "   macro avg       0.68      0.68      0.68       135\n",
      "weighted avg       0.68      0.68      0.68       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,optuna_rfc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b01f6-ba6c-419d-8d5e-18b9593eedc3",
   "metadata": {},
   "source": [
    "# Optuna в CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5449ec-cb81-4c08-bc0c-e39bd5ed9107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-12 20:32:48,171] A new study created in memory with name: no-name-844d38db-dff6-4a59-8146-9b52e4f2c66f\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 20:39:20,359] Trial 3 finished with value: 0.5803921568627451 and parameters: {'iterations': 223, 'depth': 7, 'learning_rate': 0.022779188992176715, 'l2_leaf_reg': 1.0917999983871332, 'border_count': 69}. Best is trial 3 with value: 0.5803921568627451.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:12:43,751] Trial 0 finished with value: 0.5973856209150327 and parameters: {'iterations': 379, 'depth': 9, 'learning_rate': 0.01298633335629707, 'l2_leaf_reg': 0.27335697101570294, 'border_count': 87}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:16:54,663] Trial 5 finished with value: 0.5712418300653596 and parameters: {'iterations': 161, 'depth': 6, 'learning_rate': 0.013380231179895495, 'l2_leaf_reg': 0.04696015026198926, 'border_count': 100}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:17:21,773] Trial 4 finished with value: 0.5973856209150327 and parameters: {'iterations': 379, 'depth': 9, 'learning_rate': 0.022274577057376708, 'l2_leaf_reg': 0.04741877674429317, 'border_count': 78}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:23:36,374] Trial 2 finished with value: 0.5751633986928105 and parameters: {'iterations': 194, 'depth': 8, 'learning_rate': 0.030485569008280842, 'l2_leaf_reg': 1.0869388195426504, 'border_count': 62}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:37:50,841] Trial 6 finished with value: 0.5620915032679739 and parameters: {'iterations': 181, 'depth': 6, 'learning_rate': 0.016794105009673807, 'l2_leaf_reg': 0.02515314438646802, 'border_count': 58}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:41:37,033] Trial 7 finished with value: 0.592156862745098 and parameters: {'iterations': 310, 'depth': 7, 'learning_rate': 0.06875047505421321, 'l2_leaf_reg': 0.44487457561173094, 'border_count': 75}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:43:26,080] Trial 9 finished with value: 0.5647058823529412 and parameters: {'iterations': 114, 'depth': 6, 'learning_rate': 0.02945100797811379, 'l2_leaf_reg': 0.022199796090315464, 'border_count': 56}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:45:37,641] Trial 8 finished with value: 0.5908496732026144 and parameters: {'iterations': 397, 'depth': 7, 'learning_rate': 0.02072402352865788, 'l2_leaf_reg': 0.6613741288555153, 'border_count': 54}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:48:52,711] Trial 11 finished with value: 0.5790849673202615 and parameters: {'iterations': 205, 'depth': 6, 'learning_rate': 0.02531570898087099, 'l2_leaf_reg': 0.1515221839222351, 'border_count': 87}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 21:50:08,218] Trial 10 finished with value: 0.5908496732026144 and parameters: {'iterations': 374, 'depth': 6, 'learning_rate': 0.08769076830248791, 'l2_leaf_reg': 0.6612308179151779, 'border_count': 100}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:07:38,043] Trial 1 finished with value: 0.5947712418300654 and parameters: {'iterations': 303, 'depth': 10, 'learning_rate': 0.017091900941621486, 'l2_leaf_reg': 0.031553247396953796, 'border_count': 100}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:08:50,581] Trial 14 finished with value: 0.5738562091503269 and parameters: {'iterations': 155, 'depth': 7, 'learning_rate': 0.01797553645827746, 'l2_leaf_reg': 2.425473315854993, 'border_count': 95}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:10:21,338] Trial 13 finished with value: 0.5934640522875817 and parameters: {'iterations': 360, 'depth': 8, 'learning_rate': 0.052239791498469336, 'l2_leaf_reg': 0.021963367521990095, 'border_count': 86}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:17:12,329] Trial 15 finished with value: 0.5856209150326798 and parameters: {'iterations': 444, 'depth': 6, 'learning_rate': 0.04393730536137524, 'l2_leaf_reg': 0.06231175044659426, 'border_count': 72}. Best is trial 0 with value: 0.5973856209150327.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:30:24,952] Trial 16 finished with value: 0.6039215686274509 and parameters: {'iterations': 376, 'depth': 7, 'learning_rate': 0.03591338854313402, 'l2_leaf_reg': 4.806012493315716, 'border_count': 79}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-12 22:57:56,731] Trial 12 finished with value: 0.5843137254901961 and parameters: {'iterations': 469, 'depth': 10, 'learning_rate': 0.01485692408903157, 'l2_leaf_reg': 0.7293514863155628, 'border_count': 69}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 00:16:18,954] Trial 17 finished with value: 0.5790849673202615 and parameters: {'iterations': 482, 'depth': 10, 'learning_rate': 0.010828620082751268, 'l2_leaf_reg': 0.2599569446384074, 'border_count': 94}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 00:44:18,066] Trial 18 finished with value: 0.596078431372549 and parameters: {'iterations': 489, 'depth': 10, 'learning_rate': 0.013030584963240603, 'l2_leaf_reg': 0.12044808992896612, 'border_count': 86}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 02:02:19,150] Trial 19 finished with value: 0.5633986928104576 and parameters: {'iterations': 477, 'depth': 10, 'learning_rate': 0.010779661686962368, 'l2_leaf_reg': 4.315056662929257, 'border_count': 83}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 02:08:50,903] Trial 20 finished with value: 0.6026143790849674 and parameters: {'iterations': 486, 'depth': 10, 'learning_rate': 0.04362098469600632, 'l2_leaf_reg': 0.1134582628781276, 'border_count': 85}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 02:21:21,752] Trial 21 finished with value: 0.5869281045751634 and parameters: {'iterations': 431, 'depth': 10, 'learning_rate': 0.010021843246085115, 'l2_leaf_reg': 0.1154366986985861, 'border_count': 83}. Best is trial 16 with value: 0.6039215686274509.\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_8508\\1127732574.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),\n",
      "[I 2025-03-13 03:00:52,602] Trial 23 finished with value: 0.5856209150326798 and parameters: {'iterations': 499, 'depth': 9, 'learning_rate': 0.010297097474035455, 'l2_leaf_reg': 2.923192043379398, 'border_count': 84}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 03:01:21,113] Trial 24 finished with value: 0.5673202614379086 and parameters: {'iterations': 269, 'depth': 9, 'learning_rate': 0.01091226450354552, 'l2_leaf_reg': 3.662784380043747, 'border_count': 83}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 03:22:25,738] Trial 25 finished with value: 0.5882352941176471 and parameters: {'iterations': 256, 'depth': 9, 'learning_rate': 0.0417032245190182, 'l2_leaf_reg': 3.2262879857803464, 'border_count': 82}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 03:25:41,312] Trial 26 finished with value: 0.5856209150326798 and parameters: {'iterations': 256, 'depth': 9, 'learning_rate': 0.042074279994313846, 'l2_leaf_reg': 2.857962064249351, 'border_count': 80}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 03:28:31,078] Trial 22 finished with value: 0.5830065359477125 and parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.010215900553201991, 'l2_leaf_reg': 0.14811735330898487, 'border_count': 84}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 03:59:14,779] Trial 27 finished with value: 0.5973856209150327 and parameters: {'iterations': 428, 'depth': 9, 'learning_rate': 0.041246422602748106, 'l2_leaf_reg': 0.010180051550263535, 'border_count': 79}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 04:01:06,936] Trial 28 finished with value: 0.5843137254901961 and parameters: {'iterations': 428, 'depth': 9, 'learning_rate': 0.03961647383143893, 'l2_leaf_reg': 0.011554872070483297, 'border_count': 82}. Best is trial 16 with value: 0.6039215686274509.\n",
      "[I 2025-03-13 04:03:22,503] Trial 29 finished with value: 0.5934640522875817 and parameters: {'iterations': 331, 'depth': 9, 'learning_rate': 0.041412729830347016, 'l2_leaf_reg': 0.2466855097193425, 'border_count': 92}. Best is trial 16 with value: 0.6039215686274509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'iterations': 376, 'depth': 7, 'learning_rate': 0.03591338854313402, 'l2_leaf_reg': 4.806012493315716, 'border_count': 79}\n",
      "Лучший результат: 0.6039215686274509\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Функция для оптимизации\n",
    "def objective(trial):\n",
    " \n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 500),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 6, 10),  \n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1), \n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 5.0),  \n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 50, 100),  \n",
    "        \"loss_function\": \"MultiClass\", \n",
    "        \"eval_metric\": \"Accuracy\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_state\": 42,\n",
    "        \"task_type\": \"GPU\" if CatBoostClassifier().get_param(\"task_type\") == \"GPU\" else \"CPU\",  \n",
    "        \"early_stopping_rounds\": 50  \n",
    "    }\n",
    "\n",
    "    # Создаём модель\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # Кросс-валидация\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "    \n",
    "    return score  \n",
    "\n",
    "# Оптимизация\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=30, n_jobs=-1)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(\"Лучшие параметры:\", study.best_params)\n",
    "print(\"Лучший результат:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb746f5a-1683-45ab-96ee-f1917e2765ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3696488\ttotal: 321ms\tremaining: 2m\n",
      "1:\tlearn: 1.3538293\ttotal: 493ms\tremaining: 1m 32s\n",
      "2:\tlearn: 1.3391763\ttotal: 681ms\tremaining: 1m 24s\n",
      "3:\tlearn: 1.3255955\ttotal: 847ms\tremaining: 1m 18s\n",
      "4:\tlearn: 1.3135272\ttotal: 1.02s\tremaining: 1m 15s\n",
      "5:\tlearn: 1.3004374\ttotal: 1.21s\tremaining: 1m 14s\n",
      "6:\tlearn: 1.2885012\ttotal: 1.42s\tremaining: 1m 15s\n",
      "7:\tlearn: 1.2751855\ttotal: 1.59s\tremaining: 1m 13s\n",
      "8:\tlearn: 1.2633083\ttotal: 1.81s\tremaining: 1m 14s\n",
      "9:\tlearn: 1.2531274\ttotal: 1.99s\tremaining: 1m 12s\n",
      "10:\tlearn: 1.2435266\ttotal: 2.2s\tremaining: 1m 13s\n",
      "11:\tlearn: 1.2316884\ttotal: 2.38s\tremaining: 1m 12s\n",
      "12:\tlearn: 1.2200039\ttotal: 2.57s\tremaining: 1m 11s\n",
      "13:\tlearn: 1.2101535\ttotal: 2.76s\tremaining: 1m 11s\n",
      "14:\tlearn: 1.1974524\ttotal: 2.95s\tremaining: 1m 11s\n",
      "15:\tlearn: 1.1870188\ttotal: 3.15s\tremaining: 1m 10s\n",
      "16:\tlearn: 1.1770081\ttotal: 3.35s\tremaining: 1m 10s\n",
      "17:\tlearn: 1.1683630\ttotal: 3.52s\tremaining: 1m 9s\n",
      "18:\tlearn: 1.1592604\ttotal: 3.72s\tremaining: 1m 9s\n",
      "19:\tlearn: 1.1507031\ttotal: 3.89s\tremaining: 1m 9s\n",
      "20:\tlearn: 1.1415890\ttotal: 4.07s\tremaining: 1m 8s\n",
      "21:\tlearn: 1.1343135\ttotal: 4.26s\tremaining: 1m 8s\n",
      "22:\tlearn: 1.1258978\ttotal: 4.45s\tremaining: 1m 8s\n",
      "23:\tlearn: 1.1172428\ttotal: 4.63s\tremaining: 1m 7s\n",
      "24:\tlearn: 1.1091525\ttotal: 4.82s\tremaining: 1m 7s\n",
      "25:\tlearn: 1.1008348\ttotal: 5s\tremaining: 1m 7s\n",
      "26:\tlearn: 1.0932133\ttotal: 5.19s\tremaining: 1m 7s\n",
      "27:\tlearn: 1.0862850\ttotal: 5.38s\tremaining: 1m 6s\n",
      "28:\tlearn: 1.0788946\ttotal: 5.56s\tremaining: 1m 6s\n",
      "29:\tlearn: 1.0718626\ttotal: 5.75s\tremaining: 1m 6s\n",
      "30:\tlearn: 1.0655595\ttotal: 5.93s\tremaining: 1m 6s\n",
      "31:\tlearn: 1.0591686\ttotal: 6.13s\tremaining: 1m 5s\n",
      "32:\tlearn: 1.0522300\ttotal: 6.32s\tremaining: 1m 5s\n",
      "33:\tlearn: 1.0464745\ttotal: 6.49s\tremaining: 1m 5s\n",
      "34:\tlearn: 1.0398168\ttotal: 6.68s\tremaining: 1m 5s\n",
      "35:\tlearn: 1.0337045\ttotal: 6.86s\tremaining: 1m 4s\n",
      "36:\tlearn: 1.0271058\ttotal: 7.05s\tremaining: 1m 4s\n",
      "37:\tlearn: 1.0213330\ttotal: 7.24s\tremaining: 1m 4s\n",
      "38:\tlearn: 1.0158770\ttotal: 7.43s\tremaining: 1m 4s\n",
      "39:\tlearn: 1.0104878\ttotal: 7.6s\tremaining: 1m 3s\n",
      "40:\tlearn: 1.0045304\ttotal: 7.84s\tremaining: 1m 4s\n",
      "41:\tlearn: 0.9987424\ttotal: 8.03s\tremaining: 1m 3s\n",
      "42:\tlearn: 0.9931427\ttotal: 8.3s\tremaining: 1m 4s\n",
      "43:\tlearn: 0.9878122\ttotal: 8.49s\tremaining: 1m 4s\n",
      "44:\tlearn: 0.9825362\ttotal: 8.69s\tremaining: 1m 3s\n",
      "45:\tlearn: 0.9755835\ttotal: 8.93s\tremaining: 1m 4s\n",
      "46:\tlearn: 0.9695797\ttotal: 9.15s\tremaining: 1m 4s\n",
      "47:\tlearn: 0.9639758\ttotal: 9.34s\tremaining: 1m 3s\n",
      "48:\tlearn: 0.9601901\ttotal: 9.52s\tremaining: 1m 3s\n",
      "49:\tlearn: 0.9547385\ttotal: 9.69s\tremaining: 1m 3s\n",
      "50:\tlearn: 0.9497103\ttotal: 9.86s\tremaining: 1m 2s\n",
      "51:\tlearn: 0.9450911\ttotal: 10s\tremaining: 1m 2s\n",
      "52:\tlearn: 0.9409170\ttotal: 10.2s\tremaining: 1m 2s\n",
      "53:\tlearn: 0.9360345\ttotal: 10.4s\tremaining: 1m 1s\n",
      "54:\tlearn: 0.9321296\ttotal: 10.6s\tremaining: 1m 1s\n",
      "55:\tlearn: 0.9277518\ttotal: 10.7s\tremaining: 1m 1s\n",
      "56:\tlearn: 0.9227446\ttotal: 10.9s\tremaining: 1m 1s\n",
      "57:\tlearn: 0.9186828\ttotal: 11.1s\tremaining: 1m\n",
      "58:\tlearn: 0.9149772\ttotal: 11.2s\tremaining: 1m\n",
      "59:\tlearn: 0.9102494\ttotal: 11.4s\tremaining: 1m\n",
      "60:\tlearn: 0.9060682\ttotal: 11.6s\tremaining: 59.8s\n",
      "61:\tlearn: 0.9016392\ttotal: 11.8s\tremaining: 59.5s\n",
      "62:\tlearn: 0.8973863\ttotal: 11.9s\tremaining: 59.3s\n",
      "63:\tlearn: 0.8938574\ttotal: 12.1s\tremaining: 59s\n",
      "64:\tlearn: 0.8899573\ttotal: 12.3s\tremaining: 58.7s\n",
      "65:\tlearn: 0.8864000\ttotal: 12.4s\tremaining: 58.4s\n",
      "66:\tlearn: 0.8821367\ttotal: 12.6s\tremaining: 58.1s\n",
      "67:\tlearn: 0.8792415\ttotal: 12.8s\tremaining: 57.8s\n",
      "68:\tlearn: 0.8753842\ttotal: 12.9s\tremaining: 57.5s\n",
      "69:\tlearn: 0.8713912\ttotal: 13.1s\tremaining: 57.2s\n",
      "70:\tlearn: 0.8683465\ttotal: 13.2s\tremaining: 56.9s\n",
      "71:\tlearn: 0.8641685\ttotal: 13.4s\tremaining: 56.6s\n",
      "72:\tlearn: 0.8605006\ttotal: 13.6s\tremaining: 56.3s\n",
      "73:\tlearn: 0.8572733\ttotal: 13.7s\tremaining: 56s\n",
      "74:\tlearn: 0.8534332\ttotal: 13.9s\tremaining: 55.7s\n",
      "75:\tlearn: 0.8501978\ttotal: 14s\tremaining: 55.4s\n",
      "76:\tlearn: 0.8472877\ttotal: 14.2s\tremaining: 55.2s\n",
      "77:\tlearn: 0.8437236\ttotal: 14.4s\tremaining: 55s\n",
      "78:\tlearn: 0.8399460\ttotal: 14.6s\tremaining: 54.8s\n",
      "79:\tlearn: 0.8363937\ttotal: 14.7s\tremaining: 54.5s\n",
      "80:\tlearn: 0.8326360\ttotal: 14.9s\tremaining: 54.3s\n",
      "81:\tlearn: 0.8301482\ttotal: 15.1s\tremaining: 54s\n",
      "82:\tlearn: 0.8265863\ttotal: 15.3s\tremaining: 53.9s\n",
      "83:\tlearn: 0.8234760\ttotal: 15.4s\tremaining: 53.6s\n",
      "84:\tlearn: 0.8206338\ttotal: 15.6s\tremaining: 53.3s\n",
      "85:\tlearn: 0.8171287\ttotal: 15.7s\tremaining: 53s\n",
      "86:\tlearn: 0.8143840\ttotal: 15.9s\tremaining: 52.8s\n",
      "87:\tlearn: 0.8106922\ttotal: 16s\tremaining: 52.5s\n",
      "88:\tlearn: 0.8076092\ttotal: 16.2s\tremaining: 52.2s\n",
      "89:\tlearn: 0.8048588\ttotal: 16.4s\tremaining: 52s\n",
      "90:\tlearn: 0.8028000\ttotal: 16.5s\tremaining: 51.8s\n",
      "91:\tlearn: 0.7990893\ttotal: 16.7s\tremaining: 51.5s\n",
      "92:\tlearn: 0.7961963\ttotal: 16.9s\tremaining: 51.3s\n",
      "93:\tlearn: 0.7938652\ttotal: 17s\tremaining: 51s\n",
      "94:\tlearn: 0.7914902\ttotal: 17.2s\tremaining: 50.8s\n",
      "95:\tlearn: 0.7895518\ttotal: 17.3s\tremaining: 50.5s\n",
      "96:\tlearn: 0.7865589\ttotal: 17.5s\tremaining: 50.3s\n",
      "97:\tlearn: 0.7831196\ttotal: 17.6s\tremaining: 50s\n",
      "98:\tlearn: 0.7801774\ttotal: 17.8s\tremaining: 49.9s\n",
      "99:\tlearn: 0.7774170\ttotal: 18s\tremaining: 49.6s\n",
      "100:\tlearn: 0.7746565\ttotal: 18.2s\tremaining: 49.4s\n",
      "101:\tlearn: 0.7719942\ttotal: 18.3s\tremaining: 49.2s\n",
      "102:\tlearn: 0.7689328\ttotal: 18.5s\tremaining: 49.1s\n",
      "103:\tlearn: 0.7659690\ttotal: 18.7s\tremaining: 48.9s\n",
      "104:\tlearn: 0.7636987\ttotal: 18.9s\tremaining: 48.7s\n",
      "105:\tlearn: 0.7610021\ttotal: 19s\tremaining: 48.5s\n",
      "106:\tlearn: 0.7588003\ttotal: 19.2s\tremaining: 48.4s\n",
      "107:\tlearn: 0.7561351\ttotal: 19.4s\tremaining: 48.2s\n",
      "108:\tlearn: 0.7537412\ttotal: 19.6s\tremaining: 48s\n",
      "109:\tlearn: 0.7516658\ttotal: 19.8s\tremaining: 47.9s\n",
      "110:\tlearn: 0.7492122\ttotal: 20s\tremaining: 47.7s\n",
      "111:\tlearn: 0.7470009\ttotal: 20.2s\tremaining: 47.6s\n",
      "112:\tlearn: 0.7451547\ttotal: 20.4s\tremaining: 47.4s\n",
      "113:\tlearn: 0.7421463\ttotal: 20.6s\tremaining: 47.2s\n",
      "114:\tlearn: 0.7395453\ttotal: 20.7s\tremaining: 47s\n",
      "115:\tlearn: 0.7374516\ttotal: 20.9s\tremaining: 46.8s\n",
      "116:\tlearn: 0.7340719\ttotal: 21.1s\tremaining: 46.7s\n",
      "117:\tlearn: 0.7317985\ttotal: 21.3s\tremaining: 46.5s\n",
      "118:\tlearn: 0.7292707\ttotal: 21.5s\tremaining: 46.4s\n",
      "119:\tlearn: 0.7272798\ttotal: 21.7s\tremaining: 46.3s\n",
      "120:\tlearn: 0.7253802\ttotal: 22s\tremaining: 46.3s\n",
      "121:\tlearn: 0.7235909\ttotal: 22.1s\tremaining: 46.1s\n",
      "122:\tlearn: 0.7214167\ttotal: 22.3s\tremaining: 45.9s\n",
      "123:\tlearn: 0.7191374\ttotal: 22.5s\tremaining: 45.7s\n",
      "124:\tlearn: 0.7172639\ttotal: 22.7s\tremaining: 45.5s\n",
      "125:\tlearn: 0.7147794\ttotal: 22.8s\tremaining: 45.3s\n",
      "126:\tlearn: 0.7126570\ttotal: 23s\tremaining: 45.1s\n",
      "127:\tlearn: 0.7104993\ttotal: 23.2s\tremaining: 44.9s\n",
      "128:\tlearn: 0.7077104\ttotal: 23.3s\tremaining: 44.7s\n",
      "129:\tlearn: 0.7053256\ttotal: 23.5s\tremaining: 44.4s\n",
      "130:\tlearn: 0.7034066\ttotal: 23.7s\tremaining: 44.2s\n",
      "131:\tlearn: 0.7011274\ttotal: 23.8s\tremaining: 44.1s\n",
      "132:\tlearn: 0.6989666\ttotal: 24s\tremaining: 43.9s\n",
      "133:\tlearn: 0.6967234\ttotal: 24.2s\tremaining: 43.7s\n",
      "134:\tlearn: 0.6947447\ttotal: 24.4s\tremaining: 43.5s\n",
      "135:\tlearn: 0.6924667\ttotal: 24.5s\tremaining: 43.3s\n",
      "136:\tlearn: 0.6908263\ttotal: 24.7s\tremaining: 43.2s\n",
      "137:\tlearn: 0.6885581\ttotal: 24.9s\tremaining: 43s\n",
      "138:\tlearn: 0.6865988\ttotal: 25.1s\tremaining: 42.8s\n",
      "139:\tlearn: 0.6843930\ttotal: 25.3s\tremaining: 42.7s\n",
      "140:\tlearn: 0.6822718\ttotal: 25.5s\tremaining: 42.5s\n",
      "141:\tlearn: 0.6799179\ttotal: 25.7s\tremaining: 42.3s\n",
      "142:\tlearn: 0.6779813\ttotal: 25.9s\tremaining: 42.1s\n",
      "143:\tlearn: 0.6757508\ttotal: 26s\tremaining: 41.9s\n",
      "144:\tlearn: 0.6735467\ttotal: 26.2s\tremaining: 41.7s\n",
      "145:\tlearn: 0.6715564\ttotal: 26.4s\tremaining: 41.5s\n",
      "146:\tlearn: 0.6697542\ttotal: 26.5s\tremaining: 41.3s\n",
      "147:\tlearn: 0.6680763\ttotal: 26.7s\tremaining: 41.1s\n",
      "148:\tlearn: 0.6658345\ttotal: 26.9s\tremaining: 40.9s\n",
      "149:\tlearn: 0.6640165\ttotal: 27s\tremaining: 40.7s\n",
      "150:\tlearn: 0.6618523\ttotal: 27.2s\tremaining: 40.5s\n",
      "151:\tlearn: 0.6597714\ttotal: 27.4s\tremaining: 40.3s\n",
      "152:\tlearn: 0.6576061\ttotal: 27.5s\tremaining: 40.1s\n",
      "153:\tlearn: 0.6556532\ttotal: 27.7s\tremaining: 39.9s\n",
      "154:\tlearn: 0.6541966\ttotal: 27.8s\tremaining: 39.7s\n",
      "155:\tlearn: 0.6525291\ttotal: 28s\tremaining: 39.5s\n",
      "156:\tlearn: 0.6508776\ttotal: 28.2s\tremaining: 39.3s\n",
      "157:\tlearn: 0.6491627\ttotal: 28.3s\tremaining: 39s\n",
      "158:\tlearn: 0.6475686\ttotal: 28.5s\tremaining: 38.8s\n",
      "159:\tlearn: 0.6459997\ttotal: 28.6s\tremaining: 38.6s\n",
      "160:\tlearn: 0.6443942\ttotal: 28.8s\tremaining: 38.4s\n",
      "161:\tlearn: 0.6425162\ttotal: 28.9s\tremaining: 38.2s\n",
      "162:\tlearn: 0.6413159\ttotal: 29.1s\tremaining: 38s\n",
      "163:\tlearn: 0.6398215\ttotal: 29.2s\tremaining: 37.8s\n",
      "164:\tlearn: 0.6379712\ttotal: 29.4s\tremaining: 37.6s\n",
      "165:\tlearn: 0.6360383\ttotal: 29.6s\tremaining: 37.4s\n",
      "166:\tlearn: 0.6341922\ttotal: 29.7s\tremaining: 37.2s\n",
      "167:\tlearn: 0.6327833\ttotal: 29.9s\tremaining: 37s\n",
      "168:\tlearn: 0.6309329\ttotal: 30s\tremaining: 36.8s\n",
      "169:\tlearn: 0.6292560\ttotal: 30.2s\tremaining: 36.6s\n",
      "170:\tlearn: 0.6277832\ttotal: 30.3s\tremaining: 36.4s\n",
      "171:\tlearn: 0.6259223\ttotal: 30.5s\tremaining: 36.2s\n",
      "172:\tlearn: 0.6239792\ttotal: 30.7s\tremaining: 36s\n",
      "173:\tlearn: 0.6218907\ttotal: 30.8s\tremaining: 35.8s\n",
      "174:\tlearn: 0.6206021\ttotal: 31s\tremaining: 35.6s\n",
      "175:\tlearn: 0.6187843\ttotal: 31.1s\tremaining: 35.4s\n",
      "176:\tlearn: 0.6173487\ttotal: 31.3s\tremaining: 35.2s\n",
      "177:\tlearn: 0.6160704\ttotal: 31.5s\tremaining: 35s\n",
      "178:\tlearn: 0.6147026\ttotal: 31.7s\tremaining: 34.9s\n",
      "179:\tlearn: 0.6130391\ttotal: 31.9s\tremaining: 34.7s\n",
      "180:\tlearn: 0.6110430\ttotal: 32s\tremaining: 34.5s\n",
      "181:\tlearn: 0.6089130\ttotal: 32.2s\tremaining: 34.3s\n",
      "182:\tlearn: 0.6076901\ttotal: 32.3s\tremaining: 34.1s\n",
      "183:\tlearn: 0.6057498\ttotal: 32.5s\tremaining: 33.9s\n",
      "184:\tlearn: 0.6041265\ttotal: 32.6s\tremaining: 33.7s\n",
      "185:\tlearn: 0.6025480\ttotal: 32.8s\tremaining: 33.5s\n",
      "186:\tlearn: 0.6013619\ttotal: 32.9s\tremaining: 33.3s\n",
      "187:\tlearn: 0.5996598\ttotal: 33.1s\tremaining: 33.1s\n",
      "188:\tlearn: 0.5981266\ttotal: 33.2s\tremaining: 32.9s\n",
      "189:\tlearn: 0.5967982\ttotal: 33.4s\tremaining: 32.7s\n",
      "190:\tlearn: 0.5946551\ttotal: 33.5s\tremaining: 32.5s\n",
      "191:\tlearn: 0.5928252\ttotal: 33.7s\tremaining: 32.3s\n",
      "192:\tlearn: 0.5913892\ttotal: 33.8s\tremaining: 32.1s\n",
      "193:\tlearn: 0.5899183\ttotal: 34s\tremaining: 31.9s\n",
      "194:\tlearn: 0.5881687\ttotal: 34.2s\tremaining: 31.8s\n",
      "195:\tlearn: 0.5867935\ttotal: 34.4s\tremaining: 31.6s\n",
      "196:\tlearn: 0.5852904\ttotal: 34.5s\tremaining: 31.4s\n",
      "197:\tlearn: 0.5838867\ttotal: 34.7s\tremaining: 31.2s\n",
      "198:\tlearn: 0.5823637\ttotal: 34.9s\tremaining: 31s\n",
      "199:\tlearn: 0.5808432\ttotal: 35s\tremaining: 30.8s\n",
      "200:\tlearn: 0.5790651\ttotal: 35.2s\tremaining: 30.6s\n",
      "201:\tlearn: 0.5775396\ttotal: 35.4s\tremaining: 30.5s\n",
      "202:\tlearn: 0.5764472\ttotal: 35.5s\tremaining: 30.3s\n",
      "203:\tlearn: 0.5745467\ttotal: 35.7s\tremaining: 30.1s\n",
      "204:\tlearn: 0.5726986\ttotal: 35.9s\tremaining: 29.9s\n",
      "205:\tlearn: 0.5707353\ttotal: 36s\tremaining: 29.7s\n",
      "206:\tlearn: 0.5686519\ttotal: 36.2s\tremaining: 29.5s\n",
      "207:\tlearn: 0.5671594\ttotal: 36.4s\tremaining: 29.4s\n",
      "208:\tlearn: 0.5654855\ttotal: 36.5s\tremaining: 29.2s\n",
      "209:\tlearn: 0.5637226\ttotal: 36.7s\tremaining: 29s\n",
      "210:\tlearn: 0.5621279\ttotal: 36.9s\tremaining: 28.8s\n",
      "211:\tlearn: 0.5609213\ttotal: 37s\tremaining: 28.6s\n",
      "212:\tlearn: 0.5590251\ttotal: 37.2s\tremaining: 28.5s\n",
      "213:\tlearn: 0.5577820\ttotal: 37.4s\tremaining: 28.3s\n",
      "214:\tlearn: 0.5559329\ttotal: 37.5s\tremaining: 28.1s\n",
      "215:\tlearn: 0.5540651\ttotal: 37.7s\tremaining: 27.9s\n",
      "216:\tlearn: 0.5524356\ttotal: 37.9s\tremaining: 27.7s\n",
      "217:\tlearn: 0.5510560\ttotal: 38s\tremaining: 27.6s\n",
      "218:\tlearn: 0.5494815\ttotal: 38.2s\tremaining: 27.4s\n",
      "219:\tlearn: 0.5473873\ttotal: 38.3s\tremaining: 27.2s\n",
      "220:\tlearn: 0.5454228\ttotal: 38.5s\tremaining: 27s\n",
      "221:\tlearn: 0.5439899\ttotal: 38.7s\tremaining: 26.8s\n",
      "222:\tlearn: 0.5425544\ttotal: 38.8s\tremaining: 26.7s\n",
      "223:\tlearn: 0.5404799\ttotal: 39s\tremaining: 26.5s\n",
      "224:\tlearn: 0.5391839\ttotal: 39.2s\tremaining: 26.3s\n",
      "225:\tlearn: 0.5374205\ttotal: 39.4s\tremaining: 26.1s\n",
      "226:\tlearn: 0.5359812\ttotal: 39.6s\tremaining: 26s\n",
      "227:\tlearn: 0.5345945\ttotal: 39.7s\tremaining: 25.8s\n",
      "228:\tlearn: 0.5329682\ttotal: 39.9s\tremaining: 25.6s\n",
      "229:\tlearn: 0.5319833\ttotal: 40.1s\tremaining: 25.4s\n",
      "230:\tlearn: 0.5305734\ttotal: 40.2s\tremaining: 25.3s\n",
      "231:\tlearn: 0.5287965\ttotal: 40.4s\tremaining: 25.1s\n",
      "232:\tlearn: 0.5271673\ttotal: 40.6s\tremaining: 24.9s\n",
      "233:\tlearn: 0.5256816\ttotal: 40.7s\tremaining: 24.7s\n",
      "234:\tlearn: 0.5243995\ttotal: 40.9s\tremaining: 24.5s\n",
      "235:\tlearn: 0.5227831\ttotal: 41.1s\tremaining: 24.4s\n",
      "236:\tlearn: 0.5214366\ttotal: 41.2s\tremaining: 24.2s\n",
      "237:\tlearn: 0.5196522\ttotal: 41.4s\tremaining: 24s\n",
      "238:\tlearn: 0.5189293\ttotal: 41.6s\tremaining: 23.8s\n",
      "239:\tlearn: 0.5173088\ttotal: 41.7s\tremaining: 23.7s\n",
      "240:\tlearn: 0.5159667\ttotal: 41.9s\tremaining: 23.5s\n",
      "241:\tlearn: 0.5145037\ttotal: 42s\tremaining: 23.3s\n",
      "242:\tlearn: 0.5129890\ttotal: 42.2s\tremaining: 23.1s\n",
      "243:\tlearn: 0.5113642\ttotal: 42.4s\tremaining: 22.9s\n",
      "244:\tlearn: 0.5101182\ttotal: 42.5s\tremaining: 22.7s\n",
      "245:\tlearn: 0.5081507\ttotal: 42.7s\tremaining: 22.5s\n",
      "246:\tlearn: 0.5067677\ttotal: 42.8s\tremaining: 22.4s\n",
      "247:\tlearn: 0.5051572\ttotal: 43s\tremaining: 22.2s\n",
      "248:\tlearn: 0.5034594\ttotal: 43.2s\tremaining: 22s\n",
      "249:\tlearn: 0.5021665\ttotal: 43.3s\tremaining: 21.8s\n",
      "250:\tlearn: 0.5004780\ttotal: 43.5s\tremaining: 21.6s\n",
      "251:\tlearn: 0.4986656\ttotal: 43.6s\tremaining: 21.5s\n",
      "252:\tlearn: 0.4974104\ttotal: 43.8s\tremaining: 21.3s\n",
      "253:\tlearn: 0.4961062\ttotal: 43.9s\tremaining: 21.1s\n",
      "254:\tlearn: 0.4948137\ttotal: 44.1s\tremaining: 20.9s\n",
      "255:\tlearn: 0.4933745\ttotal: 44.3s\tremaining: 20.7s\n",
      "256:\tlearn: 0.4922056\ttotal: 44.4s\tremaining: 20.6s\n",
      "257:\tlearn: 0.4906244\ttotal: 44.6s\tremaining: 20.4s\n",
      "258:\tlearn: 0.4890348\ttotal: 44.7s\tremaining: 20.2s\n",
      "259:\tlearn: 0.4877840\ttotal: 44.9s\tremaining: 20s\n",
      "260:\tlearn: 0.4862995\ttotal: 45s\tremaining: 19.8s\n",
      "261:\tlearn: 0.4850333\ttotal: 45.2s\tremaining: 19.7s\n",
      "262:\tlearn: 0.4835400\ttotal: 45.3s\tremaining: 19.5s\n",
      "263:\tlearn: 0.4821214\ttotal: 45.5s\tremaining: 19.3s\n",
      "264:\tlearn: 0.4807994\ttotal: 45.6s\tremaining: 19.1s\n",
      "265:\tlearn: 0.4794165\ttotal: 45.8s\tremaining: 18.9s\n",
      "266:\tlearn: 0.4777213\ttotal: 46s\tremaining: 18.8s\n",
      "267:\tlearn: 0.4763939\ttotal: 46.1s\tremaining: 18.6s\n",
      "268:\tlearn: 0.4745710\ttotal: 46.3s\tremaining: 18.4s\n",
      "269:\tlearn: 0.4731020\ttotal: 46.4s\tremaining: 18.2s\n",
      "270:\tlearn: 0.4720451\ttotal: 46.6s\tremaining: 18.1s\n",
      "271:\tlearn: 0.4704748\ttotal: 46.8s\tremaining: 17.9s\n",
      "272:\tlearn: 0.4693856\ttotal: 46.9s\tremaining: 17.7s\n",
      "273:\tlearn: 0.4688682\ttotal: 47.1s\tremaining: 17.5s\n",
      "274:\tlearn: 0.4674645\ttotal: 47.2s\tremaining: 17.4s\n",
      "275:\tlearn: 0.4659662\ttotal: 47.4s\tremaining: 17.2s\n",
      "276:\tlearn: 0.4648376\ttotal: 47.6s\tremaining: 17s\n",
      "277:\tlearn: 0.4635588\ttotal: 47.7s\tremaining: 16.8s\n",
      "278:\tlearn: 0.4625984\ttotal: 47.9s\tremaining: 16.6s\n",
      "279:\tlearn: 0.4614324\ttotal: 48s\tremaining: 16.5s\n",
      "280:\tlearn: 0.4601045\ttotal: 48.2s\tremaining: 16.3s\n",
      "281:\tlearn: 0.4586942\ttotal: 48.4s\tremaining: 16.1s\n",
      "282:\tlearn: 0.4572316\ttotal: 48.5s\tremaining: 15.9s\n",
      "283:\tlearn: 0.4557779\ttotal: 48.7s\tremaining: 15.8s\n",
      "284:\tlearn: 0.4542892\ttotal: 48.8s\tremaining: 15.6s\n",
      "285:\tlearn: 0.4525940\ttotal: 49s\tremaining: 15.4s\n",
      "286:\tlearn: 0.4514687\ttotal: 49.1s\tremaining: 15.2s\n",
      "287:\tlearn: 0.4498793\ttotal: 49.3s\tremaining: 15.1s\n",
      "288:\tlearn: 0.4482756\ttotal: 49.4s\tremaining: 14.9s\n",
      "289:\tlearn: 0.4467034\ttotal: 49.6s\tremaining: 14.7s\n",
      "290:\tlearn: 0.4451703\ttotal: 49.8s\tremaining: 14.5s\n",
      "291:\tlearn: 0.4438334\ttotal: 49.9s\tremaining: 14.4s\n",
      "292:\tlearn: 0.4427513\ttotal: 50.1s\tremaining: 14.2s\n",
      "293:\tlearn: 0.4414896\ttotal: 50.3s\tremaining: 14s\n",
      "294:\tlearn: 0.4399562\ttotal: 50.4s\tremaining: 13.8s\n",
      "295:\tlearn: 0.4384038\ttotal: 50.6s\tremaining: 13.7s\n",
      "296:\tlearn: 0.4367530\ttotal: 50.7s\tremaining: 13.5s\n",
      "297:\tlearn: 0.4360390\ttotal: 50.9s\tremaining: 13.3s\n",
      "298:\tlearn: 0.4348633\ttotal: 51.1s\tremaining: 13.2s\n",
      "299:\tlearn: 0.4337560\ttotal: 51.3s\tremaining: 13s\n",
      "300:\tlearn: 0.4326908\ttotal: 51.4s\tremaining: 12.8s\n",
      "301:\tlearn: 0.4312907\ttotal: 51.6s\tremaining: 12.6s\n",
      "302:\tlearn: 0.4298114\ttotal: 51.8s\tremaining: 12.5s\n",
      "303:\tlearn: 0.4284447\ttotal: 51.9s\tremaining: 12.3s\n",
      "304:\tlearn: 0.4270050\ttotal: 52.1s\tremaining: 12.1s\n",
      "305:\tlearn: 0.4255263\ttotal: 52.3s\tremaining: 12s\n",
      "306:\tlearn: 0.4240058\ttotal: 52.4s\tremaining: 11.8s\n",
      "307:\tlearn: 0.4225882\ttotal: 52.6s\tremaining: 11.6s\n",
      "308:\tlearn: 0.4214734\ttotal: 52.8s\tremaining: 11.4s\n",
      "309:\tlearn: 0.4203024\ttotal: 53s\tremaining: 11.3s\n",
      "310:\tlearn: 0.4193888\ttotal: 53.1s\tremaining: 11.1s\n",
      "311:\tlearn: 0.4181881\ttotal: 53.3s\tremaining: 10.9s\n",
      "312:\tlearn: 0.4170954\ttotal: 53.4s\tremaining: 10.8s\n",
      "313:\tlearn: 0.4159976\ttotal: 53.6s\tremaining: 10.6s\n",
      "314:\tlearn: 0.4147298\ttotal: 53.8s\tremaining: 10.4s\n",
      "315:\tlearn: 0.4134713\ttotal: 53.9s\tremaining: 10.2s\n",
      "316:\tlearn: 0.4122305\ttotal: 54.1s\tremaining: 10.1s\n",
      "317:\tlearn: 0.4109380\ttotal: 54.3s\tremaining: 9.9s\n",
      "318:\tlearn: 0.4101913\ttotal: 54.4s\tremaining: 9.73s\n",
      "319:\tlearn: 0.4092671\ttotal: 54.6s\tremaining: 9.56s\n",
      "320:\tlearn: 0.4079093\ttotal: 54.8s\tremaining: 9.38s\n",
      "321:\tlearn: 0.4070367\ttotal: 55s\tremaining: 9.21s\n",
      "322:\tlearn: 0.4060012\ttotal: 55.1s\tremaining: 9.04s\n",
      "323:\tlearn: 0.4047235\ttotal: 55.3s\tremaining: 8.87s\n",
      "324:\tlearn: 0.4035911\ttotal: 55.4s\tremaining: 8.7s\n",
      "325:\tlearn: 0.4020924\ttotal: 55.6s\tremaining: 8.53s\n",
      "326:\tlearn: 0.4010913\ttotal: 55.8s\tremaining: 8.36s\n",
      "327:\tlearn: 0.3999120\ttotal: 55.9s\tremaining: 8.19s\n",
      "328:\tlearn: 0.3990216\ttotal: 56.1s\tremaining: 8.01s\n",
      "329:\tlearn: 0.3980433\ttotal: 56.3s\tremaining: 7.84s\n",
      "330:\tlearn: 0.3969166\ttotal: 56.4s\tremaining: 7.67s\n",
      "331:\tlearn: 0.3961561\ttotal: 56.6s\tremaining: 7.5s\n",
      "332:\tlearn: 0.3949095\ttotal: 56.8s\tremaining: 7.33s\n",
      "333:\tlearn: 0.3940684\ttotal: 56.9s\tremaining: 7.16s\n",
      "334:\tlearn: 0.3932732\ttotal: 57.1s\tremaining: 6.99s\n",
      "335:\tlearn: 0.3922538\ttotal: 57.3s\tremaining: 6.82s\n",
      "336:\tlearn: 0.3911502\ttotal: 57.4s\tremaining: 6.65s\n",
      "337:\tlearn: 0.3902924\ttotal: 57.6s\tremaining: 6.48s\n",
      "338:\tlearn: 0.3896188\ttotal: 57.8s\tremaining: 6.3s\n",
      "339:\tlearn: 0.3884567\ttotal: 57.9s\tremaining: 6.13s\n",
      "340:\tlearn: 0.3874017\ttotal: 58.1s\tremaining: 5.96s\n",
      "341:\tlearn: 0.3863786\ttotal: 58.3s\tremaining: 5.79s\n",
      "342:\tlearn: 0.3852082\ttotal: 58.4s\tremaining: 5.62s\n",
      "343:\tlearn: 0.3843723\ttotal: 58.6s\tremaining: 5.45s\n",
      "344:\tlearn: 0.3834701\ttotal: 58.8s\tremaining: 5.28s\n",
      "345:\tlearn: 0.3824851\ttotal: 58.9s\tremaining: 5.11s\n",
      "346:\tlearn: 0.3813656\ttotal: 59.1s\tremaining: 4.94s\n",
      "347:\tlearn: 0.3805068\ttotal: 59.2s\tremaining: 4.76s\n",
      "348:\tlearn: 0.3793230\ttotal: 59.4s\tremaining: 4.59s\n",
      "349:\tlearn: 0.3780916\ttotal: 59.5s\tremaining: 4.42s\n",
      "350:\tlearn: 0.3771215\ttotal: 59.7s\tremaining: 4.25s\n",
      "351:\tlearn: 0.3761645\ttotal: 59.8s\tremaining: 4.08s\n",
      "352:\tlearn: 0.3752378\ttotal: 60s\tremaining: 3.91s\n",
      "353:\tlearn: 0.3745091\ttotal: 1m\tremaining: 3.74s\n",
      "354:\tlearn: 0.3733792\ttotal: 1m\tremaining: 3.57s\n",
      "355:\tlearn: 0.3725964\ttotal: 1m\tremaining: 3.4s\n",
      "356:\tlearn: 0.3717018\ttotal: 1m\tremaining: 3.23s\n",
      "357:\tlearn: 0.3706515\ttotal: 1m\tremaining: 3.06s\n",
      "358:\tlearn: 0.3693656\ttotal: 1m\tremaining: 2.88s\n",
      "359:\tlearn: 0.3683702\ttotal: 1m 1s\tremaining: 2.71s\n",
      "360:\tlearn: 0.3674382\ttotal: 1m 1s\tremaining: 2.54s\n",
      "361:\tlearn: 0.3667452\ttotal: 1m 1s\tremaining: 2.38s\n",
      "362:\tlearn: 0.3658988\ttotal: 1m 1s\tremaining: 2.21s\n",
      "363:\tlearn: 0.3649200\ttotal: 1m 1s\tremaining: 2.04s\n",
      "364:\tlearn: 0.3640018\ttotal: 1m 1s\tremaining: 1.86s\n",
      "365:\tlearn: 0.3627636\ttotal: 1m 2s\tremaining: 1.7s\n",
      "366:\tlearn: 0.3620188\ttotal: 1m 2s\tremaining: 1.52s\n",
      "367:\tlearn: 0.3609034\ttotal: 1m 2s\tremaining: 1.35s\n",
      "368:\tlearn: 0.3600809\ttotal: 1m 2s\tremaining: 1.19s\n",
      "369:\tlearn: 0.3592750\ttotal: 1m 2s\tremaining: 1.02s\n",
      "370:\tlearn: 0.3583085\ttotal: 1m 2s\tremaining: 847ms\n",
      "371:\tlearn: 0.3578103\ttotal: 1m 2s\tremaining: 677ms\n",
      "372:\tlearn: 0.3567479\ttotal: 1m 3s\tremaining: 508ms\n",
      "373:\tlearn: 0.3561629\ttotal: 1m 3s\tremaining: 339ms\n",
      "374:\tlearn: 0.3552741\ttotal: 1m 3s\tremaining: 169ms\n",
      "375:\tlearn: 0.3545197\ttotal: 1m 3s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "optuna_cbc = CatBoostClassifier(iterations=376, depth=7, learning_rate=0.03591338854313402, l2_leaf_reg=4.806012493315716, border_count=79)\n",
    "optuna_cbc.fit(X_train,y_train)\n",
    "optuna_cbc_preds = optuna_cbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886f8271-79b0-4205-bae1-5d87a3504978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.65      0.63      0.64        41\n",
      "          Q2       0.71      0.75      0.73        40\n",
      "          Q3       0.65      0.61      0.63        28\n",
      "          Q4       0.59      0.62      0.60        26\n",
      "\n",
      "    accuracy                           0.66       135\n",
      "   macro avg       0.65      0.65      0.65       135\n",
      "weighted avg       0.66      0.66      0.66       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,optuna_cbc_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
