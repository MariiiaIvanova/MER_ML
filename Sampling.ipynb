{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0681c2a0-2fda-4166-8841-974e230b2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import mode\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f61a4-829b-43cd-9afd-6a2abdf4c529",
   "metadata": {},
   "source": [
    "# Извлечение данных. Треки длительностью 6 секунд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00d11cc-7f9c-48f9-94f2-94f1a93f4604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 4111 интервалов.\n",
      "Форма массива хромаграмм: (4111, 336)\n",
      "Форма массива MFCC: (4111, 40)\n",
      "Форма массива Mel-спектрограмм: (4111, 128)\n"
     ]
    }
   ],
   "source": [
    "# Папка с аудиофайлами\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "\n",
    "# Списки для хранения признаков и имен файлов\n",
    "chroma_features_list = []\n",
    "mel_list = []\n",
    "mfcc_list = []\n",
    "tempo_list = []\n",
    "file_names = []\n",
    "\n",
    "# Размер интервала в секундах\n",
    "interval_duration = 6  # секунды\n",
    "\n",
    "for file in files:\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "\n",
    "    # Определяем длину трека в секундах\n",
    "    track_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    # Разбиваем трек на интервалы по 6 секунд\n",
    "    num_intervals = int(track_duration // interval_duration)\n",
    "\n",
    "    # Обрабатываем каждый интервал по очереди\n",
    "    for i in range(num_intervals):\n",
    "        start_sample = i * interval_duration * sr\n",
    "        end_sample = (i + 1) * interval_duration * sr\n",
    "        y_interval = y[int(start_sample):int(end_sample)]\n",
    "\n",
    "        # Извлекаем признаки для каждого интервала\n",
    "\n",
    "        def extract_statistics(feature):\n",
    "            return np.hstack([\n",
    "                np.mean(feature, axis=1),    # Среднее\n",
    "                np.std(feature, axis=1),     # Стандартное отклонение\n",
    "                np.median(feature, axis=1),  # Медиана\n",
    "                np.max(feature, axis=1) - np.min(feature, axis=1)  # Размах\n",
    "            ])\n",
    "\n",
    "        # 1. Хромаграмма CQT\n",
    "        chroma_cqt = librosa.feature.chroma_cqt(y=y_interval, sr=sr, bins_per_octave=60, n_chroma=60)\n",
    "        chroma_cqt = np.log1p(chroma_cqt)\n",
    "        chroma_cqt_stats = extract_statistics(chroma_cqt)\n",
    "\n",
    "        # 2. Хромаграмма STFT\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y_interval, sr=sr)\n",
    "        chroma_stft = np.log1p(chroma_stft)\n",
    "        chroma_stft_stats = extract_statistics(chroma_stft)\n",
    "\n",
    "        # 3. Хромаграмма CENS\n",
    "        chroma_cens = librosa.feature.chroma_cens(y=y_interval, sr=sr)\n",
    "        chroma_cens = np.log1p(chroma_cens)\n",
    "        chroma_cens_stats = extract_statistics(chroma_cens)\n",
    "\n",
    "        # Объединяем хромаграммы в один вектор\n",
    "        chroma_features = np.hstack([chroma_cqt_stats, chroma_stft_stats, chroma_cens_stats])\n",
    "\n",
    "        # 4. Mel-спектрограмма\n",
    "        mel = librosa.feature.melspectrogram(y=y_interval, sr=sr)\n",
    "        mel_list.append(mel.mean(axis=1))\n",
    "\n",
    "        # 5. MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y_interval, sr=sr, n_mfcc=40)\n",
    "        mfcc_list.append(mfcc.mean(axis=1))\n",
    "\n",
    "        # 6. Темп (BPM)\n",
    "        tempo, _ = librosa.beat.beat_track(y=y_interval, sr=sr)\n",
    "        tempo_list.append(tempo)\n",
    "\n",
    "        # Добавляем признаки в список\n",
    "        chroma_features_list.append(chroma_features)\n",
    "        file_names.append(file)\n",
    "\n",
    "# Преобразуем в numpy массив\n",
    "chroma_array = np.array(chroma_features_list)\n",
    "mel_array = np.array(mel_list)\n",
    "mfcc_array = np.array(mfcc_list)\n",
    "\n",
    "# Нормализация признаков\n",
    "scaler = StandardScaler()\n",
    "chroma_array_scaled = scaler.fit_transform(chroma_array)\n",
    "mel_array_scaled = scaler.fit_transform(mel_array)\n",
    "mfcc_array_scaled = scaler.fit_transform(mfcc_array)\n",
    "\n",
    "# Выводим информацию о данных\n",
    "print(f'Обработано {len(chroma_features_list)} интервалов.')\n",
    "print(f'Форма массива хромаграмм: {chroma_array_scaled.shape}')\n",
    "print(f'Форма массива MFCC: {mfcc_array_scaled.shape}')\n",
    "print(f'Форма массива Mel-спектрограмм: {mel_array_scaled.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdd97da-4677-42b3-85e9-617d6dde7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT0000004637.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000011357.mp3: 29.18 сек → 4 интервалов\n",
      "MT0000011975.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000040632.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000044741.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000054705.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000082187.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000088320.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000092267.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000133200.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000202045.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000203193.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000203272.mp3: 29.13 сек → 4 интервалов\n",
      "MT0000216849.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000218346.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000235880.mp3: 29.94 сек → 4 интервалов\n",
      "MT0000249842.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000255724.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000299291.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000300896.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000315392.mp3: 30.10 сек → 5 интервалов\n",
      "MT0000336135.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000348553.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000364027.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000369789.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000377411.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000379144.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000392975.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000414517.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000426771.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000441552.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000442827.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000446304.mp3: 30.10 сек → 5 интервалов\n",
      "MT0000456939.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000460427.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000522789.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000523076.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000534539.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000540286.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000550961.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000636335.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000661250.mp3: 29.13 сек → 4 интервалов\n",
      "MT0000661847.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000664362.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000698081.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000711493.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000729701.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000732821.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000742898.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000746822.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000762097.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000764951.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000796526.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000821772.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000888329.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000901959.mp3: 29.99 сек → 4 интервалов\n",
      "MT0000922312.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000941301.mp3: 29.94 сек → 4 интервалов\n",
      "MT0000949813.mp3: 29.94 сек → 4 интервалов\n",
      "MT0000956340.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000971834.mp3: 30.06 сек → 5 интервалов\n",
      "MT0000980148.mp3: 28.93 сек → 4 интервалов\n",
      "MT0000992846.mp3: 30.10 сек → 5 интервалов\n",
      "MT0001052263.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001053268.mp3: 30.02 сек → 5 интервалов\n",
      "MT0001058887.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001109401.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001189913.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001193971.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001195535.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001217651.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001236649.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001284801.mp3: 29.81 сек → 4 интервалов\n",
      "MT0001333258.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001335920.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001340713.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001376988.mp3: 30.10 сек → 5 интервалов\n",
      "MT0001394087.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001418045.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001419145.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001438043.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001472536.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001494812.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001511433.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001515531.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001521543.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001523435.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001526386.mp3: 29.95 сек → 4 интервалов\n",
      "MT0001533920.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001542676.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001583214.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001586807.mp3: 29.94 сек → 4 интервалов\n",
      "MT0001594582.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001605268.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001613887.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001615005.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001624303.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001641228.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001661022.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001671399.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001673884.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001676671.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001680969.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001703346.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001753457.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001757676.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001766004.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001768550.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001810607.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001844620.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001870847.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001871732.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001877603.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001891229.mp3: 29.94 сек → 4 интервалов\n",
      "MT0001898830.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001920501.mp3: 29.81 сек → 4 интервалов\n",
      "MT0001927746.mp3: 29.95 сек → 4 интервалов\n",
      "MT0001929641.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001934726.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001938929.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001942272.mp3: 29.16 сек → 4 интервалов\n",
      "MT0001962373.mp3: 29.86 сек → 4 интервалов\n",
      "MT0001967374.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001972380.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001975228.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001980613.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001982863.mp3: 30.06 сек → 5 интервалов\n",
      "MT0001993588.mp3: 29.15 сек → 4 интервалов\n",
      "MT0002006203.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002033629.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002050671.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002053300.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002057142.mp3: 30.13 сек → 5 интервалов\n",
      "MT0002070112.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002086401.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002087541.mp3: 29.95 сек → 4 интервалов\n",
      "MT0002119439.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002124238.mp3: 29.86 сек → 4 интервалов\n",
      "MT0002126934.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002132088.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002142155.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002161109.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002222957.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002233402.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002262181.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002297016.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002351905.mp3: 29.16 сек → 4 интервалов\n",
      "MT0002366291.mp3: 29.16 сек → 4 интервалов\n",
      "MT0002372242.mp3: 29.91 сек → 4 интервалов\n",
      "MT0002379222.mp3: 30.10 сек → 5 интервалов\n",
      "MT0002385077.mp3: 27.18 сек → 4 интервалов\n",
      "MT0002391847.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002399275.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002415184.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002448379.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002479795.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002485672.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002525905.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002532237.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002536460.mp3: 29.96 сек → 4 интервалов\n",
      "MT0002538335.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002595792.mp3: 30.10 сек → 5 интервалов\n",
      "MT0002602057.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002634024.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002674708.mp3: 29.81 сек → 4 интервалов\n",
      "MT0002698706.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002698827.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002714805.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002760912.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002794078.mp3: 29.86 сек → 4 интервалов\n",
      "MT0002811975.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002834532.mp3: 29.94 сек → 4 интервалов\n",
      "MT0002846256.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002894033.mp3: 29.13 сек → 4 интервалов\n",
      "MT0002915967.mp3: 30.06 сек → 5 интервалов\n",
      "MT0002960683.mp3: 29.95 сек → 4 интервалов\n",
      "MT0002986568.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003019852.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003022328.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003025046.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003037596.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003037754.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003044417.mp3: 29.94 сек → 4 интервалов\n",
      "MT0003053135.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003101727.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003106472.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003114552.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003129858.mp3: 30.10 сек → 5 интервалов\n",
      "MT0003136077.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003144898.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003170370.mp3: 29.94 сек → 4 интервалов\n",
      "MT0003209662.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003213835.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003243311.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003248394.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003262589.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003272751.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003280103.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003286463.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003300388.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003311798.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003326925.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003349423.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003352308.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003362542.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003366948.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003390733.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003396470.mp3: 29.94 сек → 4 интервалов\n",
      "MT0003402538.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003420996.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003435704.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003442366.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003454112.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003462877.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003501434.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003530174.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003542756.mp3: 29.94 сек → 4 интервалов\n",
      "MT0003546058.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003570082.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003594672.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003601752.mp3: 29.94 сек → 4 интервалов\n",
      "MT0003603772.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003639120.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003669917.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003710207.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003724610.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003778826.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003782002.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003787478.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003788939.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003794106.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003807077.mp3: 30.10 сек → 5 интервалов\n",
      "MT0003863509.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003900455.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003903675.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003930610.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003935485.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003949060.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003956612.mp3: 30.06 сек → 5 интервалов\n",
      "MT0003968586.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004027946.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004028719.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004032071.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004036096.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004037272.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004068560.mp3: 30.02 сек → 5 интервалов\n",
      "MT0004082588.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004085907.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004089549.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004093767.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004122617.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004131058.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004141823.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004232099.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004263956.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004274911.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004287283.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004290389.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004293364.mp3: 30.02 сек → 5 интервалов\n",
      "MT0004316859.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004331116.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004339430.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004342301.mp3: 29.86 сек → 4 интервалов\n",
      "MT0004428604.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004447086.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004447226.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004459450.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004511265.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004537445.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004558461.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004584067.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004609722.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004645468.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004669603.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004683099.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004693207.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004711079.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004715422.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004751933.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004759106.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004759588.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004807446.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004817670.mp3: 29.94 сек → 4 интервалов\n",
      "MT0004833310.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004840819.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004842694.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004850690.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004867185.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004867564.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004882280.mp3: 29.86 сек → 4 интервалов\n",
      "MT0004896738.mp3: 29.15 сек → 4 интервалов\n",
      "MT0004911454.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004922692.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004942017.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004956006.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004958762.mp3: 29.99 сек → 4 интервалов\n",
      "MT0004978135.mp3: 30.06 сек → 5 интервалов\n",
      "MT0004988249.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005001966.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005003824.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005026798.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005029328.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005039941.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005074629.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005083488.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005091539.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005115042.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005129157.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005155949.mp3: 29.94 сек → 4 интервалов\n",
      "MT0005157391.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005163122.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005171805.mp3: 25.94 сек → 4 интервалов\n",
      "MT0005202791.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005213723.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005217073.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005221680.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005239610.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005253065.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005261375.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005262725.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005265641.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005270263.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005285696.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005331755.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005387539.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005409948.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005469880.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005478759.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005515169.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005520274.mp3: 29.95 сек → 4 интервалов\n",
      "MT0005523766.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005550288.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005550441.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005595173.mp3: 29.18 сек → 4 интервалов\n",
      "MT0005606947.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005608787.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005625762.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005656534.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005673020.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005674518.mp3: 29.68 сек → 4 интервалов\n",
      "MT0005695311.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005713768.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005737276.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005751512.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005752234.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005798527.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005832516.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005850999.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005884980.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005897799.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005951020.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005963165.mp3: 29.86 сек → 4 интервалов\n",
      "MT0005981667.mp3: 30.06 сек → 5 интервалов\n",
      "MT0005987148.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006001707.mp3: 29.13 сек → 4 интервалов\n",
      "MT0006037085.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006096934.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006107326.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006117018.mp3: 29.86 сек → 4 интервалов\n",
      "MT0006159067.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006164654.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006171393.mp3: 30.10 сек → 5 интервалов\n",
      "MT0006254062.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006292011.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006315323.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006352493.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006367176.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006397809.mp3: 29.83 сек → 4 интервалов\n",
      "MT0006400514.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006410285.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006484633.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006510599.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006520567.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006540794.mp3: 29.95 сек → 4 интервалов\n",
      "MT0006552038.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006553914.mp3: 29.16 сек → 4 интервалов\n",
      "MT0006555035.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006564487.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006640142.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006640857.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006672286.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006742179.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006746691.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006747288.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006764092.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006769480.mp3: 30.10 сек → 5 интервалов\n",
      "MT0006798861.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006806145.mp3: 29.20 сек → 4 интервалов\n",
      "MT0006810990.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006862088.mp3: 29.94 сек → 4 интервалов\n",
      "MT0006903607.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006919273.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006919878.mp3: 30.10 сек → 5 интервалов\n",
      "MT0006939177.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006955716.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006983241.mp3: 30.06 сек → 5 интервалов\n",
      "MT0006996768.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007013069.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007039041.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007043504.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007043936.mp3: 29.16 сек → 4 интервалов\n",
      "MT0007053424.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007057303.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007064420.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007067293.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007087238.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007099407.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007107079.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007119529.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007147603.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007186714.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007207968.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007232134.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007265208.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007338724.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007342701.mp3: 29.16 сек → 4 интервалов\n",
      "MT0007349999.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007372035.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007379559.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007379700.mp3: 29.86 сек → 4 интервалов\n",
      "MT0007410187.mp3: 30.10 сек → 5 интервалов\n",
      "MT0007413949.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007438571.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007439502.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007443823.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007453719.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007477802.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007497706.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007535042.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007550652.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007556029.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007583962.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007610380.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007627521.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007652281.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007659703.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007697753.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007728545.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007766156.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007799677.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007812490.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007833171.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007840454.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007860263.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007914044.mp3: 30.06 сек → 5 интервалов\n",
      "MT0007926918.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008007368.mp3: 29.81 сек → 4 интервалов\n",
      "MT0008018703.mp3: 29.95 сек → 4 интервалов\n",
      "MT0008077089.mp3: 29.95 сек → 4 интервалов\n",
      "MT0008084656.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008137868.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008167476.mp3: 27.14 сек → 4 интервалов\n",
      "MT0008170600.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008208983.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008222676.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008276791.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008340316.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008342962.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008346862.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008361425.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008363839.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008399774.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008401073.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008451831.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008455201.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008493270.mp3: 29.95 сек → 4 интервалов\n",
      "MT0008511909.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008530072.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008570712.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008575372.mp3: 29.81 сек → 4 интервалов\n",
      "MT0008596275.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008644609.mp3: 29.99 сек → 4 интервалов\n",
      "MT0008665212.mp3: 29.99 сек → 4 интервалов\n",
      "MT0008675527.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008684922.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008686594.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008716237.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008718991.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008733057.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008807220.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008841966.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008972801.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008979040.mp3: 30.06 сек → 5 интервалов\n",
      "MT0008999898.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009010830.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009016829.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009041370.mp3: 29.99 сек → 4 интервалов\n",
      "MT0009075362.mp3: 29.86 сек → 4 интервалов\n",
      "MT0009117202.mp3: 29.13 сек → 4 интервалов\n",
      "MT0009169626.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009182700.mp3: 29.15 сек → 4 интервалов\n",
      "MT0009185069.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009188643.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009202768.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009208842.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009213083.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009217411.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009220462.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009253118.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009289348.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009293226.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009346128.mp3: 30.02 сек → 5 интервалов\n",
      "MT0009348908.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009368615.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009378909.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009385684.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009421924.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009437817.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009521580.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009601423.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009619048.mp3: 29.88 сек → 4 интервалов\n",
      "MT0009628869.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009693151.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009729892.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009741521.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009769814.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009800907.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009845271.mp3: 29.15 сек → 4 интервалов\n",
      "MT0009845275.mp3: 29.15 сек → 4 интервалов\n",
      "MT0009845276.mp3: 29.15 сек → 4 интервалов\n",
      "MT0009872131.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009897495.mp3: 30.04 сек → 5 интервалов\n",
      "MT0009904717.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009908994.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009991160.mp3: 30.06 сек → 5 интервалов\n",
      "MT0009996318.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010085729.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010203716.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010310896.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010344415.mp3: 30.04 сек → 5 интервалов\n",
      "MT0010375510.mp3: 29.13 сек → 4 интервалов\n",
      "MT0010392442.mp3: 29.86 сек → 4 интервалов\n",
      "MT0010415730.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010463505.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010465830.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010468178.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010482550.mp3: 30.02 сек → 5 интервалов\n",
      "MT0010485603.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010487769.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010489498.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010490157.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010501618.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010585105.mp3: 29.81 сек → 4 интервалов\n",
      "MT0010615428.mp3: 29.68 сек → 4 интервалов\n",
      "MT0010617945.mp3: 29.92 сек → 4 интервалов\n",
      "MT0010624346.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010665248.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010694663.mp3: 29.83 сек → 4 интервалов\n",
      "MT0010707508.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010736208.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010739708.mp3: 29.86 сек → 4 интервалов\n",
      "MT0010758927.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010804974.mp3: 29.94 сек → 4 интервалов\n",
      "MT0010810859.mp3: 29.68 сек → 4 интервалов\n",
      "MT0010818060.mp3: 29.68 сек → 4 интервалов\n",
      "MT0010842738.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010850805.mp3: 30.02 сек → 5 интервалов\n",
      "MT0010855214.mp3: 29.88 сек → 4 интервалов\n",
      "MT0010897525.mp3: 29.86 сек → 4 интервалов\n",
      "MT0010900969.mp3: 30.06 сек → 5 интервалов\n",
      "MT0010965655.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010979481.mp3: 27.06 сек → 4 интервалов\n",
      "MT0010983830.mp3: 29.81 сек → 4 интервалов\n",
      "MT0010984486.mp3: 29.95 сек → 4 интервалов\n",
      "MT0010998105.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011032905.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011051663.mp3: 25.57 сек → 4 интервалов\n",
      "MT0011066228.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011095825.mp3: 29.96 сек → 4 интервалов\n",
      "MT0011104152.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011145388.mp3: 29.84 сек → 4 интервалов\n",
      "MT0011158114.mp3: 29.13 сек → 4 интервалов\n",
      "MT0011230792.mp3: 29.86 сек → 4 интервалов\n",
      "MT0011250965.mp3: 29.96 сек → 4 интервалов\n",
      "MT0011259078.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011308097.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011322528.mp3: 29.99 сек → 4 интервалов\n",
      "MT0011348776.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011354857.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011369407.mp3: 30.10 сек → 5 интервалов\n",
      "MT0011376343.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011380622.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011391187.mp3: 29.95 сек → 4 интервалов\n",
      "MT0011398970.mp3: 29.96 сек → 4 интервалов\n",
      "MT0011413068.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011440705.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011458668.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011489804.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011560587.mp3: 29.86 сек → 4 интервалов\n",
      "MT0011564855.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011574534.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011575842.mp3: 29.86 сек → 4 интервалов\n",
      "MT0011594970.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011612883.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011667212.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011697297.mp3: 29.88 сек → 4 интервалов\n",
      "MT0011702301.mp3: 29.95 сек → 4 интервалов\n",
      "MT0011739779.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011786799.mp3: 29.86 сек → 4 интервалов\n",
      "MT0011821215.mp3: 29.88 сек → 4 интервалов\n",
      "MT0011836290.mp3: 29.99 сек → 4 интервалов\n",
      "MT0011862487.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011869625.mp3: 28.93 сек → 4 интервалов\n",
      "MT0011886148.mp3: 29.94 сек → 4 интервалов\n",
      "MT0011894681.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011895175.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011899302.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011906602.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011916674.mp3: 29.68 сек → 4 интервалов\n",
      "MT0011922080.mp3: 29.68 сек → 4 интервалов\n",
      "MT0011922905.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011930865.mp3: 29.68 сек → 4 интервалов\n",
      "MT0011938737.mp3: 29.95 сек → 4 интервалов\n",
      "MT0011950450.mp3: 29.68 сек → 4 интервалов\n",
      "MT0011957429.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011959819.mp3: 30.06 сек → 5 интервалов\n",
      "MT0011960348.mp3: 29.58 сек → 4 интервалов\n",
      "MT0011969592.mp3: 29.88 сек → 4 интервалов\n",
      "MT0011975274.mp3: 29.77 сек → 4 интервалов\n",
      "MT0011997914.mp3: 29.81 сек → 4 интервалов\n",
      "MT0011999773.mp3: 30.06 сек → 5 интервалов\n",
      "MT0012001409.mp3: 29.81 сек → 4 интервалов\n",
      "MT0012008752.mp3: 29.95 сек → 4 интервалов\n",
      "MT0012020062.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012027536.mp3: 29.68 сек → 4 интервалов\n",
      "MT0012041920.mp3: 28.37 сек → 4 интервалов\n",
      "MT0012112600.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012116237.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012124855.mp3: 30.06 сек → 5 интервалов\n",
      "MT0012151268.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012168286.mp3: 28.93 сек → 4 интервалов\n",
      "MT0012202513.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012222183.mp3: 29.68 сек → 4 интервалов\n",
      "MT0012292188.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012317309.mp3: 29.88 сек → 4 интервалов\n",
      "MT0012331779.mp3: 29.94 сек → 4 интервалов\n",
      "MT0012333553.mp3: 29.68 сек → 4 интервалов\n",
      "MT0012383717.mp3: 29.13 сек → 4 интервалов\n",
      "MT0012396528.mp3: 29.72 сек → 4 интервалов\n",
      "MT0012534566.mp3: 29.83 сек → 4 интервалов\n",
      "MT0012601428.mp3: 29.13 сек → 4 интервалов\n",
      "MT0012634038.mp3: 30.06 сек → 5 интервалов\n",
      "MT0012658636.mp3: 29.96 сек → 4 интервалов\n",
      "MT0012675695.mp3: 30.04 сек → 5 интервалов\n",
      "MT0012742379.mp3: 29.81 сек → 4 интервалов\n",
      "MT0012766840.mp3: 30.04 сек → 5 интервалов\n",
      "MT0012794033.mp3: 30.06 сек → 5 интервалов\n",
      "MT0012798988.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012846850.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012855159.mp3: 29.81 сек → 4 интервалов\n",
      "MT0012862507.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012865192.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012888230.mp3: 29.13 сек → 4 интервалов\n",
      "MT0012893353.mp3: 28.19 сек → 4 интервалов\n",
      "MT0012914763.mp3: 29.86 сек → 4 интервалов\n",
      "MT0012941049.mp3: 29.88 сек → 4 интервалов\n",
      "MT0013044535.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013080259.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013095380.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013101577.mp3: 29.81 сек → 4 интервалов\n",
      "MT0013161246.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013166908.mp3: 29.39 сек → 4 интервалов\n",
      "MT0013173557.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013176970.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013177702.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013219857.mp3: 29.68 сек → 4 интервалов\n",
      "MT0013235939.mp3: 29.95 сек → 4 интервалов\n",
      "MT0013280170.mp3: 28.26 сек → 4 интервалов\n",
      "MT0013313448.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013350034.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013389935.mp3: 29.81 сек → 4 интервалов\n",
      "MT0013411556.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013416300.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013418800.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013486354.mp3: 29.86 сек → 4 интервалов\n",
      "MT0013590244.mp3: 29.88 сек → 4 интервалов\n",
      "MT0013612461.mp3: 29.88 сек → 4 интервалов\n",
      "MT0013621344.mp3: 10.08 сек → 1 интервалов\n",
      "MT0013633209.mp3: 29.13 сек → 4 интервалов\n",
      "MT0013673733.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013676763.mp3: 30.06 сек → 5 интервалов\n",
      "MT0013790748.mp3: 29.16 сек → 4 интервалов\n",
      "MT0013800071.mp3: 29.15 сек → 4 интервалов\n",
      "MT0013822237.mp3: 29.18 сек → 4 интервалов\n",
      "MT0013824918.mp3: 29.15 сек → 4 интервалов\n",
      "MT0013885218.mp3: 29.13 сек → 4 интервалов\n",
      "MT0013914319.mp3: 10.08 сек → 1 интервалов\n",
      "MT0013955066.mp3: 29.12 сек → 4 интервалов\n",
      "MT0014046859.mp3: 29.16 сек → 4 интервалов\n",
      "MT0014050974.mp3: 27.18 сек → 4 интервалов\n",
      "MT0014118699.mp3: 29.18 сек → 4 интервалов\n",
      "MT0014134790.mp3: 28.21 сек → 4 интервалов\n",
      "MT0014157389.mp3: 29.16 сек → 4 интервалов\n",
      "MT0014192212.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014475915.mp3: 29.20 сек → 4 интервалов\n",
      "MT0014489361.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014507179.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014576739.mp3: 27.14 сек → 4 интервалов\n",
      "MT0014584319.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014584473.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014586720.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014615863.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014650360.mp3: 29.18 сек → 4 интервалов\n",
      "MT0014665667.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014703649.mp3: 28.93 сек → 4 интервалов\n",
      "MT0014737299.mp3: 29.15 сек → 4 интервалов\n",
      "MT0014794891.mp3: 29.16 сек → 4 интервалов\n",
      "MT0014804830.mp3: 29.13 сек → 4 интервалов\n",
      "MT0014817509.mp3: 29.13 сек → 4 интервалов\n",
      "MT0014838459.mp3: 29.13 сек → 4 интервалов\n",
      "MT0014845647.mp3: 29.13 сек → 4 интервалов\n",
      "MT0014878397.mp3: 30.06 сек → 5 интервалов\n",
      "MT0014997916.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015004289.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015005100.mp3: 27.14 сек → 4 интервалов\n",
      "MT0015026293.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015028144.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015510419.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015514030.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015541501.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015599764.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015653546.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015659520.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015664499.mp3: 30.06 сек → 5 интервалов\n",
      "MT0015665796.mp3: 27.14 сек → 4 интервалов\n",
      "MT0015680193.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015682649.mp3: 30.06 сек → 5 интервалов\n",
      "MT0015706588.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015715008.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015742096.mp3: 30.06 сек → 5 интервалов\n",
      "MT0015849191.mp3: 29.16 сек → 4 интервалов\n",
      "MT0015934550.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015962332.mp3: 29.13 сек → 4 интервалов\n",
      "MT0015971175.mp3: 29.13 сек → 4 интервалов\n",
      "MT0016743722.mp3: 29.13 сек → 4 интервалов\n",
      "MT0016887233.mp3: 29.13 сек → 4 интервалов\n",
      "MT0016897938.mp3: 29.13 сек → 4 интервалов\n",
      "MT0016932218.mp3: 29.13 сек → 4 интервалов\n",
      "MT0016972827.mp3: 29.13 сек → 4 интервалов\n",
      "MT0017475710.mp3: 29.13 сек → 4 интервалов\n",
      "MT0017667847.mp3: 29.13 сек → 4 интервалов\n",
      "MT0017672677.mp3: 29.16 сек → 4 интервалов\n",
      "MT0017797643.mp3: 29.16 сек → 4 интервалов\n",
      "MT0018024152.mp3: 30.06 сек → 5 интервалов\n",
      "MT0018029465.mp3: 30.06 сек → 5 интервалов\n",
      "MT0018031959.mp3: 30.06 сек → 5 интервалов\n",
      "MT0018450519.mp3: 30.06 сек → 5 интервалов\n",
      "MT0018617125.mp3: 30.06 сек → 5 интервалов\n",
      "MT0018651126.mp3: 30.06 сек → 5 интервалов\n",
      "MT0026158301.mp3: 30.04 сек → 5 интервалов\n",
      "MT0026330298.mp3: 30.06 сек → 5 интервалов\n",
      "MT0026520343.mp3: 29.13 сек → 4 интервалов\n",
      "MT0026608644.mp3: 30.06 сек → 5 интервалов\n",
      "MT0026690204.mp3: 29.13 сек → 4 интервалов\n",
      "MT0026727455.mp3: 29.15 сек → 4 интервалов\n",
      "MT0026753600.mp3: 29.16 сек → 4 интервалов\n",
      "MT0026753827.mp3: 29.15 сек → 4 интервалов\n",
      "MT0026776967.mp3: 30.06 сек → 5 интервалов\n",
      "MT0026795261.mp3: 29.86 сек → 4 интервалов\n",
      "MT0026898936.mp3: 29.94 сек → 4 интервалов\n",
      "MT0026905937.mp3: 29.94 сек → 4 интервалов\n",
      "MT0026919017.mp3: 29.95 сек → 4 интервалов\n",
      "MT0026963572.mp3: 29.81 сек → 4 интервалов\n",
      "MT0027002641.mp3: 30.06 сек → 5 интервалов\n",
      "MT0027035970.mp3: 29.94 сек → 4 интервалов\n",
      "MT0027048677.mp3: 29.83 сек → 4 интервалов\n",
      "MT0027100467.mp3: 30.06 сек → 5 интервалов\n",
      "MT0027159893.mp3: 29.83 сек → 4 интервалов\n",
      "MT0027256574.mp3: 29.07 сек → 4 интервалов\n",
      "MT0027478016.mp3: 29.13 сек → 4 интервалов\n",
      "MT0027835071.mp3: 29.13 сек → 4 интервалов\n",
      "MT0027976714.mp3: 30.06 сек → 5 интервалов\n",
      "MT0028066739.mp3: 29.96 сек → 4 интервалов\n",
      "MT0028159092.mp3: 29.15 сек → 4 интервалов\n",
      "MT0028167155.mp3: 30.06 сек → 5 интервалов\n",
      "MT0028172888.mp3: 30.06 сек → 5 интервалов\n",
      "MT0028213435.mp3: 29.94 сек → 4 интервалов\n",
      "MT0028220133.mp3: 29.44 сек → 4 интервалов\n",
      "MT0028335228.mp3: 29.81 сек → 4 интервалов\n",
      "MT0028345470.mp3: 29.13 сек → 4 интервалов\n",
      "MT0028374210.mp3: 29.13 сек → 4 интервалов\n",
      "MT0028445777.mp3: 29.16 сек → 4 интервалов\n",
      "MT0028469910.mp3: 29.16 сек → 4 интервалов\n",
      "MT0028495262.mp3: 29.88 сек → 4 интервалов\n",
      "MT0028550964.mp3: 30.06 сек → 5 интервалов\n",
      "MT0028560561.mp3: 29.94 сек → 4 интервалов\n",
      "MT0028596249.mp3: 29.86 сек → 4 интервалов\n",
      "MT0028617657.mp3: 29.68 сек → 4 интервалов\n",
      "MT0028627699.mp3: 29.13 сек → 4 интервалов\n",
      "MT0028633715.mp3: 29.88 сек → 4 интервалов\n",
      "MT0028648077.mp3: 29.94 сек → 4 интервалов\n",
      "MT0028698324.mp3: 29.99 сек → 4 интервалов\n",
      "MT0028709149.mp3: 29.95 сек → 4 интервалов\n",
      "MT0028750297.mp3: 29.94 сек → 4 интервалов\n",
      "MT0028813196.mp3: 28.13 сек → 4 интервалов\n",
      "MT0028947009.mp3: 29.94 сек → 4 интервалов\n",
      "MT0029065626.mp3: 30.06 сек → 5 интервалов\n",
      "MT0029080694.mp3: 30.06 сек → 5 интервалов\n",
      "MT0029099688.mp3: 29.13 сек → 4 интервалов\n",
      "MT0029492542.mp3: 29.16 сек → 4 интервалов\n",
      "MT0029553110.mp3: 29.13 сек → 4 интервалов\n",
      "MT0029772184.mp3: 30.06 сек → 5 интервалов\n",
      "MT0029861029.mp3: 30.06 сек → 5 интервалов\n",
      "MT0029874624.mp3: 29.13 сек → 4 интервалов\n",
      "MT0029877658.mp3: 29.94 сек → 4 интервалов\n",
      "MT0029976595.mp3: 29.15 сек → 4 интервалов\n",
      "MT0030007733.mp3: 29.94 сек → 4 интервалов\n",
      "MT0030036616.mp3: 29.16 сек → 4 интервалов\n",
      "MT0030097602.mp3: 29.15 сек → 4 интервалов\n",
      "MT0030124886.mp3: 29.86 сек → 4 интервалов\n",
      "MT0030160582.mp3: 29.15 сек → 4 интервалов\n",
      "MT0030203729.mp3: 29.94 сек → 4 интервалов\n",
      "MT0030214520.mp3: 29.16 сек → 4 интервалов\n",
      "MT0030247926.mp3: 29.88 сек → 4 интервалов\n",
      "MT0030252676.mp3: 29.81 сек → 4 интервалов\n",
      "MT0030271679.mp3: 29.86 сек → 4 интервалов\n",
      "MT0030282917.mp3: 30.06 сек → 5 интервалов\n",
      "MT0030286920.mp3: 29.86 сек → 4 интервалов\n",
      "MT0030304982.mp3: 29.86 сек → 4 интервалов\n",
      "MT0030319227.mp3: 30.06 сек → 5 интервалов\n",
      "MT0030321464.mp3: 29.88 сек → 4 интервалов\n",
      "MT0030369896.mp3: 29.63 сек → 4 интервалов\n",
      "MT0030400613.mp3: 29.13 сек → 4 интервалов\n",
      "MT0030422114.mp3: 29.99 сек → 4 интервалов\n",
      "MT0030442334.mp3: 29.63 сек → 4 интервалов\n",
      "MT0030481897.mp3: 29.94 сек → 4 интервалов\n",
      "MT0030484925.mp3: 29.94 сек → 4 интервалов\n",
      "MT0030487841.mp3: 29.95 сек → 4 интервалов\n",
      "MT0030494794.mp3: 29.94 сек → 4 интервалов\n",
      "MT0030495725.mp3: 29.95 сек → 4 интервалов\n",
      "MT0031495046.mp3: 29.94 сек → 4 интервалов\n",
      "MT0031544440.mp3: 29.68 сек → 4 интервалов\n",
      "MT0031693432.mp3: 26.98 сек → 4 интервалов\n",
      "MT0031807708.mp3: 29.88 сек → 4 интервалов\n",
      "MT0031826774.mp3: 29.86 сек → 4 интервалов\n",
      "MT0031827474.mp3: 29.95 сек → 4 интервалов\n",
      "MT0031886830.mp3: 30.06 сек → 5 интервалов\n",
      "MT0031898123.mp3: 29.94 сек → 4 интервалов\n",
      "MT0031922089.mp3: 29.75 сек → 4 интервалов\n",
      "MT0031926476.mp3: 29.94 сек → 4 интервалов\n",
      "MT0031951901.mp3: 30.06 сек → 5 интервалов\n",
      "MT0031996897.mp3: 29.16 сек → 4 интервалов\n",
      "MT0032061241.mp3: 29.94 сек → 4 интервалов\n",
      "MT0032181833.mp3: 29.16 сек → 4 интервалов\n",
      "MT0032235381.mp3: 29.15 сек → 4 интервалов\n",
      "MT0032297238.mp3: 29.86 сек → 4 интервалов\n",
      "MT0032332758.mp3: 29.13 сек → 4 интервалов\n",
      "MT0032405040.mp3: 30.06 сек → 5 интервалов\n",
      "MT0032698237.mp3: 29.95 сек → 4 интервалов\n",
      "MT0032892262.mp3: 29.15 сек → 4 интервалов\n",
      "MT0032957418.mp3: 29.16 сек → 4 интервалов\n",
      "MT0033084992.mp3: 29.86 сек → 4 интервалов\n",
      "MT0033097471.mp3: 29.15 сек → 4 интервалов\n",
      "MT0033159895.mp3: 29.13 сек → 4 интервалов\n",
      "MT0033177286.mp3: 29.88 сек → 4 интервалов\n",
      "MT0033226848.mp3: 29.81 сек → 4 интервалов\n",
      "MT0033287096.mp3: 30.06 сек → 5 интервалов\n",
      "MT0033287114.mp3: 29.16 сек → 4 интервалов\n",
      "MT0033317646.mp3: 28.37 сек → 4 интервалов\n",
      "MT0033326377.mp3: 29.88 сек → 4 интервалов\n",
      "MT0033345959.mp3: 29.94 сек → 4 интервалов\n",
      "MT0033391280.mp3: 29.86 сек → 4 интервалов\n",
      "MT0033397838.mp3: 29.94 сек → 4 интервалов\n",
      "MT0033410438.mp3: 29.86 сек → 4 интервалов\n",
      "MT0033415296.mp3: 29.94 сек → 4 интервалов\n",
      "MT0033443279.mp3: 29.13 сек → 4 интервалов\n",
      "MT0033461826.mp3: 29.81 сек → 4 интервалов\n",
      "MT0033841575.mp3: 29.88 сек → 4 интервалов\n",
      "MT0033940994.mp3: 29.95 сек → 4 интервалов\n",
      "MT0033958450.mp3: 29.13 сек → 4 интервалов\n",
      "MT0034005433.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034013916.mp3: 29.15 сек → 4 интервалов\n",
      "MT0034015731.mp3: 29.13 сек → 4 интервалов\n",
      "MT0034106363.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034125967.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034136847.mp3: 29.15 сек → 4 интервалов\n",
      "MT0034148562.mp3: 29.94 сек → 4 интервалов\n",
      "MT0034160981.mp3: 29.86 сек → 4 интервалов\n",
      "MT0034186195.mp3: 29.86 сек → 4 интервалов\n",
      "MT0034186620.mp3: 29.94 сек → 4 интервалов\n",
      "MT0034203861.mp3: 29.81 сек → 4 интервалов\n",
      "MT0034212119.mp3: 29.94 сек → 4 интервалов\n",
      "MT0034403951.mp3: 29.13 сек → 4 интервалов\n",
      "MT0034555338.mp3: 29.81 сек → 4 интервалов\n",
      "MT0034574251.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034577404.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034694413.mp3: 29.86 сек → 4 интервалов\n",
      "MT0034816599.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034982187.mp3: 29.86 сек → 4 интервалов\n",
      "MT0034988131.mp3: 30.06 сек → 5 интервалов\n",
      "MT0034991842.mp3: 29.86 сек → 4 интервалов\n",
      "MT0035000258.mp3: 29.81 сек → 4 интервалов\n",
      "MT0035007057.mp3: 30.06 сек → 5 интервалов\n",
      "MT0035241621.mp3: 29.88 сек → 4 интервалов\n",
      "MT0035316286.mp3: 30.06 сек → 5 интервалов\n",
      "MT0035332835.mp3: 29.94 сек → 4 интервалов\n",
      "MT0035334027.mp3: 29.81 сек → 4 интервалов\n",
      "MT0036111736.mp3: 30.06 сек → 5 интервалов\n",
      "MT0036368550.mp3: 30.06 сек → 5 интервалов\n",
      "MT0040033011.mp3: 30.06 сек → 5 интервалов\n",
      "Всего ожидается интервалов: 4111\n"
     ]
    }
   ],
   "source": [
    "total_expected_intervals = 0\n",
    "\n",
    "for file in files:\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "    track_duration = librosa.get_duration(y=y, sr=sr)\n",
    "    num_intervals = int(track_duration // interval_duration)\n",
    "    print(f\"{file}: {track_duration:.2f} сек → {num_intervals} интервалов\")\n",
    "    total_expected_intervals += num_intervals\n",
    "\n",
    "print(f\"Всего ожидается интервалов: {total_expected_intervals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f947a01-e353-4711-9098-e73b94683959",
   "metadata": {},
   "source": [
    "# Треки разной длины. Делим на фиксированное количество частей(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e02262c-7bd6-439e-a717-3d42e03ca228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1008\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=504\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=504\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Путь к папке\n",
    "folder_path = 'C:/Users/Mary/Desktop/Диплом/all_music/'\n",
    "files = fnmatch.filter(os.listdir(folder_path), '*.mp3')\n",
    "\n",
    "# Списки для хранения признаков\n",
    "chroma_features_list = []\n",
    "mel_list = []\n",
    "mfcc_list = []\n",
    "tempo_list = []\n",
    "file_names = []\n",
    "interval_indices = []\n",
    "\n",
    "# Обработка каждого аудиофайла\n",
    "for file in files:\n",
    "    audio_path = os.path.join(folder_path, file)\n",
    "    y, sr = librosa.load(audio_path, sr=None, res_type='kaiser_fast')\n",
    "    total_samples = len(y)\n",
    "\n",
    "    num_segments = 5\n",
    "    segment_length = total_samples // num_segments\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length\n",
    "        end_sample = (i + 1) * segment_length if i < num_segments - 1 else total_samples\n",
    "        y_interval = y[start_sample:end_sample]\n",
    "\n",
    "        def extract_statistics(feature):\n",
    "            return np.hstack([\n",
    "                np.mean(feature, axis=1),\n",
    "                np.std(feature, axis=1),\n",
    "                np.median(feature, axis=1),\n",
    "                np.max(feature, axis=1) - np.min(feature, axis=1)\n",
    "            ])\n",
    "\n",
    "        chroma_cqt = librosa.feature.chroma_cqt(y=y_interval, sr=sr, bins_per_octave=60, n_chroma=60)\n",
    "        chroma_cqt = np.log1p(chroma_cqt)\n",
    "        chroma_cqt_stats = extract_statistics(chroma_cqt)\n",
    "\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y_interval, sr=sr)\n",
    "        chroma_stft = np.log1p(chroma_stft)\n",
    "        chroma_stft_stats = extract_statistics(chroma_stft)\n",
    "\n",
    "        chroma_cens = librosa.feature.chroma_cens(y=y_interval, sr=sr)\n",
    "        chroma_cens = np.log1p(chroma_cens)\n",
    "        chroma_cens_stats = extract_statistics(chroma_cens)\n",
    "\n",
    "        chroma_features = np.hstack([chroma_cqt_stats, chroma_stft_stats, chroma_cens_stats])\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(y=y_interval, sr=sr)\n",
    "        mel_list.append(mel.mean(axis=1))\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y_interval, sr=sr, n_mfcc=40)\n",
    "        mfcc_list.append(mfcc.mean(axis=1))\n",
    "\n",
    "        tempo, _ = librosa.beat.beat_track(y=y_interval, sr=sr)\n",
    "        tempo_list.append(tempo)\n",
    "\n",
    "        chroma_features_list.append(chroma_features)\n",
    "        file_names.append(file)\n",
    "        interval_indices.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d109aa-2b33-4783-a893-7c148dd21558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chroma_0  chroma_1  chroma_2  chroma_3  chroma_4  chroma_5  chroma_6  \\\n",
      "0  0.268737  0.023156  0.098043  0.040503  0.049885  0.212958  0.528250   \n",
      "1  0.605032 -0.167954 -0.416713 -0.451981 -0.382166 -0.265434 -0.043554   \n",
      "2 -0.350068 -0.480495 -0.290440 -0.157244  0.035751  0.247772  0.580638   \n",
      "3  0.660533 -0.248691 -0.275367 -0.159114 -0.211003 -0.116964  0.206494   \n",
      "4 -0.488292 -0.616932 -0.412675 -0.210915 -0.131289 -0.012906  0.390483   \n",
      "\n",
      "   chroma_7  chroma_8  chroma_9  ...   mfcc_33   mfcc_34   mfcc_35   mfcc_36  \\\n",
      "0  0.847383  1.015245  1.485166  ...  0.797992  0.413381 -0.145381 -0.833907   \n",
      "1  0.254138  0.535075  1.253548  ...  1.015882  1.074985 -0.195630 -0.756741   \n",
      "2  0.794555  1.430729  1.389776  ...  1.478598  1.318274  0.148898 -0.431756   \n",
      "3  0.271629  0.395723  0.262516  ...  0.549146  1.228777  0.476222  0.039069   \n",
      "4  0.831392  0.939970  2.180129  ...  2.191127  1.996992  0.062888 -1.399714   \n",
      "\n",
      "    mfcc_37   mfcc_38   mfcc_39     tempo         file_name  interval_number  \n",
      "0 -0.793811 -0.550932  0.815139  1.191941  MT0000004637.mp3                0  \n",
      "1 -0.858018 -0.896949 -0.223597  1.411365  MT0000004637.mp3                1  \n",
      "2 -0.679825 -0.724001  0.186107  1.191941  MT0000004637.mp3                2  \n",
      "3 -0.677075 -1.205169 -0.381277  1.191941  MT0000004637.mp3                3  \n",
      "4 -1.024570 -0.458077  0.926160  1.191941  MT0000004637.mp3                4  \n",
      "\n",
      "[5 rows x 507 columns]\n",
      "Всего строк в датафрейме: 4500\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем признаки в массивы\n",
    "chroma_array = np.array(chroma_features_list)\n",
    "mel_array = np.array(mel_list)\n",
    "mfcc_array = np.array(mfcc_list)\n",
    "tempo_array = np.array(tempo_list).reshape(-1, 1)\n",
    "\n",
    "# Нормализация\n",
    "scaler = StandardScaler()\n",
    "chroma_array_scaled = scaler.fit_transform(chroma_array)\n",
    "mel_array_scaled = scaler.fit_transform(mel_array)\n",
    "mfcc_array_scaled = scaler.fit_transform(mfcc_array)\n",
    "tempo_array_scaled = scaler.fit_transform(tempo_array)\n",
    "\n",
    "# Объединяем признаки\n",
    "X_full = np.hstack([chroma_array_scaled, mel_array_scaled, mfcc_array_scaled, tempo_array_scaled])\n",
    "\n",
    "# Формируем имена колонок\n",
    "chroma_cols = [f'chroma_{i}' for i in range(chroma_array.shape[1])]\n",
    "mel_cols = [f'mel_{i}' for i in range(mel_array.shape[1])]\n",
    "mfcc_cols = [f'mfcc_{i}' for i in range(mfcc_array.shape[1])]\n",
    "tempo_col = ['tempo']\n",
    "all_columns = chroma_cols + mel_cols + mfcc_cols + tempo_col\n",
    "\n",
    "# Создаём датафрейм\n",
    "df = pd.DataFrame(X_full, columns=all_columns)\n",
    "df['file_name'] = file_names\n",
    "df['interval_number'] = interval_indices\n",
    "\n",
    "# Просмотр результатов\n",
    "print(df.head())\n",
    "print(f'Всего строк в датафрейме: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0930d812-837c-487e-bae4-ece7ffb1f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\df_five_parts_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52a3d4ec-0117-488c-96e3-8694184190e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 507)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76281b-7784-42d4-8041-bb9ed4080579",
   "metadata": {},
   "source": [
    "# Собираем итоговый датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eea5f4b2-31b6-446a-8064-01befbdc4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/MER_audio_taffc_dataset/panda_dataset_taffc_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a273657-aad1-499c-ba7b-9667f64bf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df['Artist'] = music_df['Artist'].isna().fillna('no_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1ce1799-ed3d-4558-a4be-ab7b2d727aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df, pd.Series(file_names, name='Song')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "585219fd-e997-4f67-b94c-1794df6a43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Song'] = combined_df['Song'].str[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52d75658-36dd-41ae-93b2-841b6fad5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop('file_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8caeaa73-7324-4b78-aee0-a30bd0cccfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(music_df, combined_df, on='Song', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "eb13360e-e675-44ee-b908-833a734bda42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>Song</th>\n",
       "      <th>chroma_0</th>\n",
       "      <th>chroma_1</th>\n",
       "      <th>chroma_2</th>\n",
       "      <th>chroma_3</th>\n",
       "      <th>chroma_4</th>\n",
       "      <th>chroma_5</th>\n",
       "      <th>chroma_6</th>\n",
       "      <th>chroma_7</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_32</th>\n",
       "      <th>mfcc_33</th>\n",
       "      <th>mfcc_34</th>\n",
       "      <th>mfcc_35</th>\n",
       "      <th>mfcc_36</th>\n",
       "      <th>mfcc_37</th>\n",
       "      <th>mfcc_38</th>\n",
       "      <th>mfcc_39</th>\n",
       "      <th>tempo</th>\n",
       "      <th>interval_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3</td>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>0.268737</td>\n",
       "      <td>0.023156</td>\n",
       "      <td>0.098043</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>0.212958</td>\n",
       "      <td>0.528250</td>\n",
       "      <td>0.847383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.032472</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.413381</td>\n",
       "      <td>-0.145381</td>\n",
       "      <td>-0.833907</td>\n",
       "      <td>-0.793811</td>\n",
       "      <td>-0.550932</td>\n",
       "      <td>0.815139</td>\n",
       "      <td>1.191941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q3</td>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>0.605032</td>\n",
       "      <td>-0.167954</td>\n",
       "      <td>-0.416713</td>\n",
       "      <td>-0.451981</td>\n",
       "      <td>-0.382166</td>\n",
       "      <td>-0.265434</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>0.254138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891880</td>\n",
       "      <td>1.015882</td>\n",
       "      <td>1.074985</td>\n",
       "      <td>-0.195630</td>\n",
       "      <td>-0.756741</td>\n",
       "      <td>-0.858018</td>\n",
       "      <td>-0.896949</td>\n",
       "      <td>-0.223597</td>\n",
       "      <td>1.411365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>-0.350068</td>\n",
       "      <td>-0.480495</td>\n",
       "      <td>-0.290440</td>\n",
       "      <td>-0.157244</td>\n",
       "      <td>0.035751</td>\n",
       "      <td>0.247772</td>\n",
       "      <td>0.580638</td>\n",
       "      <td>0.794555</td>\n",
       "      <td>...</td>\n",
       "      <td>1.439565</td>\n",
       "      <td>1.478598</td>\n",
       "      <td>1.318274</td>\n",
       "      <td>0.148898</td>\n",
       "      <td>-0.431756</td>\n",
       "      <td>-0.679825</td>\n",
       "      <td>-0.724001</td>\n",
       "      <td>0.186107</td>\n",
       "      <td>1.191941</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q3</td>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>0.660533</td>\n",
       "      <td>-0.248691</td>\n",
       "      <td>-0.275367</td>\n",
       "      <td>-0.159114</td>\n",
       "      <td>-0.211003</td>\n",
       "      <td>-0.116964</td>\n",
       "      <td>0.206494</td>\n",
       "      <td>0.271629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403377</td>\n",
       "      <td>0.549146</td>\n",
       "      <td>1.228777</td>\n",
       "      <td>0.476222</td>\n",
       "      <td>0.039069</td>\n",
       "      <td>-0.677075</td>\n",
       "      <td>-1.205169</td>\n",
       "      <td>-0.381277</td>\n",
       "      <td>1.191941</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>MT0000004637</td>\n",
       "      <td>-0.488292</td>\n",
       "      <td>-0.616932</td>\n",
       "      <td>-0.412675</td>\n",
       "      <td>-0.210915</td>\n",
       "      <td>-0.131289</td>\n",
       "      <td>-0.012906</td>\n",
       "      <td>0.390483</td>\n",
       "      <td>0.831392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.613432</td>\n",
       "      <td>2.191127</td>\n",
       "      <td>1.996992</td>\n",
       "      <td>0.062888</td>\n",
       "      <td>-1.399714</td>\n",
       "      <td>-1.024570</td>\n",
       "      <td>-0.458077</td>\n",
       "      <td>0.926160</td>\n",
       "      <td>1.191941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quadrant          Song  chroma_0  chroma_1  chroma_2  chroma_3  chroma_4  \\\n",
       "0       Q3  MT0000004637  0.268737  0.023156  0.098043  0.040503  0.049885   \n",
       "1       Q3  MT0000004637  0.605032 -0.167954 -0.416713 -0.451981 -0.382166   \n",
       "2       Q3  MT0000004637 -0.350068 -0.480495 -0.290440 -0.157244  0.035751   \n",
       "3       Q3  MT0000004637  0.660533 -0.248691 -0.275367 -0.159114 -0.211003   \n",
       "4       Q3  MT0000004637 -0.488292 -0.616932 -0.412675 -0.210915 -0.131289   \n",
       "\n",
       "   chroma_5  chroma_6  chroma_7  ...   mfcc_32   mfcc_33   mfcc_34   mfcc_35  \\\n",
       "0  0.212958  0.528250  0.847383  ...  1.032472  0.797992  0.413381 -0.145381   \n",
       "1 -0.265434 -0.043554  0.254138  ...  0.891880  1.015882  1.074985 -0.195630   \n",
       "2  0.247772  0.580638  0.794555  ...  1.439565  1.478598  1.318274  0.148898   \n",
       "3 -0.116964  0.206494  0.271629  ...  0.403377  0.549146  1.228777  0.476222   \n",
       "4 -0.012906  0.390483  0.831392  ...  1.613432  2.191127  1.996992  0.062888   \n",
       "\n",
       "    mfcc_36   mfcc_37   mfcc_38   mfcc_39     tempo  interval_number  \n",
       "0 -0.833907 -0.793811 -0.550932  0.815139  1.191941                0  \n",
       "1 -0.756741 -0.858018 -0.896949 -0.223597  1.411365                1  \n",
       "2 -0.431756 -0.679825 -0.724001  0.186107  1.191941                2  \n",
       "3  0.039069 -0.677075 -1.205169 -0.381277  1.191941                3  \n",
       "4 -1.399714 -1.024570 -0.458077  0.926160  1.191941                4  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = merged_df[['Quadrant'] +['Song'] + list(merged_df.columns[-506:])]\n",
    "#merged_df = pd.concat(merged_df['Quadrant'], combined_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "392bbd95-314d-4c1c-965d-33c530913ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 507)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dcc482b4-1cbc-4e08-ae0b-8741c3957e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r'C:\\Users\\Mary\\Desktop\\Диплом\\df_five_parts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcda8ee-be1f-478a-a04d-570c12fdc122",
   "metadata": {},
   "source": [
    "# Построение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "df756d95-adaa-4715-885c-93ae61c65456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Mary/Desktop/Диплом/df_five_parts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cc669f47-1bf5-4807-8b6a-dba4ca74dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99aec6-2d81-40ec-bebd-15ac67be3194",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0a5b832f-44ee-48f5-a695-7b46e4a55c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.56      0.65      0.60        23\n",
      "          Q2       0.83      0.86      0.84        22\n",
      "          Q3       0.68      0.65      0.67        23\n",
      "          Q4       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.68      0.68      0.68        90\n",
      "weighted avg       0.68      0.68      0.68        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Получаем уникальные треки\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "# Делим треки на train и test\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant'].first()\n",
    ")\n",
    "\n",
    "# Создаем train/test датасеты\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "# Сохраняем истинные метки\n",
    "test_df['Quadrant_true'] = test_df['Quadrant']\n",
    "\n",
    "# Признаки и метки для обучения\n",
    "X_train = train_df.drop(['Quadrant', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant']\n",
    "\n",
    "# Подготовка признаков для теста\n",
    "X_test = test_df.drop(['Quadrant', 'Song', 'Quadrant_true'], axis=1)\n",
    "\n",
    "# Обучение модели\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "test_df['Quadrant_predicted'] = model.predict(X_test)\n",
    "\n",
    "# Мажоритарное голосование по трекам\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "# Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c86fd470-7e16-4928-aa62-5f418692d4a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 20:29:32,221] A new study created in memory with name: no-name-7c121bfc-ad24-4edb-83ee-e3d39bae878c\n",
      "[I 2025-05-07 20:30:23,809] Trial 0 finished with value: 0.6062745098039216 and parameters: {'n_estimators': 364, 'max_depth': 41, 'min_samples_split': 0.08260440553307664, 'min_samples_leaf': 13, 'max_features': 0.2806694722229516, 'bootstrap': True}. Best is trial 0 with value: 0.6062745098039216.\n",
      "[I 2025-05-07 20:30:50,605] Trial 1 finished with value: 0.6248366013071895 and parameters: {'n_estimators': 209, 'max_depth': 11, 'min_samples_split': 0.08115168348734783, 'min_samples_leaf': 11, 'max_features': 0.18176108216292614, 'bootstrap': False}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:32:22,935] Trial 2 finished with value: 0.48 and parameters: {'n_estimators': 481, 'max_depth': 17, 'min_samples_split': 0.3890970516954139, 'min_samples_leaf': 3, 'max_features': 0.7930066533804991, 'bootstrap': False}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:32:26,037] Trial 3 finished with value: 0.529673202614379 and parameters: {'n_estimators': 61, 'max_depth': 21, 'min_samples_split': 0.24721499494445986, 'min_samples_leaf': 2, 'max_features': 0.10943842248323309, 'bootstrap': True}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:34:14,012] Trial 4 finished with value: 0.5741176470588235 and parameters: {'n_estimators': 415, 'max_depth': 46, 'min_samples_split': 0.14997487163967418, 'min_samples_leaf': 4, 'max_features': 0.6338770735819031, 'bootstrap': True}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:35:03,567] Trial 5 finished with value: 0.5422222222222222 and parameters: {'n_estimators': 441, 'max_depth': 8, 'min_samples_split': 0.3074134859290206, 'min_samples_leaf': 4, 'max_features': 0.3463516356577793, 'bootstrap': False}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:36:01,836] Trial 6 finished with value: 0.5312418300653594 and parameters: {'n_estimators': 220, 'max_depth': 45, 'min_samples_split': 0.26881955883139014, 'min_samples_leaf': 14, 'max_features': 0.7411609932028135, 'bootstrap': False}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:36:52,874] Trial 7 finished with value: 0.43503267973856213 and parameters: {'n_estimators': 417, 'max_depth': 25, 'min_samples_split': 0.48429114962419384, 'min_samples_leaf': 13, 'max_features': 0.9385124319373706, 'bootstrap': True}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:37:40,267] Trial 8 finished with value: 0.4763398692810458 and parameters: {'n_estimators': 405, 'max_depth': 16, 'min_samples_split': 0.3066061311654922, 'min_samples_leaf': 10, 'max_features': 0.5389863679192819, 'bootstrap': True}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:38:44,265] Trial 9 finished with value: 0.5871895424836602 and parameters: {'n_estimators': 209, 'max_depth': 14, 'min_samples_split': 0.1272986397093604, 'min_samples_leaf': 14, 'max_features': 0.7078531705635012, 'bootstrap': True}. Best is trial 1 with value: 0.6248366013071895.\n",
      "[I 2025-05-07 20:39:06,322] Trial 10 finished with value: 0.6363398692810457 and parameters: {'n_estimators': 80, 'max_depth': 35, 'min_samples_split': 0.049088092633004864, 'min_samples_leaf': 20, 'max_features': 0.40801301632396075, 'bootstrap': False}. Best is trial 10 with value: 0.6363398692810457.\n",
      "[I 2025-05-07 20:39:30,625] Trial 11 finished with value: 0.6721568627450981 and parameters: {'n_estimators': 73, 'max_depth': 34, 'min_samples_split': 0.012517679401501294, 'min_samples_leaf': 20, 'max_features': 0.38570066744252995, 'bootstrap': False}. Best is trial 11 with value: 0.6721568627450981.\n",
      "[I 2025-05-07 20:39:48,900] Trial 12 finished with value: 0.6473202614379084 and parameters: {'n_estimators': 50, 'max_depth': 34, 'min_samples_split': 0.02729503681042616, 'min_samples_leaf': 20, 'max_features': 0.4572050692266427, 'bootstrap': False}. Best is trial 11 with value: 0.6721568627450981.\n",
      "[I 2025-05-07 20:40:31,549] Trial 13 finished with value: 0.6739869281045752 and parameters: {'n_estimators': 127, 'max_depth': 30, 'min_samples_split': 0.012081460347111217, 'min_samples_leaf': 20, 'max_features': 0.48159252351841336, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:41:01,275] Trial 14 finished with value: 0.5764705882352942 and parameters: {'n_estimators': 152, 'max_depth': 31, 'min_samples_split': 0.17411880150573586, 'min_samples_leaf': 17, 'max_features': 0.5285855685918073, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:41:10,161] Trial 15 finished with value: 0.5050980392156862 and parameters: {'n_estimators': 142, 'max_depth': 2, 'min_samples_split': 0.019531304400636412, 'min_samples_leaf': 17, 'max_features': 0.26009488993625685, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:42:04,871] Trial 16 finished with value: 0.562875816993464 and parameters: {'n_estimators': 303, 'max_depth': 30, 'min_samples_split': 0.21907646629761574, 'min_samples_leaf': 18, 'max_features': 0.423261619961689, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:42:54,452] Trial 17 finished with value: 0.596078431372549 and parameters: {'n_estimators': 123, 'max_depth': 39, 'min_samples_split': 0.09774394276142709, 'min_samples_leaf': 7, 'max_features': 0.6261355289957039, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:43:30,060] Trial 18 finished with value: 0.5783006535947712 and parameters: {'n_estimators': 275, 'max_depth': 25, 'min_samples_split': 0.180067479364576, 'min_samples_leaf': 16, 'max_features': 0.31643952627023486, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:44:56,116] Trial 19 finished with value: 0.6177777777777778 and parameters: {'n_estimators': 102, 'max_depth': 37, 'min_samples_split': 0.01273093167086971, 'min_samples_leaf': 20, 'max_features': 0.8655855903860875, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:45:20,549] Trial 20 finished with value: 0.4823529411764706 and parameters: {'n_estimators': 173, 'max_depth': 50, 'min_samples_split': 0.4359506222732237, 'min_samples_leaf': 8, 'max_features': 0.4752159582375401, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:45:54,367] Trial 21 finished with value: 0.6700653594771242 and parameters: {'n_estimators': 61, 'max_depth': 32, 'min_samples_split': 0.01000849065387117, 'min_samples_leaf': 19, 'max_features': 0.4156580714697403, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:46:34,279] Trial 22 finished with value: 0.6117647058823529 and parameters: {'n_estimators': 93, 'max_depth': 29, 'min_samples_split': 0.06667104045786697, 'min_samples_leaf': 18, 'max_features': 0.6345870926079722, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:46:59,536] Trial 23 finished with value: 0.5963398692810458 and parameters: {'n_estimators': 109, 'max_depth': 21, 'min_samples_split': 0.1245659855700593, 'min_samples_leaf': 19, 'max_features': 0.36113615740014204, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:47:52,882] Trial 24 finished with value: 0.6295424836601308 and parameters: {'n_estimators': 181, 'max_depth': 33, 'min_samples_split': 0.04989279044897882, 'min_samples_leaf': 16, 'max_features': 0.5001438639127571, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:48:24,540] Trial 25 finished with value: 0.6075816993464053 and parameters: {'n_estimators': 258, 'max_depth': 27, 'min_samples_split': 0.10820091863819747, 'min_samples_leaf': 16, 'max_features': 0.23644644020898872, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:48:40,327] Trial 26 finished with value: 0.6700653594771241 and parameters: {'n_estimators': 50, 'max_depth': 41, 'min_samples_split': 0.016598499353535592, 'min_samples_leaf': 18, 'max_features': 0.38177605919071356, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:49:32,989] Trial 27 finished with value: 0.6164705882352941 and parameters: {'n_estimators': 132, 'max_depth': 22, 'min_samples_split': 0.05904228626549504, 'min_samples_leaf': 20, 'max_features': 0.5944222043307941, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:49:40,530] Trial 28 finished with value: 0.5848366013071896 and parameters: {'n_estimators': 83, 'max_depth': 37, 'min_samples_split': 0.1853042130980433, 'min_samples_leaf': 18, 'max_features': 0.1636501044651486, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:50:04,769] Trial 29 finished with value: 0.6128104575163399 and parameters: {'n_estimators': 171, 'max_depth': 44, 'min_samples_split': 0.07512100855391843, 'min_samples_leaf': 15, 'max_features': 0.2936032459415608, 'bootstrap': True}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:51:05,816] Trial 30 finished with value: 0.5916339869281045 and parameters: {'n_estimators': 325, 'max_depth': 32, 'min_samples_split': 0.13598696455793613, 'min_samples_leaf': 11, 'max_features': 0.4365731763253865, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:51:20,378] Trial 31 finished with value: 0.6732026143790849 and parameters: {'n_estimators': 51, 'max_depth': 43, 'min_samples_split': 0.014411740428832958, 'min_samples_leaf': 19, 'max_features': 0.39864211469896604, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:51:47,989] Trial 32 finished with value: 0.6352941176470588 and parameters: {'n_estimators': 75, 'max_depth': 41, 'min_samples_split': 0.04272894379698179, 'min_samples_leaf': 19, 'max_features': 0.5727801423336771, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:52:01,362] Trial 33 finished with value: 0.6122875816993464 and parameters: {'n_estimators': 105, 'max_depth': 48, 'min_samples_split': 0.09157150988039811, 'min_samples_leaf': 19, 'max_features': 0.24105247355721832, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:52:17,644] Trial 34 finished with value: 0.6188235294117647 and parameters: {'n_estimators': 75, 'max_depth': 37, 'min_samples_split': 0.07533985941863856, 'min_samples_leaf': 17, 'max_features': 0.32857993051339934, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:52:37,522] Trial 35 finished with value: 0.6622222222222222 and parameters: {'n_estimators': 50, 'max_depth': 43, 'min_samples_split': 0.010662061429897833, 'min_samples_leaf': 19, 'max_features': 0.4949203167358217, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:52:46,613] Trial 36 finished with value: 0.4551633986928105 and parameters: {'n_estimators': 124, 'max_depth': 27, 'min_samples_split': 0.37105402653160874, 'min_samples_leaf': 15, 'max_features': 0.38620614392937713, 'bootstrap': True}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:53:18,243] Trial 37 finished with value: 0.6528104575163399 and parameters: {'n_estimators': 235, 'max_depth': 35, 'min_samples_split': 0.037800661922208614, 'min_samples_leaf': 20, 'max_features': 0.19146485243835584, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:53:54,289] Trial 38 finished with value: 0.6075816993464053 and parameters: {'n_estimators': 154, 'max_depth': 23, 'min_samples_split': 0.09311012509851127, 'min_samples_leaf': 17, 'max_features': 0.4502652589437816, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:55:30,320] Trial 39 finished with value: 0.6261437908496732 and parameters: {'n_estimators': 500, 'max_depth': 29, 'min_samples_split': 0.05936007574579063, 'min_samples_leaf': 12, 'max_features': 0.3519031817265388, 'bootstrap': True}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:56:13,523] Trial 40 finished with value: 0.5764705882352942 and parameters: {'n_estimators': 188, 'max_depth': 19, 'min_samples_split': 0.15728470443328293, 'min_samples_leaf': 8, 'max_features': 0.5238360969038506, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:56:36,515] Trial 41 finished with value: 0.6522875816993464 and parameters: {'n_estimators': 66, 'max_depth': 41, 'min_samples_split': 0.02833765482158586, 'min_samples_leaf': 18, 'max_features': 0.37994804884584454, 'bootstrap': False}. Best is trial 13 with value: 0.6739869281045752.\n",
      "[I 2025-05-07 20:57:02,677] Trial 42 finished with value: 0.6980392156862746 and parameters: {'n_estimators': 55, 'max_depth': 39, 'min_samples_split': 0.016764029941844595, 'min_samples_leaf': 1, 'max_features': 0.4123331653177646, 'bootstrap': False}. Best is trial 42 with value: 0.6980392156862746.\n",
      "[I 2025-05-07 20:57:32,515] Trial 43 finished with value: 0.6567320261437909 and parameters: {'n_estimators': 91, 'max_depth': 47, 'min_samples_split': 0.04289983794775577, 'min_samples_leaf': 2, 'max_features': 0.3042394949329064, 'bootstrap': False}. Best is trial 42 with value: 0.6980392156862746.\n",
      "[I 2025-05-07 20:58:24,250] Trial 44 finished with value: 0.7116339869281045 and parameters: {'n_estimators': 113, 'max_depth': 39, 'min_samples_split': 0.010592267005094316, 'min_samples_leaf': 5, 'max_features': 0.41404881150661577, 'bootstrap': False}. Best is trial 44 with value: 0.7116339869281045.\n",
      "[I 2025-05-07 20:58:58,246] Trial 45 finished with value: 0.5958169934640524 and parameters: {'n_estimators': 110, 'max_depth': 38, 'min_samples_split': 0.11660397427514783, 'min_samples_leaf': 1, 'max_features': 0.46994458061569677, 'bootstrap': False}. Best is trial 44 with value: 0.7116339869281045.\n",
      "[I 2025-05-07 20:59:33,063] Trial 46 finished with value: 0.6112418300653594 and parameters: {'n_estimators': 141, 'max_depth': 43, 'min_samples_split': 0.08004614554886015, 'min_samples_leaf': 5, 'max_features': 0.40687777959700056, 'bootstrap': True}. Best is trial 44 with value: 0.7116339869281045.\n",
      "[I 2025-05-07 20:59:53,277] Trial 47 finished with value: 0.5173856209150327 and parameters: {'n_estimators': 85, 'max_depth': 40, 'min_samples_split': 0.34753477619256434, 'min_samples_leaf': 5, 'max_features': 0.6754446037461561, 'bootstrap': False}. Best is trial 44 with value: 0.7116339869281045.\n",
      "[I 2025-05-07 21:00:37,903] Trial 48 finished with value: 0.5411764705882353 and parameters: {'n_estimators': 208, 'max_depth': 35, 'min_samples_split': 0.2559494665092641, 'min_samples_leaf': 3, 'max_features': 0.5489211082733366, 'bootstrap': False}. Best is trial 44 with value: 0.7116339869281045.\n",
      "[I 2025-05-07 21:01:32,386] Trial 49 finished with value: 0.6499346405228758 and parameters: {'n_estimators': 115, 'max_depth': 44, 'min_samples_split': 0.0366262048664788, 'min_samples_leaf': 6, 'max_features': 0.516457406716272, 'bootstrap': False}. Best is trial 44 with value: 0.7116339869281045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 113, 'max_depth': 39, 'min_samples_split': 0.010592267005094316, 'min_samples_leaf': 5, 'max_features': 0.41404881150661577, 'bootstrap': False}\n",
      "Accuracy: 0.6296296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.59      0.71      0.64        34\n",
      "          Q2       0.76      0.76      0.76        33\n",
      "          Q3       0.60      0.53      0.56        34\n",
      "          Q4       0.58      0.53      0.55        34\n",
      "\n",
      "    accuracy                           0.63       135\n",
      "   macro avg       0.63      0.63      0.63       135\n",
      "weighted avg       0.63      0.63      0.63       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n",
    "\n",
    "# 1. Делим треки на train/test по названиям песен\n",
    "unique_tracks = df['Song'].unique()\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=df.groupby('Song')['Quadrant'].first()\n",
    ")\n",
    "\n",
    "# 2. Создаем train/test датафреймы\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "# 3. Выделяем признаки и метки\n",
    "X_train = train_df.drop(['Quadrant', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant']\n",
    "X_test = test_df.drop(['Quadrant', 'Song'], axis=1)\n",
    "y_test_true = test_df['Quadrant'].copy()  # Сохраняем истинные метки\n",
    "\n",
    "# 4. Оптимизация гиперпараметров (только по train!)\n",
    "def objective(trial):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 50),\n",
    "        min_samples_split=trial.suggest_float(\"min_samples_split\", 0.01, 0.5),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        max_features=trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "        bootstrap=trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Кросс-валидация внутри трейна\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# 5. Запуск Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# 6. Обучение финальной модели на всем трейне\n",
    "best_model = RandomForestClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Предсказание по частям треков на тесте\n",
    "test_df['Quadrant_predicted'] = best_model.predict(X_test)\n",
    "\n",
    "# 8. Мажоритарное голосование по трекам\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant'].first()\n",
    "\n",
    "# 9. Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "564133e6-7e03-4be6-a431-132163ff32fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.56      0.65      0.60        23\n",
      "          Q2       0.83      0.86      0.84        22\n",
      "          Q3       0.68      0.65      0.67        23\n",
      "          Q4       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.68      0.68      0.68        90\n",
      "weighted avg       0.68      0.68      0.68        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "model = RandomForestClassifier(n_estimators = 113, max_depth = 39, min_samples_split = 0.010592267005094316, min_samples_leaf = 5, max_features = 0.41404881150661577, bootstrap = False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Мажоритарное голосование по трекам\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "# Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd3f3b-9cf5-4a4a-a235-e1f88cacdcc6",
   "metadata": {},
   "source": [
    "# Взвешенное среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c56f95fa-dfa6-46ed-b04b-5643866f7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (взвешенное голосование): 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.64      0.70      0.67        23\n",
      "          Q2       0.83      0.86      0.84        22\n",
      "          Q3       0.73      0.70      0.71        23\n",
      "          Q4       0.60      0.55      0.57        22\n",
      "\n",
      "    accuracy                           0.70        90\n",
      "   macro avg       0.70      0.70      0.70        90\n",
      "weighted avg       0.70      0.70      0.70        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Подготовка данных ---\n",
    "\n",
    "# Кодируем целевую переменную\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "# Получаем уникальные треки\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "# Делим треки на train и test (по целым трекам, не по строкам)\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "# Создаем train/test датасеты\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "# Сохраняем истинные метки\n",
    "test_df['Quadrant_true'] = test_df['Quadrant_encoded']\n",
    "\n",
    "# Признаки и метки для обучения\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "\n",
    "# Подготовка признаков для теста\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song', 'Quadrant_true'], axis=1)\n",
    "\n",
    "# --- Обучение модели ---\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Предсказания вероятностей ---\n",
    "probas = model.predict_proba(X_test)\n",
    "classes = model.classes_\n",
    "\n",
    "# Добавим вероятности в test_df\n",
    "for i, cls in enumerate(classes):\n",
    "    test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "# --- Взвешенное голосование по треку ---\n",
    "proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "# Выбор класса с наибольшей средней вероятностью\n",
    "track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "\n",
    "# Истинные метки\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "# --- Метрики ---\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "report = classification_report(\n",
    "    track_true_labels,\n",
    "    track_predictions_encoded,\n",
    "    target_names=label_encoder.classes_\n",
    ")\n",
    "\n",
    "print(\"Accuracy (взвешенное голосование):\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206db45-6582-414a-8f56-2c2b53a170ea",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "be1d37d9-7fa0-4288-a757-cf05140889b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (взвешенное голосование): 0.674074074074074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.66      0.79      0.72        34\n",
      "          Q2       0.87      0.82      0.84        33\n",
      "          Q3       0.63      0.56      0.59        34\n",
      "          Q4       0.55      0.53      0.54        34\n",
      "\n",
      "    accuracy                           0.67       135\n",
      "   macro avg       0.68      0.68      0.67       135\n",
      "weighted avg       0.68      0.67      0.67       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Подготовка данных ---\n",
    "\n",
    "# Кодируем целевую переменную\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "# Получаем уникальные треки\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "# Делим треки на train и test (по целым трекам, не по строкам)\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "# Создаем train/test датасеты\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "# Сохраняем истинные метки\n",
    "test_df['Quadrant_true'] = test_df['Quadrant_encoded']\n",
    "\n",
    "# Признаки и метки для обучения\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "\n",
    "# Подготовка признаков для теста\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song', 'Quadrant_true'], axis=1)\n",
    "\n",
    "# --- Обучение модели ---\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Предсказания вероятностей ---\n",
    "probas = model.predict_proba(X_test)\n",
    "classes = model.classes_\n",
    "\n",
    "# Добавим вероятности в test_df\n",
    "for i, cls in enumerate(classes):\n",
    "    test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "# --- Взвешенное голосование по треку ---\n",
    "proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "# Выбор класса с наибольшей средней вероятностью\n",
    "track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "\n",
    "# Истинные метки\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "# --- Метрики ---\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "report = classification_report(\n",
    "    track_true_labels,\n",
    "    track_predictions_encoded,\n",
    "    target_names=label_encoder.classes_\n",
    ")\n",
    "\n",
    "print(\"Accuracy (взвешенное голосование):\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73914b91-ba35-4d8e-bdae-17881d34f879",
   "metadata": {},
   "source": [
    "# Взвешенное среднее + Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "56621cf2-6813-4a68-8f0c-f5d6024f615d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 23:07:06,293] A new study created in memory with name: no-name-bf9b0069-af58-421d-9b91-6beaecb3c7d0\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:07:59,825] Trial 0 finished with value: 0.7 and parameters: {'n_estimators': 500, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto'}. Best is trial 0 with value: 0.7.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:08:49,766] Trial 1 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 500, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 0 with value: 0.7.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:08:58,267] Trial 2 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-07 23:09:08,853] Trial 3 finished with value: 0.7 and parameters: {'n_estimators': 100, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:09:59,572] Trial 4 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 500, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-07 23:10:41,903] Trial 5 finished with value: 0.7 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:11:19,394] Trial 6 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 400, 'max_depth': 110, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-07 23:11:49,357] Trial 7 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 300, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-07 23:12:42,758] Trial 8 finished with value: 0.7 and parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-07 23:13:21,504] Trial 9 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:13:50,575] Trial 10 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:14:28,843] Trial 11 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:15:07,288] Trial 12 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 400, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:15:23,977] Trial 13 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:16:00,272] Trial 14 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:16:30,920] Trial 15 finished with value: 0.7 and parameters: {'n_estimators': 300, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:16:50,401] Trial 16 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:17:31,351] Trial 17 finished with value: 0.7 and parameters: {'n_estimators': 400, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:17:49,830] Trial 18 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:18:25,766] Trial 19 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 9 with value: 0.7111111111111111.\n",
      "[I 2025-05-07 23:19:04,557] Trial 20 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:19:40,747] Trial 21 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:20:20,102] Trial 22 finished with value: 0.7 and parameters: {'n_estimators': 300, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:20:45,082] Trial 23 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:21:05,753] Trial 24 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:21:26,494] Trial 25 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:21:57,144] Trial 26 finished with value: 0.7 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:22:08,068] Trial 27 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:22:25,483] Trial 28 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:22:58,141] Trial 29 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 300, 'max_depth': 110, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:23:29,489] Trial 30 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 300, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:23:50,270] Trial 31 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:24:11,191] Trial 32 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:24:21,343] Trial 33 finished with value: 0.7 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:24:43,644] Trial 34 finished with value: 0.7 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:24:53,956] Trial 35 finished with value: 0.7 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:25:24,885] Trial 36 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:25:46,467] Trial 37 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:26:16,878] Trial 38 finished with value: 0.7 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:26:28,564] Trial 39 finished with value: 0.7 and parameters: {'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:26:55,237] Trial 40 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:27:16,018] Trial 41 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:27:39,047] Trial 42 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:27:59,551] Trial 43 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:28:10,060] Trial 44 finished with value: 0.7 and parameters: {'n_estimators': 100, 'max_depth': 70, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:28:40,817] Trial 45 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:29:29,243] Trial 46 finished with value: 0.7 and parameters: {'n_estimators': 500, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2025-05-07 23:29:50,105] Trial 47 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:30:09,346] Trial 48 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n",
      "[I 2025-05-07 23:30:42,219] Trial 49 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 300, 'max_depth': 70, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 20 with value: 0.7222222222222222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Accuracy (взвешенное голосование): 0.7222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.63      0.74      0.68        23\n",
      "          Q2       0.86      0.86      0.86        22\n",
      "          Q3       0.73      0.70      0.71        23\n",
      "          Q4       0.68      0.59      0.63        22\n",
      "\n",
      "    accuracy                           0.72        90\n",
      "   macro avg       0.73      0.72      0.72        90\n",
      "weighted avg       0.73      0.72      0.72        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# --- Подготовка данных ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "test_df['Quadrant_true'] = test_df['Quadrant_encoded']\n",
    "\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song', 'Quadrant_true'], axis=1)\n",
    "\n",
    "# --- Определение функции оптимизации для Optuna ---\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 110, step=20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10, step=2),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4, step=1),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt']),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    probas = model.predict_proba(X_test)\n",
    "    classes = model.classes_\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "    proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "    track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "    track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "    track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "    accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "    return accuracy\n",
    "\n",
    "# --- Запуск оптимизации ---\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# --- Обучение модели с лучшими гиперпараметрами ---\n",
    "best_model = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "probas = best_model.predict_proba(X_test)\n",
    "classes = best_model.classes_\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "report = classification_report(track_true_labels, track_predictions_encoded, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"Accuracy (взвешенное голосование):\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3a2166f6-fb72-4b3f-b61c-928cc1cb3a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 23:35:18,957] A new study created in memory with name: no-name-8f930041-851d-4d80-9dc1-88488be6baad\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:35:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:36:02,635] Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.15790642541617875, 'subsample': 0.5319306149718444, 'colsample_bytree': 0.9838965683153312, 'gamma': 0.36834210951697366}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:36:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:37:20,045] Trial 1 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.027400969036043804, 'subsample': 0.9927728675552693, 'colsample_bytree': 0.6450838150338469, 'gamma': 0.36699177177904885}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:37:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:38:48,594] Trial 2 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.07342332063376601, 'subsample': 0.7001379243088375, 'colsample_bytree': 0.8881953922192044, 'gamma': 0.20503300404822455}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:38:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:40:03,046] Trial 3 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.04304592605844364, 'subsample': 0.6030433145064039, 'colsample_bytree': 0.647080838325685, 'gamma': 0.4861866903910883}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:40:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:40:18,775] Trial 4 finished with value: 0.6333333333333333 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.24775682680067798, 'subsample': 0.8056692196340289, 'colsample_bytree': 0.6407542651990464, 'gamma': 0.22963754412109683}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:40:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:40:33,567] Trial 5 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.20709807226202004, 'subsample': 0.7917521606206408, 'colsample_bytree': 0.9673201266665028, 'gamma': 1.524213484786081}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:40:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:40:48,377] Trial 6 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.2710485260444659, 'subsample': 0.9387920140627618, 'colsample_bytree': 0.8809946785061379, 'gamma': 3.899724663416184}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:40:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:41:17,843] Trial 7 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.061761439982174225, 'subsample': 0.7551164002541604, 'colsample_bytree': 0.7245591164255013, 'gamma': 4.67234428705606}. Best is trial 0 with value: 0.6666666666666666.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:41:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:41:51,736] Trial 8 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09336437482692563, 'subsample': 0.8177741331799839, 'colsample_bytree': 0.6904798660321592, 'gamma': 0.7059649689920056}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:41:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:42:58,358] Trial 9 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.03203361789846832, 'subsample': 0.6163520762621816, 'colsample_bytree': 0.8323025563366164, 'gamma': 0.39047954393599094}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:42:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:43:33,223] Trial 10 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 400, 'max_depth': 15, 'learning_rate': 0.12127762219223334, 'subsample': 0.886161313330329, 'colsample_bytree': 0.5142166933815131, 'gamma': 2.378004184804917}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:43:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:44:03,643] Trial 11 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.11744623127948724, 'subsample': 0.6451430477644822, 'colsample_bytree': 0.7802932276366931, 'gamma': 1.482307359276199}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:44:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:46:04,484] Trial 12 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 200, 'max_depth': 13, 'learning_rate': 0.01186439897939677, 'subsample': 0.5257066885800715, 'colsample_bytree': 0.7807809500977247, 'gamma': 1.436499241610971}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:46:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:46:39,027] Trial 13 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.09647147826419172, 'subsample': 0.858866946103458, 'colsample_bytree': 0.8743359325253761, 'gamma': 2.6217752017979357}. Best is trial 8 with value: 0.6888888888888889.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:46:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:47:11,042] Trial 14 finished with value: 0.7111111111111111 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.15295031915253157, 'subsample': 0.6822168198841638, 'colsample_bytree': 0.5270382013055497, 'gamma': 1.1691032088656743}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:47:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:47:38,000] Trial 15 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.168965969714066, 'subsample': 0.6985600341345513, 'colsample_bytree': 0.5117241261693363, 'gamma': 2.2334813087583147}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:48:08,115] Trial 16 finished with value: 0.6222222222222222 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.19776612028532348, 'subsample': 0.7062318972832037, 'colsample_bytree': 0.5845177370523292, 'gamma': 1.073320407539915}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:48:31,996] Trial 17 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.12870233845694326, 'subsample': 0.8725532126932845, 'colsample_bytree': 0.7010932655470542, 'gamma': 3.145147671963639}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:48:55,450] Trial 18 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.18809256845818376, 'subsample': 0.8150007690884639, 'colsample_bytree': 0.5815389861167044, 'gamma': 0.9903204092356064}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:49:25,410] Trial 19 finished with value: 0.6333333333333333 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.22644474634028422, 'subsample': 0.7537660188953856, 'colsample_bytree': 0.5825408071975188, 'gamma': 1.935923640857521}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:50:08,657] Trial 20 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.08391151933673045, 'subsample': 0.6508166870701156, 'colsample_bytree': 0.6925193888053373, 'gamma': 0.9535203128785785}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:50:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:51:21,088] Trial 21 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.04394950580055513, 'subsample': 0.5873821694442065, 'colsample_bytree': 0.816717779226136, 'gamma': 0.7789105869449453}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:51:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:52:18,303] Trial 22 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.1413852390165082, 'subsample': 0.5830847775742276, 'colsample_bytree': 0.8290715515724697, 'gamma': 0.08237414048664704}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:52:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:52:37,723] Trial 23 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1034546910776441, 'subsample': 0.6508055940166687, 'colsample_bytree': 0.7520815313889269, 'gamma': 1.8630801573733258}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:52:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:53:50,979] Trial 24 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 200, 'max_depth': 14, 'learning_rate': 0.06169593060032315, 'subsample': 0.7247774791203424, 'colsample_bytree': 0.9264642900405116, 'gamma': 0.6941543166383913}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:53:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:55:57,156] Trial 25 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.012679250893268167, 'subsample': 0.6344984955235818, 'colsample_bytree': 0.8198946592345986, 'gamma': 2.962785627771137}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:55:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:56:30,050] Trial 26 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.2979068472683356, 'subsample': 0.5570486702250126, 'colsample_bytree': 0.5427468314513516, 'gamma': 1.26622339475467}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:56:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:57:06,337] Trial 27 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.17360786235954884, 'subsample': 0.840280500758382, 'colsample_bytree': 0.6762859388535646, 'gamma': 0.6955217818569617}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:57:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:57:26,250] Trial 28 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1427987459008655, 'subsample': 0.9129638368819831, 'colsample_bytree': 0.6063228172219846, 'gamma': 1.8648374932453848}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:57:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 23:59:41,590] Trial 29 finished with value: 0.7 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.09535147195422347, 'subsample': 0.6825494548599306, 'colsample_bytree': 0.9865549711887789, 'gamma': 0.011985675983001043}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:59:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:00:35,462] Trial 30 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.08725913893724419, 'subsample': 0.7749750031424221, 'colsample_bytree': 0.9577956129184528, 'gamma': 0.00729368490756062}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:00:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:01:30,129] Trial 31 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.15091970955055584, 'subsample': 0.502168656825291, 'colsample_bytree': 0.9888728293830465, 'gamma': 0.6230553296933974}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:01:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:03:25,387] Trial 32 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.04138177198617102, 'subsample': 0.6762852328361396, 'colsample_bytree': 0.9222476737134627, 'gamma': 0.39012841250141317}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:03:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:04:31,766] Trial 33 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.1106899171892957, 'subsample': 0.6214641950653709, 'colsample_bytree': 0.8426053013999807, 'gamma': 0.3703302560260763}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:04:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:04:48,681] Trial 34 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.07223839476368682, 'subsample': 0.7311532207400874, 'colsample_bytree': 0.7663784421924806, 'gamma': 1.1010962146654464}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:04:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:07:37,930] Trial 35 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.029876254267607844, 'subsample': 0.6784314631608578, 'colsample_bytree': 0.9143768849618048, 'gamma': 0.39165185984329215}. Best is trial 14 with value: 0.7111111111111111.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:07:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:08:48,023] Trial 36 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1306167555154348, 'subsample': 0.6809985690046554, 'colsample_bytree': 0.6299077697675527, 'gamma': 0.06953923548252894}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:08:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:10:15,133] Trial 37 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.16525739926881186, 'subsample': 0.7728442267358614, 'colsample_bytree': 0.6336726475362815, 'gamma': 0.0076834599766557226}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:10:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:11:07,463] Trial 38 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.13320319952684917, 'subsample': 0.6817043163909764, 'colsample_bytree': 0.5424014798806326, 'gamma': 0.22378800770179658}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:11:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:11:57,850] Trial 39 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.09838174504363784, 'subsample': 0.8159358082253496, 'colsample_bytree': 0.6616548856713028, 'gamma': 0.8234763718104516}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:11:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:12:16,888] Trial 40 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.18374481836245377, 'subsample': 0.9648478348357574, 'colsample_bytree': 0.7206129299865909, 'gamma': 4.996169548948156}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:12:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:13:36,556] Trial 41 finished with value: 0.7 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.056005326599917804, 'subsample': 0.6176840560350625, 'colsample_bytree': 0.6270923935480741, 'gamma': 0.5046547660090388}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:13:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:14:49,248] Trial 42 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.06388331297990543, 'subsample': 0.6011136950568965, 'colsample_bytree': 0.6183398722390798, 'gamma': 0.4969700106797943}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:14:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:15:58,455] Trial 43 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.07733829787713448, 'subsample': 0.7249304065426284, 'colsample_bytree': 0.543830215662657, 'gamma': 0.21703084254494073}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:15:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:16:29,389] Trial 44 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.11916510613968734, 'subsample': 0.5599508309623897, 'colsample_bytree': 0.6565979532140994, 'gamma': 1.3073721731306103}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:16:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:17:43,097] Trial 45 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.049970013878073774, 'subsample': 0.6600289697851109, 'colsample_bytree': 0.5639721201073304, 'gamma': 0.6871758568832596}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:18:37,315] Trial 46 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.09284716101601559, 'subsample': 0.7071236529456262, 'colsample_bytree': 0.6125388792815405, 'gamma': 0.5566295053342706}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:18:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:19:00,121] Trial 47 finished with value: 0.6555555555555556 and parameters: {'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.15509741059056634, 'subsample': 0.7887315762467746, 'colsample_bytree': 0.7152572492092559, 'gamma': 4.250222140784539}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:19:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:19:33,815] Trial 48 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.1077833344786518, 'subsample': 0.624623297121754, 'colsample_bytree': 0.6338940927969435, 'gamma': 1.687315338590806}. Best is trial 36 with value: 0.7222222222222222.\n",
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:19:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-08 00:20:25,644] Trial 49 finished with value: 0.6777777777777778 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.1265735180739357, 'subsample': 0.6934432941635306, 'colsample_bytree': 0.6813469670055968, 'gamma': 0.20914120192000524}. Best is trial 36 with value: 0.7222222222222222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.1306167555154348, 'subsample': 0.6809985690046554, 'colsample_bytree': 0.6299077697675527, 'gamma': 0.06953923548252894}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\.conda\\anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:20:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (взвешенное голосование): 0.7222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.72      0.78      0.75        23\n",
      "          Q2       0.88      0.95      0.91        22\n",
      "          Q3       0.70      0.61      0.65        23\n",
      "          Q4       0.57      0.55      0.56        22\n",
      "\n",
      "    accuracy                           0.72        90\n",
      "   macro avg       0.72      0.72      0.72        90\n",
      "weighted avg       0.72      0.72      0.72        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# --- Подготовка данных ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "test_df['Quadrant_true'] = test_df['Quadrant_encoded']\n",
    "\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song', 'Quadrant_true'], axis=1)\n",
    "\n",
    "# --- Определение функции оптимизации для Optuna ---\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    probas = model.predict_proba(X_test)\n",
    "    classes = model.classes_\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "    proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "    track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "    track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "    track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "    accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "    return accuracy\n",
    "\n",
    "# --- Запуск оптимизации ---\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# --- Обучение модели с лучшими гиперпараметрами ---\n",
    "best_model = xgb.XGBClassifier(**study.best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "probas = best_model.predict_proba(X_test)\n",
    "classes = best_model.classes_\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    test_df[f'proba_{cls}'] = probas[:, i]\n",
    "\n",
    "proba_cols = [f'proba_{cls}' for cls in classes]\n",
    "track_probas = test_df.groupby('Song')[proba_cols].mean()\n",
    "\n",
    "track_predictions_encoded = track_probas.idxmax(axis=1).apply(lambda x: int(x.replace(\"proba_\", \"\")))\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions_encoded)\n",
    "report = classification_report(track_true_labels, track_predictions_encoded, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"Accuracy (взвешенное голосование):\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6e3d4-f0fe-4f16-b782-cc9856c0f36c",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров и XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c76a54b3-5a70-4776-8245-898860cb47ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_7028\\2715908434.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
      "[I 2025-05-07 19:18:34,055] A new study created in memory with name: no-name-90cf111e-be79-48d6-b249-7b045525e88d\n",
      "[I 2025-05-07 19:18:57,647] Trial 0 finished with value: 0.6281481481481481 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.0202225534609789, 'subsample': 0.8617846284895918, 'colsample_bytree': 0.8443188047621206, 'gamma': 2.7786450016043336, 'reg_alpha': 3.7846295774664176, 'reg_lambda': 3.494898055368176}. Best is trial 0 with value: 0.6281481481481481.\n",
      "[I 2025-05-07 19:19:26,664] Trial 1 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.06657777591472111, 'subsample': 0.7120913366078359, 'colsample_bytree': 0.6875367435265285, 'gamma': 2.5268837377562954, 'reg_alpha': 2.4680016795902526, 'reg_lambda': 0.7455783517342024}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:19:49,630] Trial 2 finished with value: 0.6355555555555555 and parameters: {'n_estimators': 176, 'max_depth': 13, 'learning_rate': 0.07635491165146087, 'subsample': 0.8811814710554302, 'colsample_bytree': 0.8854534820529707, 'gamma': 2.778684108971801, 'reg_alpha': 3.4600593852532358, 'reg_lambda': 3.832884310115656}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:19:55,186] Trial 3 finished with value: 0.6118518518518519 and parameters: {'n_estimators': 50, 'max_depth': 11, 'learning_rate': 0.19496136987670232, 'subsample': 0.9960849582317665, 'colsample_bytree': 0.553278852797747, 'gamma': 4.908011041663078, 'reg_alpha': 3.363288418766555, 'reg_lambda': 4.796660994170877}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:20:12,162] Trial 4 finished with value: 0.6385185185185185 and parameters: {'n_estimators': 201, 'max_depth': 3, 'learning_rate': 0.06683017026888793, 'subsample': 0.8588249504714174, 'colsample_bytree': 0.7416453805732225, 'gamma': 2.8901653322602767, 'reg_alpha': 2.5181657674699216, 'reg_lambda': 2.5045768640921064}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:20:54,223] Trial 5 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.027938856005155742, 'subsample': 0.5171434529970116, 'colsample_bytree': 0.6776038189623915, 'gamma': 2.810009446423964, 'reg_alpha': 2.2186600053403027, 'reg_lambda': 0.45553326328692745}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:21:16,392] Trial 6 finished with value: 0.6355555555555555 and parameters: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.07869487112548054, 'subsample': 0.8956527172080251, 'colsample_bytree': 0.5813366276438011, 'gamma': 2.3292768552108036, 'reg_alpha': 2.3601111390425595, 'reg_lambda': 3.8966294750706236}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:21:58,038] Trial 7 finished with value: 0.6251851851851852 and parameters: {'n_estimators': 69, 'max_depth': 13, 'learning_rate': 0.01328803488007905, 'subsample': 0.9883830819492145, 'colsample_bytree': 0.8832564173699187, 'gamma': 1.6347927898425136, 'reg_alpha': 3.9740993439558263, 'reg_lambda': 3.798070420167124}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:22:15,996] Trial 8 finished with value: 0.6311111111111111 and parameters: {'n_estimators': 145, 'max_depth': 15, 'learning_rate': 0.07493515481556619, 'subsample': 0.8444170747855066, 'colsample_bytree': 0.730146969481601, 'gamma': 4.780542735288406, 'reg_alpha': 0.3331321825654693, 'reg_lambda': 0.7332660243754596}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:22:27,845] Trial 9 finished with value: 0.6266666666666667 and parameters: {'n_estimators': 133, 'max_depth': 3, 'learning_rate': 0.033865072947175244, 'subsample': 0.5895469917464917, 'colsample_bytree': 0.5267777123733772, 'gamma': 3.774556153241981, 'reg_alpha': 1.9131173509169979, 'reg_lambda': 1.6405104912548207}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:22:54,722] Trial 10 finished with value: 0.6177777777777778 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.17420771566273724, 'subsample': 0.6561997717974287, 'colsample_bytree': 0.6431413538320474, 'gamma': 0.7206588461644134, 'reg_alpha': 4.891207850953756, 'reg_lambda': 1.5770089123948796}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:23:51,061] Trial 11 finished with value: 0.6414814814814814 and parameters: {'n_estimators': 279, 'max_depth': 9, 'learning_rate': 0.033961529546370384, 'subsample': 0.5029630966355556, 'colsample_bytree': 0.6779127311450438, 'gamma': 1.569228565302677, 'reg_alpha': 1.352657470800462, 'reg_lambda': 0.020061870242574664}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:24:27,581] Trial 12 finished with value: 0.6459259259259259 and parameters: {'n_estimators': 241, 'max_depth': 7, 'learning_rate': 0.03658247155648667, 'subsample': 0.7076735716076451, 'colsample_bytree': 0.7996244234433685, 'gamma': 3.734700155172771, 'reg_alpha': 1.1914799509352973, 'reg_lambda': 0.18908879878850726}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:24:49,816] Trial 13 finished with value: 0.6266666666666667 and parameters: {'n_estimators': 242, 'max_depth': 6, 'learning_rate': 0.1166261066376952, 'subsample': 0.7394503822075285, 'colsample_bytree': 0.9881051273762991, 'gamma': 3.808634019410697, 'reg_alpha': 0.5821861987833636, 'reg_lambda': 1.1904302838365581}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:25:24,092] Trial 14 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 216, 'max_depth': 7, 'learning_rate': 0.04489150277597562, 'subsample': 0.7229425469812564, 'colsample_bytree': 0.7974247207321633, 'gamma': 3.7726168905232353, 'reg_alpha': 1.2315440270819815, 'reg_lambda': 2.36509544795465}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:25:56,484] Trial 15 finished with value: 0.642962962962963 and parameters: {'n_estimators': 216, 'max_depth': 11, 'learning_rate': 0.04703351822546296, 'subsample': 0.6608602323466459, 'colsample_bytree': 0.7841094255858391, 'gamma': 4.293432330963762, 'reg_alpha': 1.207778177449082, 'reg_lambda': 2.6650807146701143}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:26:25,516] Trial 16 finished with value: 0.6177777777777778 and parameters: {'n_estimators': 231, 'max_depth': 11, 'learning_rate': 0.12454554429216197, 'subsample': 0.8005368207111349, 'colsample_bytree': 0.6274138844283382, 'gamma': 1.9706269673057681, 'reg_alpha': 2.8461736215497946, 'reg_lambda': 1.9791384609952327}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:27:36,281] Trial 17 finished with value: 0.6385185185185185 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.01047004200279929, 'subsample': 0.7864718809445721, 'colsample_bytree': 0.9624412354924169, 'gamma': 0.4077188972246164, 'reg_alpha': 1.7276135639378587, 'reg_lambda': 2.9063741906857}. Best is trial 1 with value: 0.6474074074074074.\n",
      "[I 2025-05-07 19:28:31,965] Trial 18 finished with value: 0.6548148148148148 and parameters: {'n_estimators': 191, 'max_depth': 8, 'learning_rate': 0.01959020182316779, 'subsample': 0.6013328616592277, 'colsample_bytree': 0.7120070994024739, 'gamma': 3.3847491844685056, 'reg_alpha': 0.03993268430871577, 'reg_lambda': 0.9543041951287118}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:28:47,841] Trial 19 finished with value: 0.6340740740740741 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.28727969488360267, 'subsample': 0.5850986362846967, 'colsample_bytree': 0.7048208623975213, 'gamma': 3.2177693484182845, 'reg_alpha': 0.053614635970925584, 'reg_lambda': 0.8909516878231195}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:29:23,893] Trial 20 finished with value: 0.6237037037037036 and parameters: {'n_estimators': 99, 'max_depth': 13, 'learning_rate': 0.019175560042818195, 'subsample': 0.6034457633551307, 'colsample_bytree': 0.6138880653072181, 'gamma': 2.170310776111296, 'reg_alpha': 4.553874685080179, 'reg_lambda': 1.2116439819203304}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:29:58,175] Trial 21 finished with value: 0.6296296296296297 and parameters: {'n_estimators': 209, 'max_depth': 8, 'learning_rate': 0.05559928224784854, 'subsample': 0.6880639301682683, 'colsample_bytree': 0.7993034611979231, 'gamma': 3.4726016485144955, 'reg_alpha': 0.7311339988440657, 'reg_lambda': 2.093431226906559}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:30:40,198] Trial 22 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.0207276488864408, 'subsample': 0.6253007203571921, 'colsample_bytree': 0.7551591396348913, 'gamma': 4.252026784322845, 'reg_alpha': 0.7752835452748861, 'reg_lambda': 3.046356687194958}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:31:20,678] Trial 23 finished with value: 0.6325925925925926 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.04694852091250368, 'subsample': 0.7353690515159788, 'colsample_bytree': 0.8409773824194331, 'gamma': 3.24486452903679, 'reg_alpha': 0.006376536308829936, 'reg_lambda': 2.003607813774165}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:31:49,408] Trial 24 finished with value: 0.6370370370370371 and parameters: {'n_estimators': 255, 'max_depth': 10, 'learning_rate': 0.11027034310127139, 'subsample': 0.5457376492526098, 'colsample_bytree': 0.7072432876516055, 'gamma': 4.255471256240565, 'reg_alpha': 1.5762636055432828, 'reg_lambda': 0.7830891871705769}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:33:28,798] Trial 25 finished with value: 0.6355555555555555 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.015222622784499817, 'subsample': 0.8025445911664373, 'colsample_bytree': 0.7603824658362938, 'gamma': 0.9569385781685775, 'reg_alpha': 0.9933219073355815, 'reg_lambda': 1.3668054430003513}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:33:59,612] Trial 26 finished with value: 0.6340740740740741 and parameters: {'n_estimators': 191, 'max_depth': 4, 'learning_rate': 0.028902047896057236, 'subsample': 0.7029623100840761, 'colsample_bytree': 0.6791985994977578, 'gamma': 3.370399001050754, 'reg_alpha': 3.0398113223808205, 'reg_lambda': 4.665971006589651}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:34:42,445] Trial 27 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 165, 'max_depth': 7, 'learning_rate': 0.04634868823189118, 'subsample': 0.6492901015649822, 'colsample_bytree': 0.8476013107894418, 'gamma': 2.487865876323694, 'reg_alpha': 0.3312528965675103, 'reg_lambda': 0.5138042764483315}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:35:27,072] Trial 28 finished with value: 0.6370370370370371 and parameters: {'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.025507118871348385, 'subsample': 0.743041385430534, 'colsample_bytree': 0.5856709273947669, 'gamma': 1.8595851882060463, 'reg_alpha': 2.051012751175683, 'reg_lambda': 2.1837830828607876}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:35:45,259] Trial 29 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 207, 'max_depth': 5, 'learning_rate': 0.09283602032084379, 'subsample': 0.5553233500282873, 'colsample_bytree': 0.8386219727714942, 'gamma': 4.516771447683949, 'reg_alpha': 2.678212091091869, 'reg_lambda': 3.1352666151607935}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:36:44,252] Trial 30 finished with value: 0.6533333333333333 and parameters: {'n_estimators': 254, 'max_depth': 8, 'learning_rate': 0.020762537197633272, 'subsample': 0.769433203330068, 'colsample_bytree': 0.6568701330596907, 'gamma': 3.0766828324876485, 'reg_alpha': 1.4324497110969052, 'reg_lambda': 1.6479129175071483}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:37:54,681] Trial 31 finished with value: 0.6459259259259259 and parameters: {'n_estimators': 255, 'max_depth': 8, 'learning_rate': 0.015647505183715184, 'subsample': 0.7654054637286024, 'colsample_bytree': 0.6524864325149118, 'gamma': 2.913838279697855, 'reg_alpha': 1.5420296038895833, 'reg_lambda': 1.590693454256546}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:39:05,279] Trial 32 finished with value: 0.6548148148148148 and parameters: {'n_estimators': 279, 'max_depth': 9, 'learning_rate': 0.02080680770024117, 'subsample': 0.6851597077978, 'colsample_bytree': 0.7117810180105995, 'gamma': 3.058815160662568, 'reg_alpha': 1.0090375548412698, 'reg_lambda': 1.074575773191469}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:40:17,655] Trial 33 finished with value: 0.6503703703703704 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.0229377020815817, 'subsample': 0.672960452748318, 'colsample_bytree': 0.7146082375457218, 'gamma': 2.489435372160206, 'reg_alpha': 0.35828487897381694, 'reg_lambda': 0.9937666372945839}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:41:19,814] Trial 34 finished with value: 0.6385185185185185 and parameters: {'n_estimators': 286, 'max_depth': 10, 'learning_rate': 0.021899214892407128, 'subsample': 0.669651833167241, 'colsample_bytree': 0.7223018840459213, 'gamma': 3.069849245625271, 'reg_alpha': 0.40155606651431175, 'reg_lambda': 1.0589540043212866}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:42:47,130] Trial 35 finished with value: 0.6355555555555555 and parameters: {'n_estimators': 268, 'max_depth': 12, 'learning_rate': 0.010710824934602067, 'subsample': 0.6279726838985467, 'colsample_bytree': 0.6556222295968339, 'gamma': 3.568126557448814, 'reg_alpha': 0.9038533087166568, 'reg_lambda': 0.4229273600533938}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:44:04,630] Trial 36 finished with value: 0.64 and parameters: {'n_estimators': 245, 'max_depth': 9, 'learning_rate': 0.019115975517715832, 'subsample': 0.6189640777712518, 'colsample_bytree': 0.5971747150348142, 'gamma': 2.394816287266482, 'reg_alpha': 0.4839120464242427, 'reg_lambda': 1.8118166178171573}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:45:39,352] Trial 37 finished with value: 0.6488888888888888 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.013321272200094256, 'subsample': 0.6845344851238367, 'colsample_bytree': 0.6963842126908772, 'gamma': 2.7232481374816953, 'reg_alpha': 0.17955078671319777, 'reg_lambda': 1.356510737051833}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:46:43,552] Trial 38 finished with value: 0.6444444444444445 and parameters: {'n_estimators': 299, 'max_depth': 6, 'learning_rate': 0.016459380387231336, 'subsample': 0.9290683362607974, 'colsample_bytree': 0.5581020701012965, 'gamma': 2.6060359921074507, 'reg_alpha': 0.9323012831023636, 'reg_lambda': 0.9403947051634254}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:47:43,177] Trial 39 finished with value: 0.6488888888888888 and parameters: {'n_estimators': 259, 'max_depth': 8, 'learning_rate': 0.026386462307781196, 'subsample': 0.7669641563139558, 'colsample_bytree': 0.7486940340953586, 'gamma': 3.021696816426763, 'reg_alpha': 0.6356805923443083, 'reg_lambda': 0.5591169895177954}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:48:44,212] Trial 40 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 233, 'max_depth': 9, 'learning_rate': 0.023111393574631697, 'subsample': 0.5344317768966738, 'colsample_bytree': 0.5082773872487649, 'gamma': 2.109921087538184, 'reg_alpha': 0.25045416717966495, 'reg_lambda': 1.386939231507733}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:50:16,374] Trial 41 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 280, 'max_depth': 9, 'learning_rate': 0.012766432141828588, 'subsample': 0.6900738251026199, 'colsample_bytree': 0.706368662899323, 'gamma': 2.708414331363936, 'reg_alpha': 0.16954565338339292, 'reg_lambda': 1.337974934914078}. Best is trial 18 with value: 0.6548148148148148.\n",
      "[I 2025-05-07 19:51:50,883] Trial 42 finished with value: 0.6562962962962963 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.012061780773956976, 'subsample': 0.6831818777114562, 'colsample_bytree': 0.6632851105280485, 'gamma': 2.7345480107386457, 'reg_alpha': 0.010485174920886964, 'reg_lambda': 1.698396786566164}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:53:44,812] Trial 43 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 265, 'max_depth': 11, 'learning_rate': 0.016976307129953152, 'subsample': 0.8306294270442709, 'colsample_bytree': 0.6617368323628742, 'gamma': 1.4115999794997276, 'reg_alpha': 0.5325168554927872, 'reg_lambda': 1.0454176936482802}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:54:32,547] Trial 44 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.030843154262390534, 'subsample': 0.6435536119438893, 'colsample_bytree': 0.6304212522469775, 'gamma': 3.093207719555091, 'reg_alpha': 0.9906678657411012, 'reg_lambda': 1.6876487502087303}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:56:03,388] Trial 45 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 289, 'max_depth': 8, 'learning_rate': 0.01297639413545211, 'subsample': 0.5876791731543354, 'colsample_bytree': 0.7239811165876068, 'gamma': 2.2716217465986936, 'reg_alpha': 0.4128836611142351, 'reg_lambda': 0.35613651727077367}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:57:10,561] Trial 46 finished with value: 0.6355555555555555 and parameters: {'n_estimators': 272, 'max_depth': 12, 'learning_rate': 0.024706079837323185, 'subsample': 0.5639577936418474, 'colsample_bytree': 0.7634858225150776, 'gamma': 2.5785430248044285, 'reg_alpha': 0.7053288638711387, 'reg_lambda': 0.6890496215225463}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:57:47,825] Trial 47 finished with value: 0.642962962962963 and parameters: {'n_estimators': 195, 'max_depth': 7, 'learning_rate': 0.03892600274775425, 'subsample': 0.7150700435143501, 'colsample_bytree': 0.6831064758329494, 'gamma': 2.86508811895038, 'reg_alpha': 1.4032071304455376, 'reg_lambda': 2.3291771198306503}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:58:44,902] Trial 48 finished with value: 0.6474074074074074 and parameters: {'n_estimators': 233, 'max_depth': 12, 'learning_rate': 0.018277386594467857, 'subsample': 0.6769644642524775, 'colsample_bytree': 0.611491530181437, 'gamma': 3.9836053684286465, 'reg_alpha': 0.04325839040929352, 'reg_lambda': 1.8625297273983652}. Best is trial 42 with value: 0.6562962962962963.\n",
      "[I 2025-05-07 19:59:17,941] Trial 49 finished with value: 0.6385185185185185 and parameters: {'n_estimators': 76, 'max_depth': 11, 'learning_rate': 0.011371932781752067, 'subsample': 0.7720955443173328, 'colsample_bytree': 0.7350064997841238, 'gamma': 3.464515587171074, 'reg_alpha': 1.9320242641107757, 'reg_lambda': 0.2567213568444444}. Best is trial 42 with value: 0.6562962962962963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.012061780773956976, 'subsample': 0.6831818777114562, 'colsample_bytree': 0.6632851105280485, 'gamma': 2.7345480107386457, 'reg_alpha': 0.010485174920886964, 'reg_lambda': 1.698396786566164}\n",
      "Accuracy: 0.6592592592592592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.59      0.68      0.63        34\n",
      "          Q2       0.77      0.82      0.79        33\n",
      "          Q3       0.70      0.56      0.62        34\n",
      "          Q4       0.59      0.59      0.59        34\n",
      "\n",
      "    accuracy                           0.66       135\n",
      "   macro avg       0.66      0.66      0.66       135\n",
      "weighted avg       0.66      0.66      0.66       135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_7028\\2715908434.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Quadrant_encoded'] = best_model.predict(X_test)\n",
      "C:\\Users\\Mary\\AppData\\Local\\Temp\\ipykernel_7028\\2715908434.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Quadrant_predicted'] = label_encoder.inverse_transform(test_df['Quadrant_encoded'])\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "# --- Этап 1: Кодирование целевой переменной ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "# Получаем уникальные треки\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "# Делим треки на train и test\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "# Создаем train/test датасеты\n",
    "train_df = df[df['Song'].isin(train_tracks)]\n",
    "test_df = df[df['Song'].isin(test_tracks)]\n",
    "\n",
    "# Признаки и метки\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_test = test_df['Quadrant_encoded']\n",
    "\n",
    "# --- Этап 2: Оптимизация гиперпараметров ---\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0,\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# --- Этап 3: Обучение финальной модели ---\n",
    "best_model = XGBClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и обратное декодирование\n",
    "test_df['Quadrant_encoded'] = best_model.predict(X_test)\n",
    "test_df['Quadrant_predicted'] = label_encoder.inverse_transform(test_df['Quadrant_encoded'])\n",
    "\n",
    "# Мажоритарное голосование\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant'].first()\n",
    "\n",
    "# Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e7176d45-df0a-4302-b924-2854e2d82a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6632851105280485, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=2.7345480107386457, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012061780773956976,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=267, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6632851105280485, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=2.7345480107386457, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012061780773956976,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=267, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6632851105280485, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=2.7345480107386457, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.012061780773956976,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=267, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['Quadrant'] = label_encoder.fit_transform(train_df['Quadrant'])\n",
    "\n",
    "# Признаки и метки\n",
    "X_train = train_df.drop(['Quadrant', 'Song'],axis=1)  # Подставь свои признаки\n",
    "y_train = train_df['Quadrant']\n",
    "\n",
    "# Обучение модели\n",
    "model = XGBClassifier(n_estimators = 267, max_depth = 10, learning_rate = 0.012061780773956976, subsample = 0.6831818777114562, colsample_bytree = 0.6632851105280485, gamma = 2.7345480107386457, reg_alpha = 0.010485174920886964, reg_lambda = 1.698396786566164)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "94049293-d284-4cb5-9321-f72824cb7c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.56      0.65      0.60        23\n",
      "          Q2       0.83      0.86      0.84        22\n",
      "          Q3       0.68      0.65      0.67        23\n",
      "          Q4       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.68        90\n",
      "   macro avg       0.68      0.68      0.68        90\n",
      "weighted avg       0.68      0.68      0.68        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "test_df['Quadrant'] = label_encoder.fit_transform(test_df['Quadrant'])\n",
    "\n",
    "# Мажоритарное голосование по трекам\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant_true'].first()\n",
    "\n",
    "# Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bd0d5-5e82-4c5e-9cbc-8fbfbfdd06ef",
   "metadata": {},
   "source": [
    "# Более сильный поиск по сетке с кросс-валидацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4363b1e8-5ab7-41b3-9c2e-0b3cf7d9e802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 21:51:34,006] A new study created in memory with name: no-name-43316c83-7e76-4d55-948c-a9f2de39aad5\n",
      "[I 2025-05-07 21:52:30,572] Trial 0 finished with value: 0.5840522875816992 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.012650498511991952, 'subsample': 0.531423888600521, 'colsample_bytree': 0.5101134918699682, 'gamma': 3.0526096260536577, 'reg_alpha': 1.8040819732872566, 'reg_lambda': 4.466096181303164}. Best is trial 0 with value: 0.5840522875816992.\n",
      "[I 2025-05-07 21:53:34,079] Trial 1 finished with value: 0.6047058823529412 and parameters: {'n_estimators': 244, 'max_depth': 3, 'learning_rate': 0.04069000625670161, 'subsample': 0.7186364465336084, 'colsample_bytree': 0.7325852693265797, 'gamma': 1.7516392892581167, 'reg_alpha': 1.6137915105126095, 'reg_lambda': 0.6852271775491608}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 21:56:26,911] Trial 2 finished with value: 0.5976470588235294 and parameters: {'n_estimators': 263, 'max_depth': 13, 'learning_rate': 0.01593950279464614, 'subsample': 0.9840038240919, 'colsample_bytree': 0.6978310697780143, 'gamma': 3.0826400773176577, 'reg_alpha': 4.661990658926915, 'reg_lambda': 2.7590764381178206}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 21:57:40,994] Trial 3 finished with value: 0.5992156862745098 and parameters: {'n_estimators': 179, 'max_depth': 13, 'learning_rate': 0.058707256476523494, 'subsample': 0.790390019275006, 'colsample_bytree': 0.7181455195945754, 'gamma': 2.916358288575545, 'reg_alpha': 3.0910414939457476, 'reg_lambda': 4.70014420319962}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 21:58:58,411] Trial 4 finished with value: 0.5916339869281045 and parameters: {'n_estimators': 259, 'max_depth': 3, 'learning_rate': 0.02046319138205782, 'subsample': 0.9421815473275064, 'colsample_bytree': 0.8821614125048791, 'gamma': 3.9850624172095643, 'reg_alpha': 2.7122385377926133, 'reg_lambda': 1.8633228015190322}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:00:15,149] Trial 5 finished with value: 0.5981699346405228 and parameters: {'n_estimators': 255, 'max_depth': 15, 'learning_rate': 0.08578015987003564, 'subsample': 0.9758781690976114, 'colsample_bytree': 0.9156015485040421, 'gamma': 3.754967160444944, 'reg_alpha': 1.9494514649356027, 'reg_lambda': 4.14354688200466}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:02:22,251] Trial 6 finished with value: 0.5971241830065359 and parameters: {'n_estimators': 215, 'max_depth': 7, 'learning_rate': 0.026116338985286244, 'subsample': 0.8006228352261557, 'colsample_bytree': 0.9885393755376899, 'gamma': 3.877442750240909, 'reg_alpha': 3.1718715041387293, 'reg_lambda': 2.5632910300949163}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:04:21,322] Trial 7 finished with value: 0.5871895424836602 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.013521538578699947, 'subsample': 0.7233390887653555, 'colsample_bytree': 0.6371268890258563, 'gamma': 0.8211130058405858, 'reg_alpha': 2.1420387003076184, 'reg_lambda': 2.8872225232696285}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:05:33,136] Trial 8 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 214, 'max_depth': 13, 'learning_rate': 0.06391372226039713, 'subsample': 0.6794570541044498, 'colsample_bytree': 0.5472734129072869, 'gamma': 2.6198368871706212, 'reg_alpha': 4.6591289834906835, 'reg_lambda': 1.7213226163626678}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:06:13,396] Trial 9 finished with value: 0.5908496732026144 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.25921897014398787, 'subsample': 0.668341574222007, 'colsample_bytree': 0.8689219225808954, 'gamma': 1.8612502678852372, 'reg_alpha': 3.0025470474716522, 'reg_lambda': 4.19299799622202}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:06:29,253] Trial 10 finished with value: 0.5905882352941177 and parameters: {'n_estimators': 54, 'max_depth': 3, 'learning_rate': 0.1437741921400436, 'subsample': 0.5601616622355059, 'colsample_bytree': 0.7888374616321151, 'gamma': 0.4404896540418868, 'reg_alpha': 0.13816664011841606, 'reg_lambda': 0.07891280996506866}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:08:43,467] Trial 11 finished with value: 0.6002614379084967 and parameters: {'n_estimators': 110, 'max_depth': 11, 'learning_rate': 0.03311210274886029, 'subsample': 0.8280589765131136, 'colsample_bytree': 0.7380242527457058, 'gamma': 1.4150073653373094, 'reg_alpha': 0.4904224132139645, 'reg_lambda': 0.07475083339561184}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:10:45,587] Trial 12 finished with value: 0.5994771241830065 and parameters: {'n_estimators': 97, 'max_depth': 10, 'learning_rate': 0.03668297383661779, 'subsample': 0.8793767770037404, 'colsample_bytree': 0.7891928514996549, 'gamma': 1.667830354602216, 'reg_alpha': 0.5981601478043761, 'reg_lambda': 0.21040135674947225}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:12:36,933] Trial 13 finished with value: 0.596078431372549 and parameters: {'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.036753816995125324, 'subsample': 0.8494784743968665, 'colsample_bytree': 0.6118038047366194, 'gamma': 1.371863408270633, 'reg_alpha': 1.1066275873352875, 'reg_lambda': 0.7812018392443074}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:13:59,208] Trial 14 finished with value: 0.5955555555555555 and parameters: {'n_estimators': 63, 'max_depth': 8, 'learning_rate': 0.0366811047729004, 'subsample': 0.5946562250022103, 'colsample_bytree': 0.7855354377696901, 'gamma': 0.016486471288827076, 'reg_alpha': 1.2894455208456694, 'reg_lambda': 1.004004754820556}. Best is trial 1 with value: 0.6047058823529412.\n",
      "[I 2025-05-07 22:15:11,509] Trial 15 finished with value: 0.6052287581699346 and parameters: {'n_estimators': 284, 'max_depth': 11, 'learning_rate': 0.09355537410296143, 'subsample': 0.7413161304778753, 'colsample_bytree': 0.6747481043134732, 'gamma': 2.0899433321250074, 'reg_alpha': 0.8595166482699502, 'reg_lambda': 0.9764912242726332}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:16:04,573] Trial 16 finished with value: 0.6036601307189543 and parameters: {'n_estimators': 298, 'max_depth': 4, 'learning_rate': 0.11868760397199139, 'subsample': 0.6449446044295788, 'colsample_bytree': 0.649866500980042, 'gamma': 2.1579134387084413, 'reg_alpha': 1.297590827298739, 'reg_lambda': 1.3973214673693455}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:16:48,362] Trial 17 finished with value: 0.5864052287581699 and parameters: {'n_estimators': 288, 'max_depth': 11, 'learning_rate': 0.1603901259761862, 'subsample': 0.7088763931303497, 'colsample_bytree': 0.5807889528987462, 'gamma': 4.668406682281875, 'reg_alpha': 3.747480642323245, 'reg_lambda': 3.3306951676548655}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:18:04,502] Trial 18 finished with value: 0.6036601307189543 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.08549580159625378, 'subsample': 0.774159076884917, 'colsample_bytree': 0.6665329858028638, 'gamma': 1.0647931637340187, 'reg_alpha': 0.9311812590748553, 'reg_lambda': 0.7938137729982961}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:18:52,957] Trial 19 finished with value: 0.5892810457516341 and parameters: {'n_estimators': 236, 'max_depth': 15, 'learning_rate': 0.21129501693149635, 'subsample': 0.6222192830201794, 'colsample_bytree': 0.8291170271052435, 'gamma': 2.1732259825366347, 'reg_alpha': 1.5705961955498355, 'reg_lambda': 2.075310256478167}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:19:53,266] Trial 20 finished with value: 0.596078431372549 and parameters: {'n_estimators': 277, 'max_depth': 5, 'learning_rate': 0.07746553599554405, 'subsample': 0.7451110485799101, 'colsample_bytree': 0.6895970135858711, 'gamma': 2.459896808121446, 'reg_alpha': 2.3675083594832658, 'reg_lambda': 1.3069830800101792}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:20:47,580] Trial 21 finished with value: 0.6023529411764706 and parameters: {'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.11866132028432064, 'subsample': 0.6517235283740456, 'colsample_bytree': 0.6424162764724002, 'gamma': 2.0779206909343464, 'reg_alpha': 1.448244681464403, 'reg_lambda': 1.2842425528980237}. Best is trial 15 with value: 0.6052287581699346.\n",
      "[I 2025-05-07 22:21:39,561] Trial 22 finished with value: 0.6094117647058823 and parameters: {'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.10943403243496633, 'subsample': 0.6000782322243383, 'colsample_bytree': 0.5845535582249093, 'gamma': 2.4476097959409953, 'reg_alpha': 0.6675989299116594, 'reg_lambda': 0.5347733994615613}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:22:20,252] Trial 23 finished with value: 0.6057516339869281 and parameters: {'n_estimators': 245, 'max_depth': 3, 'learning_rate': 0.10556933194866992, 'subsample': 0.5988810124333854, 'colsample_bytree': 0.5823748195938412, 'gamma': 3.4512268925388123, 'reg_alpha': 0.1880434678857581, 'reg_lambda': 0.5212543894308446}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:23:09,280] Trial 24 finished with value: 0.5989542483660131 and parameters: {'n_estimators': 278, 'max_depth': 7, 'learning_rate': 0.11396053525522541, 'subsample': 0.5170912633660854, 'colsample_bytree': 0.5770467289612401, 'gamma': 3.4527464807268995, 'reg_alpha': 0.31101749751084334, 'reg_lambda': 0.5039477369092539}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:23:46,375] Trial 25 finished with value: 0.5997385620915032 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.18161831110543072, 'subsample': 0.5808585721948086, 'colsample_bytree': 0.5027364146138897, 'gamma': 4.615549812070485, 'reg_alpha': 0.024135971766181097, 'reg_lambda': 0.4381688306088408}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:24:19,184] Trial 26 finished with value: 0.5918954248366014 and parameters: {'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.2901225710034534, 'subsample': 0.6076629710671251, 'colsample_bytree': 0.5941621637790011, 'gamma': 3.4482428536511893, 'reg_alpha': 0.8344828358299672, 'reg_lambda': 1.2011267359566284}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:25:41,207] Trial 27 finished with value: 0.6094117647058823 and parameters: {'n_estimators': 240, 'max_depth': 9, 'learning_rate': 0.050387280880119234, 'subsample': 0.5382052145537505, 'colsample_bytree': 0.547510354251774, 'gamma': 2.621333440733898, 'reg_alpha': 0.7892238860583518, 'reg_lambda': 2.215712316504727}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:26:44,507] Trial 28 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 237, 'max_depth': 6, 'learning_rate': 0.04833519849271408, 'subsample': 0.5521703130923451, 'colsample_bytree': 0.5433570415150833, 'gamma': 4.278970324034047, 'reg_alpha': 0.46465006099428324, 'reg_lambda': 3.5608441928596646}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:27:33,864] Trial 29 finished with value: 0.604967320261438 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.06689177524964902, 'subsample': 0.5197658040627592, 'colsample_bytree': 0.5390757519657212, 'gamma': 2.8237619949660067, 'reg_alpha': 0.003984030694714424, 'reg_lambda': 2.1870567779122605}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:28:40,357] Trial 30 finished with value: 0.6018300653594771 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.048350640635335715, 'subsample': 0.5527849073818484, 'colsample_bytree': 0.5314747716100391, 'gamma': 3.281923628132065, 'reg_alpha': 0.68088822705425, 'reg_lambda': 1.6303550178204607}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:29:39,872] Trial 31 finished with value: 0.6 and parameters: {'n_estimators': 268, 'max_depth': 9, 'learning_rate': 0.10045083852350666, 'subsample': 0.6304606995235569, 'colsample_bytree': 0.6125155413727179, 'gamma': 2.3709486185723407, 'reg_alpha': 0.9853363118215588, 'reg_lambda': 0.4423549406689743}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:30:39,115] Trial 32 finished with value: 0.6 and parameters: {'n_estimators': 286, 'max_depth': 11, 'learning_rate': 0.09664363537216349, 'subsample': 0.5069311233345328, 'colsample_bytree': 0.5663432596937331, 'gamma': 2.6769921384843895, 'reg_alpha': 1.7822404836617753, 'reg_lambda': 0.926877188242466}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:31:17,477] Trial 33 finished with value: 0.6002614379084967 and parameters: {'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.07154809696498816, 'subsample': 0.5895611878863086, 'colsample_bytree': 0.615462893268655, 'gamma': 3.181615397687752, 'reg_alpha': 0.37144882877978314, 'reg_lambda': 0.5422376221059375}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:32:10,274] Trial 34 finished with value: 0.5984313725490196 and parameters: {'n_estimators': 256, 'max_depth': 14, 'learning_rate': 0.14704516897189893, 'subsample': 0.6774491791879509, 'colsample_bytree': 0.6843321563819348, 'gamma': 2.8671264803238348, 'reg_alpha': 0.7252683841428172, 'reg_lambda': 2.177069861342358}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:33:18,162] Trial 35 finished with value: 0.6000000000000001 and parameters: {'n_estimators': 299, 'max_depth': 8, 'learning_rate': 0.051439719738109436, 'subsample': 0.5443220167794678, 'colsample_bytree': 0.5051732933611652, 'gamma': 3.5978206524330747, 'reg_alpha': 1.139797071209297, 'reg_lambda': 1.5139984545547338}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:35:06,917] Trial 36 finished with value: 0.5937254901960785 and parameters: {'n_estimators': 230, 'max_depth': 12, 'learning_rate': 0.02840204444971465, 'subsample': 0.6995759186076842, 'colsample_bytree': 0.5578133152817493, 'gamma': 3.0474964462156855, 'reg_alpha': 0.232874153393949, 'reg_lambda': 1.0570402420981007}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:36:01,162] Trial 37 finished with value: 0.596078431372549 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.05755658703124759, 'subsample': 0.9043017392621119, 'colsample_bytree': 0.7014685603504097, 'gamma': 4.246023485574678, 'reg_alpha': 1.8020206575765896, 'reg_lambda': 0.3063188887347392}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:37:04,836] Trial 38 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.09844686913379448, 'subsample': 0.5679182530736709, 'colsample_bytree': 0.5913347114571326, 'gamma': 1.6829218029914763, 'reg_alpha': 3.957358474870537, 'reg_lambda': 2.9068153670718635}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:37:58,036] Trial 39 finished with value: 0.5916339869281045 and parameters: {'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.019054177417070033, 'subsample': 0.7548606088355968, 'colsample_bytree': 0.6280980390065701, 'gamma': 2.426980958496399, 'reg_alpha': 2.079010213814139, 'reg_lambda': 1.8617644236315833}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:40:36,893] Trial 40 finished with value: 0.5877124183006536 and parameters: {'n_estimators': 169, 'max_depth': 12, 'learning_rate': 0.010786276280135142, 'subsample': 0.5022506601690792, 'colsample_bytree': 0.7182416242131864, 'gamma': 1.9304842629832535, 'reg_alpha': 0.8582318199358113, 'reg_lambda': 2.427105101780339}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:41:25,373] Trial 41 finished with value: 0.6049673202614378 and parameters: {'n_estimators': 194, 'max_depth': 4, 'learning_rate': 0.06672614674857341, 'subsample': 0.5783236334586815, 'colsample_bytree': 0.5288742569818278, 'gamma': 2.859488940362037, 'reg_alpha': 0.09884670800809074, 'reg_lambda': 2.336966299936172}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:42:08,183] Trial 42 finished with value: 0.6070588235294118 and parameters: {'n_estimators': 179, 'max_depth': 4, 'learning_rate': 0.07833773348001939, 'subsample': 0.5360656689454096, 'colsample_bytree': 0.5539489591479055, 'gamma': 2.7944030244464035, 'reg_alpha': 0.5684497507556928, 'reg_lambda': 2.659215278413294}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:42:42,595] Trial 43 finished with value: 0.605751633986928 and parameters: {'n_estimators': 147, 'max_depth': 3, 'learning_rate': 0.08203607638405389, 'subsample': 0.5405749303797913, 'colsample_bytree': 0.5977663878803122, 'gamma': 2.600832868858368, 'reg_alpha': 0.565005128055647, 'reg_lambda': 3.2449050792345098}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:43:18,946] Trial 44 finished with value: 0.5973856209150327 and parameters: {'n_estimators': 147, 'max_depth': 3, 'learning_rate': 0.04372518478938268, 'subsample': 0.5342405649051672, 'colsample_bytree': 0.5988922570506761, 'gamma': 2.6314235234835537, 'reg_alpha': 0.6309901915203386, 'reg_lambda': 3.282696616673123}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:43:54,319] Trial 45 finished with value: 0.6026143790849673 and parameters: {'n_estimators': 135, 'max_depth': 4, 'learning_rate': 0.08138938737018876, 'subsample': 0.6146177035494869, 'colsample_bytree': 0.5269430432765247, 'gamma': 3.091950447949395, 'reg_alpha': 0.358863418503531, 'reg_lambda': 3.8879053130951027}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:44:29,986] Trial 46 finished with value: 0.5937254901960785 and parameters: {'n_estimators': 183, 'max_depth': 3, 'learning_rate': 0.13566456131175028, 'subsample': 0.5343107104450412, 'colsample_bytree': 0.9981200679853546, 'gamma': 3.7581119600462554, 'reg_alpha': 1.145140787602, 'reg_lambda': 4.77261446965271}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:45:08,608] Trial 47 finished with value: 0.5905882352941175 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.05823681600257293, 'subsample': 0.5973592110889214, 'colsample_bytree': 0.5738633151219956, 'gamma': 4.016021203720902, 'reg_alpha': 0.5152340887037525, 'reg_lambda': 2.881988182935669}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:45:35,504] Trial 48 finished with value: 0.5958169934640524 and parameters: {'n_estimators': 149, 'max_depth': 4, 'learning_rate': 0.20487785191219518, 'subsample': 0.5656828707675386, 'colsample_bytree': 0.6546699771348772, 'gamma': 3.2969013113949504, 'reg_alpha': 1.3531449840783396, 'reg_lambda': 2.626542799173092}. Best is trial 22 with value: 0.6094117647058823.\n",
      "[I 2025-05-07 22:46:21,134] Trial 49 finished with value: 0.5924183006535948 and parameters: {'n_estimators': 176, 'max_depth': 6, 'learning_rate': 0.12846275460947526, 'subsample': 0.6442774528557758, 'colsample_bytree': 0.9640394068401594, 'gamma': 2.3322956621754645, 'reg_alpha': 2.6526709507897057, 'reg_lambda': 3.1669518669387644}. Best is trial 22 with value: 0.6094117647058823.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.10943403243496633, 'subsample': 0.6000782322243383, 'colsample_bytree': 0.5845535582249093, 'gamma': 2.4476097959409953, 'reg_alpha': 0.6675989299116594, 'reg_lambda': 0.5347733994615613}\n",
      "Accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          Q1       0.60      0.74      0.66        34\n",
      "          Q2       0.76      0.79      0.78        33\n",
      "          Q3       0.71      0.50      0.59        34\n",
      "          Q4       0.63      0.65      0.64        34\n",
      "\n",
      "    accuracy                           0.67       135\n",
      "   macro avg       0.67      0.67      0.66       135\n",
      "weighted avg       0.67      0.67      0.66       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Этап 1: Кодирование целевой переменной ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['Quadrant_encoded'] = label_encoder.fit_transform(df['Quadrant'])\n",
    "\n",
    "# Получаем уникальные треки\n",
    "unique_tracks = df['Song'].unique()\n",
    "\n",
    "# Делим треки на train и test\n",
    "train_tracks, test_tracks = train_test_split(\n",
    "    unique_tracks,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df.groupby('Song')['Quadrant_encoded'].first()\n",
    ")\n",
    "\n",
    "# Создаем train/test датасеты\n",
    "train_df = df[df['Song'].isin(train_tracks)].copy()\n",
    "test_df = df[df['Song'].isin(test_tracks)].copy()\n",
    "\n",
    "# Признаки и метки\n",
    "X_train = train_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_train = train_df['Quadrant_encoded']\n",
    "groups = train_df['Song']  # Для GroupKFold\n",
    "\n",
    "X_test = test_df.drop(['Quadrant', 'Quadrant_encoded', 'Song'], axis=1)\n",
    "y_test = test_df['Quadrant_encoded']\n",
    "\n",
    "# --- Этап 2: Оптимизация гиперпараметров с GroupKFold ---\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0,\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in group_kfold.split(X_train, y_train, groups=groups):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        preds = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, preds))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# --- Этап 3: Обучение финальной модели на всем тренировочном датасете ---\n",
    "best_model = XGBClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и обратное декодирование\n",
    "test_df['Quadrant_encoded'] = best_model.predict(X_test)\n",
    "test_df['Quadrant_predicted'] = label_encoder.inverse_transform(test_df['Quadrant_encoded'])\n",
    "\n",
    "# Мажоритарное голосование по треку\n",
    "track_predictions = test_df.groupby('Song')['Quadrant_predicted'].agg(lambda x: x.mode()[0])\n",
    "track_true_labels = test_df.groupby('Song')['Quadrant'].first()\n",
    "\n",
    "# Метрики\n",
    "accuracy = accuracy_score(track_true_labels, track_predictions)\n",
    "report = classification_report(track_true_labels, track_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
